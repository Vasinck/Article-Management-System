{
    "articles": [
        {
            "id": "6c41b749",
            "title": "(AAAI 2025) 超分辨率的高效注意力共享Transformer结构，即插即用，持续开源",
            "tags": [
                "这篇文章介绍了一种名为 ASID的轻量级Transformer结构，专为单图像超分辨率任务设计，目标是在极低参数量（约300K）下实现高质量图像重建，同时显著降低计算成本，适用于资源受限设备。"
            ]
        },
        {
            "id": "159b2a9c",
            "title": "(arXiv 2025) CSA-ConvBlock：轻量网络里的通道自注意力神器",
            "tags": [
                "该文提出Flat U-Net，通过全程恒定通道数C的扁平化结构大幅压缩参数，同时设计轻量通道自注意力模块CSA-ConvBlock增强跨通道建模能力，在极低参数量下实现优于经典U-Net的太阳细丝分割性能，尤其提升召回率与细粒度结构捕捉能力，适用于嵌入式或资源受限场景下的小目标分割任务。"
            ]
        },
        {
            "id": "7f6ab898",
            "title": "(arXiv 2025) LWGA模块：轻量级多尺度注意力的新选择",
            "tags": [
                "该文提出LWGANet，一种专为遥感视觉任务设计的轻量级骨干网络，其核心LWGA模块通过将特征分组并行应用点注意、局部注意、中程稀疏注意和全局稀疏注意，高效提取多尺度空间信息而不增加计算负担。该网络在场景分类、目标检测、语义分割和变化检测等四大类遥感任务的12个数据集上实现SOTA性能，显著平衡了精度与轻量化需求。LWGA模块具备即插即用特性，特别适合部署在无人机、卫星等资源受限设备上，以处理遥感图像中普遍存在的多尺度目标挑战。"
            ]
        },
        {
            "id": "b993e129",
            "title": "(arXiv 2025) 不加参数，性能飙升！加权卷积 wConv2D 登场",
            "tags": [
                "该文提出加权卷积算子wConv2D，通过引入无需训练参数的空间密度函数对卷积核进行位置感知加权，在不增加模型复杂度的前提下直接替换标准卷积，显著提升分类与去噪性能（如VGG准确率提升超10%，DnCNN去噪PSNR提升2.5dB）。该算子计算高效、兼容现有CNN架构，适用于图像分类、去噪、1D/3D信号处理等广泛任务，特别适合资源受限的边缘设备部署。作为一种通用基础算子，wConv2D通过增强卷积的空间敏感性，在保持简洁性的同时为各类视觉与信号处理模型提供即插即用的性能增益。"
            ]
        },
        {
            "id": "3b1bb820",
            "title": "(arXiv 2025) 关系感知注意力机制，即插即用，涨点启动",
            "tags": [
                "该文提出LP-DETR，通过在DETR解码器中引入层级渐进的关系感知注意力机制，显式建模目标间的局部、中程与全局空间关系，使模型在浅层聚焦局部交互、深层转向全局依赖，从而加速收敛并提升检测精度（如R50达52.5% AP）。该模块通过可学习的几何关系权重（距离、尺度、gIoU）增强自注意力，不依赖纯特征相似度，更符合检测任务的层次化认知过程。作为一种即插即用的通用组件，Relation-Aware Attention可无缝集成进各类Transformer检测器，显著提升多目标场景下的空间推理能力，适用于目标检测、实例分割及视觉关系理解等任务。"
            ]
        },
        {
            "id": "0a16e259",
            "title": "(arXiv 2025) 差分注意力：让模型自动屏蔽噪声，专注重要信息！",
            "tags": [
                "该文提出DiffCLIP，首次将差分注意力机制引入CLIP模型，通过在每个注意力头内学习两组互补注意力分布并相减，自动抑制噪声区域、强化关键信息，在仅增加0.003%参数量的极低成本下，显著提升零样本分类、图文检索、鲁棒性与细粒度理解等多任务性能。该方法通过消除跨模态对齐中的无关注意，使视觉与文本特征更精准聚焦于语义相关区域，从而增强模型判别力与泛化能力，尤其适用于背景复杂、数据噪声大或需细粒度对齐的多模态场景。作为一种即插即用模块，DiffAttention可无缝替换ViT、BERT等Transformer架构中的标准注意力层，为现有模型提供轻量高效的性能升级方案。"
            ]
        },
        {
            "id": "133d23a6",
            "title": "(CVPR 2025) 打破方形卷积的桎梏：自适应矩形卷积 ARConv 来了！",
            "tags": [
                "ARConv是一种自适应矩形卷积模块，能根据输入特征动态调整卷积核的高度与宽度及采样点数量，突破传统方形卷积限制，在遥感图像融合等多尺度任务中显著提升性能且计算开销低；作为即插即用模块，它可无缝替换标准卷积嵌入现有网络，在保持结构兼容性的同时增强空间适应性与特征提取能力。"
            ]
        },
        {
            "id": "f428e3f8",
            "title": "(CVPR 2025) Dynamic Tanh：归一化层的轻量替代方案",
            "tags": [
                "Dynamic Tanh（DyT）是一种轻量级逐元素激活模块，通过可学习缩放参数α控制tanh函数，替代Transformer中的归一化层，在视觉、语言、语音等多任务中实现相当或更优性能且无需计算均值方差；它提升了训练与推理效率，增强了对小批量和流式场景的鲁棒性，挑战了归一化层不可或缺的传统认知并提供了新视角。"
            ]
        },
        {
            "id": "a7bdcf23",
            "title": "（Arxiv2025）RestorMixer：CNN+Transformer+Mamba，涨点起飞",
            "tags": [
                "RestorMixer 是首个融合 CNN、Mamba 和 Transformer 的异构混合架构图像复原模型，通过三阶段编解码结构与交替堆叠的 EMVM 和 MWSA 模块实现局部细节、全局依赖与动态特征的协同建模；该模型在多个复原任务中性能领先，兼顾效率与精度，并通过多尺度监督与频域损失进一步提升恢复质量，验证了异构架构在视觉任务中的巨大潜力。"
            ]
        },
        {
            "id": "c3ecc130",
            "title": "（arxiv2025）新型激活函数TeLU，即插即用，涨点起飞",
            "tags": [
                "TeLU是一种新型激活函数，定义为x·tanh(eˣ)，兼具ReLU的高效梯度传播与平滑函数的稳定性，在负区间保留非零梯度避免神经元死亡，正区间近似线性加速收敛，且计算简单、理论完备；实验表明其在MLP、CNN、Transformer、RNN和VAE等多种架构中均优于ReLU、GELU等主流激活函数，收敛更快、精度更高、训练更稳定，可作为即插即用的通用替代方案。"
            ]
        },
        {
            "id": "70d70aea",
            "title": "【CVPR 2025】清华大学：见大观小，即插即用——LS卷积，CV任务统统涨点！",
            "tags": [
                "清华大学提出LSNet模型，受人类视觉系统启发设计LS卷积，通过“见大观小”策略结合大核感知与小核聚合，在图像分类、检测、分割等任务中实现性能与效率的显著提升，且具备即插即用特性。该方法在低计算成本下优于现有轻量级模型，展现出强大泛化与鲁棒性，为高效视觉网络设计提供新思路。代码已开源，便于复现与应用。"
            ]
        },
        {
            "id": "10e8a8d3",
            "title": "[CVPR 2025] | OverLoCK：像人眼一样“先扫一眼，再仔细看”的纯卷积新骨干！",
            "tags": [
                "香港大学提出纯卷积骨干网络OverLoCK，首次显式模拟人眼“先扫全局、再聚焦细节”的自上而下注意力机制，通过三分支架构与新型ContMix动态卷积，在保持局部归纳偏置的同时建模长程依赖，以三分之一参数量实现84.2% ImageNet Top-1准确率，并在检测、分割等下游任务全面超越现有模型。该方法为高性能轻量级纯卷积网络设计开辟了新路径。"
            ]
        },
        {
            "id": "abad09f4",
            "title": "(NN 2025) 注意力机制的进化：Transformer开始学会“取舍”了！",
            "tags": [
                "该文提出DSFormer网络，通过双重选择性融合机制在感受野和token两个层面优化Transformer：KSFTB模块利用多尺度卷积核自适应选择最优空间上下文范围以适配不同地物特征，TSFTB模块则在自注意力过程中仅保留最相关tokens以抑制冗余与噪声，从而在高光谱图像分类中显著提升精度并降低计算开销，同时增强模型可解释性与鲁棒性。"
            ]
        },
        {
            "id": "84658daa",
            "title": "3.5 倍能效突破，Attention 和 Softmax 的 AI 加速器实现：Cross-Road Softmax",
            "tags": [
                "本文提出Cross-Road Softmax算法，通过独热编码跳过主导值明显的softmax计算，并对剩余情况采用硬件友好的基2 Softmax近似，显著降低计算开销；基于此设计的Cross-Road Accel加速器在15nm工艺下实现，相比现有方案平均提升3.5倍能效，同时在BERT等模型上保持精度无损甚至略有提升。"
            ]
        },
        {
            "id": "be7da6f0",
            "title": "【转载】为什么“统计显著性”毫无意义",
            "tags": [
                "文章批判传统“统计显著性”概念的三大缺陷：依赖武断阈值、制造虚假确定感、忽视实际风险与收益，主张用置换检验和自助法获取结果分布，进而基于经济影响与概率权衡（如亏损概率3.8%、预期损失136万 vs 获利概率96.2%、预期收益622万）进行数据驱动决策，超越p值与置信区间的二元判断。"
            ]
        },
        {
            "id": "7d8dc886",
            "title": "(CVPR 2025) 轻量化新选择：GatedCNNBlock在视觉任务中的崛起",
            "tags": [
                "该文提出MambaOut模型，通过理论分析与实验验证指出视觉Mamba中的SSM模块在图像分类等非长序列、非自回归任务中非必需，进而移除SSM仅保留门控CNN构建轻量GatedCNNBlock，在ImageNet上性能超越多种视觉Mamba；该模块利用深度卷积与通道门控实现高效特征混合，兼具卷积归纳偏置与动态选择能力，成为视觉任务中SSM的高效替代方案。"
            ]
        },
        {
            "id": "40993640",
            "title": "86.1% ImageNet准确率！A2Mamba如何用注意力增强SSM，在三大视觉任务全面领先？",
            "tags": [
                "A2Mamba提出多尺度注意力增强状态空间模型（MASS），通过自适应多尺度注意力（含常规与扩张滑动窗口）捕获局部细节与长程依赖，并将注意力图注入状态空间模型（A2SSM）实现交叉注意力式增强，从而在单模块内深度融合Transformer与Mamba优势；基于此构建的A2Mamba骨干网络在ImageNet分类达86.1%准确率，且在检测、分割等密集任务全面领先，同时在高分辨率下保持线性复杂度、更低内存与更高吞吐量。"
            ]
        },
        {
            "id": "fa98838e",
            "title": "【TCSVT 2025】即插即用，边缘高斯聚合模块EGA，目标检测新SOTA！",
            "tags": [
                "LEGNet提出轻量级边缘-高斯聚合（EGA）模块，通过阶段自适应选择机制在浅层强化Scharr边缘特征、在深层引入高斯建模细化低置信度区域，有效提升低质量遥感图像中模糊、遮挡目标的特征可分性；配合LoG-Stem层在下采样时同步捕获多尺度边缘与不确定性信息，使模型在参数减少41.9%情况下仍超越现有方法，在DOTA等数据集上实现精度与实时性双优的SOTA表现。"
            ]
        },
        {
            "id": "afeb3164",
            "title": "CAMELTrack破局在线跟踪 | 双Transformer架构颠覆SORT与端到端范式，实现轻量化精准追踪",
            "tags": [
                "CAMELTrack提出双Transformer架构（时间编码器TE和组感知特征融合编码器GAFFE）替代传统手工启发式规则，实现数据驱动的上下文感知多线索动态融合与单阶段匹配。其关联中心训练方案解耦检测与关联，利用预提取特征和数据增强高效训练，仅需单GPU一小时，兼具端到端性能优势与SORT模块化灵活性。"
            ]
        },
        {
            "id": "762e2b0a",
            "title": "CFIS-YOLO小目标定位新突破 | CARAFE+Inner-SIoU，比YOLOv8s提升3.4%",
            "tags": [
                "CFIS-YOLO引入CARAFE动态上采样算子增强多尺度特征语义对齐，集成FasterBlock模块于C2f结构以部分卷积降低计算冗余，同时采用Inner-SIoU损失函数结合角度约束与内框机制提升小目标定位精度，在保持轻量级参数的同时显著提升检测性能与边缘部署效率。"
            ]
        },
        {
            "id": "856493df",
            "title": "Attention-IoU | 破解CV模型偏见黑箱，注意力图透视隐藏变量，突破数据集偏差检测边界",
            "tags": [
                "Attention-IoU提出一种基于注意力图的广义交并比度量方法，通过比较目标属性与敏感属性（如性别）的GradCAM热力图或真实特征掩码，量化模型内部对虚假相关特征的依赖程度。该方法能揭示数据标签未体现的隐藏混杂变量，并细粒度定位偏见产生的视觉区域，从而突破传统仅依赖准确率或数据分布的偏见检测边界。"
            ]
        },
        {
            "id": "1bb9374e",
            "title": "Blackwell架构高效加速新时代 | 英伟达为提出广义邻域注意力GNA，创新统一框架融合滑动窗口与分块注意力",
            "tags": [
                "英伟达提出广义邻域注意力（GNA），通过引入“步长”参数统一滑动窗口与分块注意力机制，支持灵活配置以在效率与平移等变性间权衡。配套开发NATTENSim分析工具模拟不同硬件与设计下的加速上限，并基于Blackwell架构实现高效FMHA核，在FP16/FP8精度下接近理论加速比，适用于视频与图像生成等多维Token任务。"
            ]
        },
        {
            "id": "e6718dd1",
            "title": "arXiv 2025 | 无需重构网络！即插即用新范式：卷积与加性自注意力强强联合",
            "tags": [
                "这篇文章提出了一个名为CAS-ViT的新模型，它巧妙地用高效的卷积和加法运算，替换掉了传统视觉Transformer中拖慢速度的复杂计算。这使得模型在手机等设备上不仅跑得飞快，准确率还能媲美主流大型模型，其核心模块更像一个即插即用的加速器，能方便地为其他网络提速。"
            ]
        },
        {
            "id": "7f81cad9",
            "title": "AnytimeYOLO革新实时检测 | 动态退出架构+优化算法实现任意中断推理，突破场景部署瓶颈",
            "tags": [
                "本文提出AnytimeYOLO，通过在YOLOv9架构中引入细粒度早期退出机制实现任意中断推理，允许模型在任何时间点输出有效预测；创新性地设计转置架构GELAN-∇·m^T，将多尺度处理并行化以提升早期性能，并结合基于图论的最优路径选择算法优化退出顺序与子集，在资源受限下平衡质量与效率；同时系统分析软硬实时推理差异及GPU部署障碍，提出理论质量评估指标指导模型选择与未来框架适配。"
            ]
        },
        {
            "id": "718c6c20",
            "title": "AAAI 2024 | 基于高阶结构的中间特征学习用于可见光-红外行人重识别",
            "tags": [
                "本文提出HOS-Net网络，通过短程长程特征提取模块结合CNN与Transformer分别捕获局部细节与全局结构，再利用白化超图网络构建的高阶结构学习模块建模特征间复杂高阶关系以增强表征并防止模型崩溃，最后通过图注意力对齐多模态多尺度特征生成可靠中间特征，并设计模态-范围身份中心对比损失拉近可见光、红外与中间特征距离，从而学习更具判别性且合理的公共特征空间用于跨模态行人重识别。"
            ]
        },
        {
            "id": "fa2599c7",
            "title": "AAAI 2025 | 特征互补映射模块FCM，即插即用，小目标检测高效涨点！",
            "tags": [
                "本文提出FBRT-YOLO实时航拍检测框架，通过嵌入特征互补映射模块FCM融合浅层空间信息与深层语义特征以增强小目标感知能力，同时引入多核感知单元MKP替代传统下采样结构以提升多尺度目标检测效率并简化网络计算。"
            ]
        },
        {
            "id": "018c6875",
            "title": "Consistent-Teacher：半监督目标检测超强SOTA",
            "tags": [
                "这是一篇半监督目标检测领域的论文，提出ConsistentTeacher方法以减少伪标签的不一致性。它通过自适应锚点分配替代固定IoU策略，使学生网络对噪声伪框更具鲁棒性。接着引入三维特征对齐模块实现分类与回归特征间的自适应校准，并利用高斯混合模型动态调整伪框置信阈值以稳定训练监督信号。"
            ]
        },
        {
            "id": "13d9d606",
            "title": "CVPR2024 | 释放通道潜力: SAR目标检测的空间频率选择卷积, 代码开源",
            "tags": [
                "这是一篇面向SAR图像目标检测的论文，提出空间频率选择卷积结构，在单一卷积层中同时建模空间上下文与频率纹理特征，通过空间感知单元、频率感知单元和无参数通道选择单元协同增强特征判别力，并构建轻量级检测网络SFS-CNet结合目标级梯度诱导学习策略提升细节表达能力。"
            ]
        },
        {
            "id": "8b54b723",
            "title": "DefMamba来袭：多尺度Backbone与可变形Mamba模块助力视觉任务新高度！",
            "tags": [
                "这是一篇面向通用视觉任务的基础模型论文，提出DefMamba架构，通过可变形Mamba模块与动态扫描策略自适应调整特征扫描路径和参考点位置，增强对图像空间结构与细节变化的感知能力，同时构建多尺度Backbone适配图像分类、目标检测与语义分割等下游任务。"
            ]
        },
        {
            "id": "736032f7",
            "title": "DiffusionDet论文解读：将目标检测重塑为去噪扩散过程",
            "tags": [
                "这是一篇目标检测领域的论文，首次将检测任务建模为从随机噪声框到精确目标框的去噪扩散过程，通过迭代式反向去噪与框更新机制实现检测框的逐步优化，同时支持推理阶段动态调整候选框数量和迭代步数以适应不同场景需求。"
            ]
        },
        {
            "id": "ba229795",
            "title": "CVPR 2025 | 解决广义类别发现中的灾难性遗忘问题",
            "tags": [
                "这是一篇广义类别发现领域的论文，提出LegoGCD方法通过局部熵正则化保留已知类别的判别能力以缓解灾难性遗忘，同时引入双视图KL散度约束提升未标记样本中潜在已知类别的筛选可靠性，从而在不修改原模型结构的前提下实现新旧类别知识的协同学习。"
            ]
        },
        {
            "id": "0cdd2773",
            "title": "CVPR 2025 | 域自适应检测新范式！多伦多大学提出 DINO Teacher：借力大模型伪标签，多数据集登顶",
            "tags": [
                "这是一篇域自适应目标检测领域的论文，提出DINO Teacher框架通过冻结预训练的大型自监督模型DINOv2作为独立伪标签生成器，摆脱传统均值教师对学生模型的依赖，同时引入无标签特征对齐机制强制学生模型特征与DINOv2泛化特征空间对齐，从而在不接触目标域标签的情况下实现跨域语义一致性与检测性能提升。"
            ]
        },
        {
            "id": "9b7c3b80",
            "title": "CVPR 2025 | 北理牵头提出 FDConv：傅里叶域分解 + 动态调制，多任务性能碾压传统动态卷积",
            "tags": [
                "这是一篇密集图像预测领域的论文，提出频率动态卷积FDConv通过在傅里叶域分解卷积核实现频率响应多样化，结合核空间调制与频带调制实现滤波器级和空间位置级的动态频率适应，从而在不显著增加参数量的前提下增强模型对多尺度频率特征的自适应建模能力，适用于目标检测、分割与分类等多任务场景。"
            ]
        },
        {
            "id": "82ce6601",
            "title": "Dynamic-DINO | MoE-Tuning革新实时目标检测，超越经典Grounding DINO性能极限！",
            "tags": [
                "这是一篇实时开集目标检测领域的论文，提出Dynamic-DINO框架通过MoE-Tuning策略将密集模型改造为动态推理结构，在不增加总参数量的前提下将FFN分解为多个细粒度专家网络并设计路由机制实现输入自适应激活，同时引入专家权重预分配与路由器初始化策略确保微调稳定性和零样本泛化能力。"
            ]
        },
        {
            "id": "dd066a2b",
            "title": "EAST 革新动作分割 | 端到端Transformer+Adapter设计，显式建模让模型登顶多项基准",
            "tags": [
                "这是一篇动作分割领域的论文，提出端到端动作分割Transformer框架EAST，通过Contract-Expand Adapter高效微调视觉主干网络提取多尺度帧特征，采用基于检测的分割范式在低帧率下预测动作Proposal并映射回全帧率进行聚合与细化，同时引入基于Proposal的数据增强策略提升模型对不确定边界的鲁棒性。"
            ]
        },
        {
            "id": "5cca1cf1",
            "title": "DeepSeek精度效率双提升，华为&信工所提出思维链“提前退出”机制",
            "tags": [
                "这是一篇大语言模型推理优化领域的论文，提出DEER方法通过动态监控思维链中的思路转换点并诱导生成试验性答案，根据答案置信度自适应决定是否提前终止冗长推理过程，从而在无需额外训练的前提下实现推理效率与准确率的同步提升。"
            ]
        },
        {
            "id": "80729d75",
            "title": "DeCLIP突破CLIP局限 | 解耦注意力+双蒸馏机制，开集检测/分割全面超越DINO/SAM",
            "tags": [
                "这是一篇开集密集预测领域的论文，提出DeCLIP框架通过解耦CLIP模型的自注意力机制分别提取内容特征和上下文特征，前者通过自蒸馏对齐图像裁剪区域增强局部判别性，后者通过视觉基础模型蒸馏学习空间相关性以提升特征一致性，从而在统一架构内协同优化视觉语言对齐与空间感知能力。"
            ]
        },
        {
            "id": "5294846b",
            "title": "ICCV 2025 | 北邮 & 中山提出UMDATrack：首个统一多域自适应跟踪框架，恶劣天气下性能远超SOTA",
            "tags": [
                "这是目标跟踪领域的论文，提出UMDATrack统一多域自适应框架，通过可控场景生成器合成少量多天气无标签视频，结合领域定制适配器快速迁移目标表征，并引入目标感知置信度对齐模块增强跨域定位一致性，实现无需冗余更新即可适应夜间、雾天等恶劣天气条件。"
            ]
        },
        {
            "id": "3dcb23fe",
            "title": "ICCV2025 | UniConvNet：扩展有效感受野的卷积神经网络视觉新主干，性能SOTA",
            "tags": [
                "这是卷积神经网络视觉主干领域的论文，提出UniConvNet通过三层感受野聚合器组合中小尺寸卷积核，在保持有效感受野渐近高斯分布的前提下扩展感受野范围，采用金字塔式通道增量结构降低计算与参数开销，并以层运算符为基础单元实现模块化堆叠，可无缝替换现有卷积层并适配高分辨率输入。"
            ]
        },
        {
            "id": "970d934c",
            "title": "ICCV 2025｜突破线性注意力瓶颈！MALA：记忆Query幅值的神经注意力机制",
            "tags": [
                "这是注意力机制领域的论文，提出MALA通过在传统线性注意力中引入Query幅值感知的缩放因子与偏移项，替代原有除法归一化为加法归一化，使注意力分数分布能随Query幅值动态调整并逼近Softmax注意力的尖锐特性，同时保持线性计算复杂度，从而在保留高效推理能力的前提下增强模型对关键区域的聚焦能力和局部感知能力。"
            ]
        },
        {
            "id": "1daad906",
            "title": "FlashDepth | 混合模型+Mamba革新，24 FPS实时2K视频深度估计，超越Depth Anything v2",
            "tags": [
                "这是视频深度估计领域的论文，提出FlashDepth通过在预训练单帧深度模型基础上引入轻量级Mamba循环模块，对中间特征进行时间对齐以保持帧间一致性，同时设计混合双流架构融合高分辨率小模型与低分辨率大模型的特征，在交叉注意力机制下兼顾边界清晰度与深度精度，最终实现在2K分辨率视频流上实时推理的能力。"
            ]
        },
        {
            "id": "143999b8",
            "title": "ICCV 2025 | 北航团队突破小目标检测瓶颈：UGS 框架实现不确定性梯度稳定，AP 提升显著",
            "tags": [
                "这是小目标检测领域的论文，提出UGS框架通过基于分类的非均匀离散定位目标替代传统回归，使梯度幅值受置信度驱动并保持有界，同时引入不确定性最小化损失抑制预测熵以稳定优化过程，并设计不确定性引导细化模块利用对抗扰动增强高不确定性区域的特征鲁棒性，三者协同缓解小目标因像素稀疏和损失曲率陡峭导致的梯度振荡与收敛困难问题。"
            ]
        },
        {
            "id": "a94be161",
            "title": "FastTracker：从“识人”到“识万物”，一个更通用的多目标跟踪框架",
            "tags": [
                "这是多目标跟踪领域的论文，提出FastTracker框架通过遮挡感知策略和道路结构感知策略增强对多类别目标的跟踪鲁棒性，尤其在车辆场景中利用运动抑制与检测框放大应对遮挡、结合道路区域与方向约束优化轨迹，整个方案不依赖外观重识别网络实现轻量高效且通用的实时跟踪能力。"
            ]
        },
        {
            "id": "0e8373b9",
            "title": "ECViT突破性Backbone架构 | 局部注意力机制+多尺度卷积，4.8M参数全面超越ViT/ResNet/ConvNeXt",
            "tags": [
                "这是图像分类领域的论文，提出了一种名为ECViT的轻量级混合架构，通过在Transformer中嵌入卷积操作引入局部性与平移不变性，并采用局部块内注意力机制和金字塔式Token合并策略实现多尺度特征高效建模，同时设计交互式前馈网络增强空间维度上的局部特征交互，在不依赖预训练的前提下兼顾全局建模与计算效率。"
            ]
        },
        {
            "id": "44164915",
            "title": "ICLR 2025 Spotlight！加州大学伯克利分校提出新型注意力机制ToST，解决Transformer的效率瓶颈",
            "tags": [
                "这是模型架构优化领域的论文，提出了一种名为ToST的新型线性复杂度注意力机制，通过引入Token统计特征和变分编码率缩减目标推导出TSSA模块，替代传统二次复杂度的自注意力，实现对序列信息的高效压缩与建模，同时保持全局语义表达能力，适用于长序列和大规模模型部署场景。"
            ]
        },
        {
            "id": "afddcd07",
            "title": "ECCV | 首个快速知识蒸馏的视觉框架：ResNet50 80.1%精度，训练加速30%",
            "tags": [
                "这是知识蒸馏领域的论文，提出了一种名为FKD的快速蒸馏框架，通过预先生成并存储每张图像多个区域裁剪对应的软标签及其空间坐标，在训练阶段复用这些标签避免重复前向传播teacher模型，同时结合多裁剪采样策略减少数据读取次数并提升样本多样性，从而在不牺牲标签质量的前提下实现训练过程的显式teacher-free加速。"
            ]
        },
        {
            "id": "3301bb88",
            "title": "ICLR 2024 | 具有层次注意力的快速视觉Transformer",
            "tags": [
                "这是视觉Transformer架构设计领域的论文，提出了一种名为FasterViT的混合架构，通过引入层次注意力模块HAT将全局自注意力分解为局部窗口注意力与载体令牌间的子全局注意力，利用可学习的载体令牌在窗口间传递和聚合信息，从而在保持跨窗口长程依赖建模能力的同时显著降低计算复杂度，并结合早期卷积层与后期注意力层的硬件感知设计优化推理吞吐量。"
            ]
        },
        {
            "id": "ca5bb3eb",
            "title": "ICML 2025 | 告别 Entropy 焦虑？北大港中用\"区域置信\"重新理解模型不确定性",
            "tags": [
                "这篇是测试时自适应领域的论文，提出了一种名为ReCAP的新方法，通过引入区域置信度概念替代传统熵最小化策略，从局部预测分布的一致性出发构建更稳定的优化目标；该方法利用概率区域建模与有限采样逼近技术，设计出可微、可部署的代理损失函数，无需源域标签即可实现稳定自适应；ReCAP具备良好的结构兼容性，可灵活集成现有样本选择机制，适用于极端数据稀缺与多重分布偏移的真实测试场景。"
            ]
        },
        {
            "id": "35b698ec",
            "title": "ICML 2025 | CCA-Attention：关键上下文感知注意力机制",
            "tags": [
                "这篇是长文本语言建模领域的论文，提出了一种名为CCA-Attention的关键上下文感知注意力机制，通过全局感知池化与局部保留模块协同工作，在降低计算复杂度的同时保持对长距离依赖和局部语义的完整建模能力；该方法动态聚合核心token以压缩计算维度，并确保每个位置都能访问邻近原始token，从而在不引入额外参数或修改模型结构的前提下实现即插即用；通过全局与局部注意力的可微融合策略，保障了所有token间的信息可达性，结合基于Triton的底层算子优化，显著提升推理效率与显存利用率。"
            ]
        },
        {
            "id": "80391a52",
            "title": "ICML 2025 | 何恺明的“残差连接”被魔改，新架构给Transformer建了个“动态立交”，28亿参数打平69亿",
            "tags": [
                "这篇是Transformer架构优化领域的论文，提出了一种名为MUDD的多路动态密集连接机制，旨在解决传统残差连接在深层网络中导致的信息瓶颈与表示坍塌问题；该方法允许每一层动态地、按需地从前序所有层聚合信息，彻底打破逐层传递的限制，构建出类似“动态立交桥”的跨层通信结构；最关键的是，它为Transformer块内的查询、键、值和残差输入分别设立了独立的动态聚合通道，使不同功能的信息流能根据自身需求独立获取历史上下文，极大提升了层间通信效率；整个方案可无缝集成到现有Transformer架构中，仅引入极低的额外计算与参数开销。"
            ]
        },
        {
            "id": "489c34b1",
            "title": "LW-DETR：用于实时检测的可替代YOLO的Transformer模型（提供源代码）",
            "tags": [
                "这是一篇关于目标检测的论文，提出了一种名为LW-DETR的轻量级检测Transformer模型，其架构由一个视觉Transformer编码器、一个投影器和一个浅层DETR解码器堆叠而成。该方法对编码器进行了改进，通过聚合多尺度、中间层和最终层的特征图来形成更丰富的特征，并采用交错窗口与全局注意力机制来降低计算复杂度。在解码器部分，模型采用了可变形交叉注意力机制和一种结合了内容查询与空间查询的混合查询选择方案。为了提升推理效率，该模型还引入了一种以窗口为主的特征图组织方式，以减少交错注意力计算中高成本的内存重排操作。"
            ]
        },
        {
            "id": "b59b2b75",
            "title": "InterpIoU：边界框回归的新损失函数——基于插值 IoU 的优化新思路，YOLO小目标涨点福音",
            "tags": [
                "这是一篇关于目标检测的论文，提出了一种名为InterpIoU的新边界框回归损失函数，旨在替代传统IoU损失中手工设计的几何惩罚项。其核心机制是通过在预测框与真实框之间构造一个插值边界框，并将该插值框与真实框的交并比作为新的惩罚项来引导优化。这种完全由交并比驱动的设计，不仅解决了预测框与真实框无重叠时的梯度消失问题，还从根本上避免了因惩罚目标不一致而导致的边界框被不合理放大等副作用。在此基础上，论文进一步提出了动态InterpIoU，该版本能够根据预测框与真实框当前的交并比值，自适应地调整插值系数，从而为不同训练阶段和不同尺度的目标提供更有效的学习信号。"
            ]
        },
        {
            "id": "c4a465dd",
            "title": "IJCV 2025 | 基于 Transformer 的通用与特定嵌入学习用于少样本目标检测",
            "tags": [
                "这是一篇关于少样本目标检测的论文，提出了一种名为T-GSEL的协同学习框架，旨在通过显式编码通用、中间和特定三种级别的特征嵌入来优化目标特征。该框架利用轻量级Transformer来动态建模输入特征与这些可学习嵌入之间的关系，并根据这种关系自含有目的地优化输入特征，以平衡通用性与判别性。为了学习并融合不同层次的特征，模型设计了一个三阶段渐进式优化结构，其中每个阶段使用不同的训练目标进行监督，并引入跨阶段连接来增强不同嵌入之间的信息互补。最终，模型将原始输入特征与后两个阶段的优化结果进行融合，从而集成不同层次的特征嵌入，以实现更有效的少样本检测。"
            ]
        },
        {
            "id": "c67a5f96",
            "title": "Transformer危！谷歌MoR架构发布：内存减半推理速度还翻倍",
            "tags": [
                "这是一篇关于大语言模型架构的论文，提出了一种名为递归混合（MoR）的新型架构，旨在通过在单一框架内首次融合参数共享和自适应计算来提升模型效率。在参数共享方面，该架构采用递归Transformer结构，通过循环复用一组共享参数池来代替传统的多层独立参数，从而显著减少模型的独特参数数量。在自适应计算方面，模型引入了动态路由机制，利用一个轻量级路由器为每个令牌分配不同的递归深度，使得计算资源能够集中在更复杂的令牌上，并允许简单令牌提前退出计算。此外，该架构还结合了专门的键值缓存策略，通过仅缓存活跃令牌的键值对或复用初始递归的缓存，来进一步降低推理过程中的内存占用。"
            ]
        },
        {
            "id": "506de506",
            "title": "TPAMI 2025 | 用于极端标签分类的多头编码",
            "tags": [
                "这是一篇关于极端标签分类的论文，提出了一种名为多头编码的机制，以解决因类别数量巨大而导致的分类器计算过载问题。其核心技术在于将一个高维的极端标签分解为多个低维局部标签的乘积，并用多个分别在这些局部标签上训练的小分类头取代传统的大型分类器。在此基础上，论文针对单标签、多标签和模型预训练等不同任务，分别设计了多头乘积、多头级联和多-头采样三种具体的实现算法，以在不同场景下高效地组合局部预测来恢复全局预测。"
            ]
        },
        {
            "id": "9def4198",
            "title": "TCSVT 2024 | GFENet：用于少样本目标检测的泛化特征提取网络",
            "tags": [
                "这是一篇关于少样本目标检测的论文，提出了一种名为GFENet的泛化特征提取网络框架，其核心思想是在基类训练阶段通过对模型进行扰动来提升其泛化性能。该框架主要通过两个模块实现这一目标：一个是通过在批次内混淆和交换特征来正则化浅层网络的混淆丢块模块，另一个是结合了自适应可变形卷积与丢块来增强模型对不同形状和大小目标检测能力的模块。此外，该方法还引入了一种基于高斯仿射变换的自适应特征增强模块在特征层面进行数据增强，并结合自蒸馏框架，利用新类与基类特征的相似度作为软标签来指导微调过程。"
            ]
        },
        {
            "id": "20758e6c",
            "title": "TMM 2024 | CMAT：用于视觉追踪的卷积混合器与自注意力机制",
            "tags": [
                "这是一篇关于视觉追踪的论文，提出了一种名为CMAT的新型追踪框架，其核心在于设计了一个聚合模块来同时利用卷积的局部特征提取能力和自注意力机制的全局依赖建模优势。该方法通过分析发现卷积和自注意力的初始阶段都包含相似的特征投影操作，因此让两条路径共享初始的一乘一卷积，从而有效减少了重复计算。在共享投影之后，模块分为两条并行路径：一条使用由深度卷积和逐点卷积构成的卷积混合器来高效地混合空间与通道信息，另一条则采用标准的自注意力机制来捕捉长距离依赖关系。最终，这两条路径的输出通过可学习的标量权重进行融合，以动态平衡局部与全局特征的重要性，并将此聚合模块嵌入到骨干网络中以构建高性能的追踪器。"
            ]
        },
        {
            "id": "e0058735",
            "title": "MoE新突破！专家链，专家开会让4层CoE打败12层MoE",
            "tags": [
                "这是一篇关于大语言模型架构的论文，提出了一种名为“专家链”的新型专家混合模型，旨在通过引入专家间的协作机制来解决复杂推理任务。其核心创新在于将传统专家混合模型中专家的并行独立工作模式转变为序贯处理模式，即在一个模型层内，输入会经历多轮迭代，每一轮都会根据当前处理结果动态选择一部分专家进行处理。为了实现这种智能的序贯流程，该架构为每一轮迭代都配备了独立的路由器，并引入了层内残差连接，确保信息在迭代过程中能够被逐步精炼和累积，从而在不增加物理层数的情况下提升模型的有效计算深度。"
            ]
        },
        {
            "id": "f3ca059c",
            "title": "NIPS 2024 | 注意力温度在基于ViT的跨域小样本学习中的重要性",
            "tags": [
                "这是一篇关于跨域小样本学习的论文，该论文发现视觉Transformer中的查询-键注意力机制在面对大领域差距时迁移性有限，导致目标域注意力失效。为解决此问题，论文提出了一种两阶段方法：在源域训练阶段，通过以一定概率随机放弃整个查询-键注意力，迫使模型学习更依赖于非查询-键参数的、更具迁移性的特征。在目标域微调与评估阶段，则对标准的注意力机制应用一个预定义的温度超参数，以缓解无效注意力图带来的负面影响。"
            ]
        },
        {
            "id": "cb7f1dbe",
            "title": "MGIoU革命 | 统一损失函数高效优化任意凸形状，计算延迟锐减40倍超越KFIoU",
            "tags": [
                "这是一篇关于计算机视觉中形状优化的论文，提出了一种名为边缘化广义交并比（MGIoU）的统一损失函数，旨在解决现有方法在优化任意凸参数化形状时存在的碎片化和低效问题。其核心技术是将复杂的高维形状重叠计算，简化为将形状顶点投影到其唯一的法线方向上，然后对这些一维投影计算广义交并比并进行边缘化求平均。为了处理顶点数量不同的非结构化凸形状，该方法进一步扩展为MGIoU+，通过引入一个额外的凸度正则化器来确保优化过程中预测形状的几何一致性。此外，论文还提出了一个互补的MGIoU-变体，它通过惩罚重叠而非最大化对齐，专门用于轨迹预测中的碰撞避免等需要最小化形状交叠的任务。"
            ]
        },
        {
            "id": "6e94db08",
            "title": "YOLO-APD突破 | 复杂道路下行人检测mAP达77.7%，实时100帧/秒",
            "tags": [
                "这是一篇目标检测的论文，提出了一种名为YOLO-APD的新型深度学习架构，该架构通过在YOLOv8的基础上进行优化，以解决在S型等复杂道路几何环境下的行人检测问题。该方法的核心创新在于集成了多个关键模块，包括用于增强多尺度特征汇聚的SimSPPF模块、计算高效的C3Ghost模块、无参数的SimAM注意力机制、用于优化特征融合的智能汇聚与分发（IGD）模块以及Mish激活函数。此外，论文还提出了一个利用车辆转向角和速度信息来动态调整检测区域的自适应ROI机制，从而将计算资源集中于关键区域，进一步提升效率和准确性。"
            ]
        },
        {
            "id": "78f47d4f",
            "title": "ViT 高阶关系破壁者 | Hypergraph Vision Transformer以动态超边实现1.9%分类跃迁",
            "tags": [
                "这是一篇关于视觉Transformer的论文，它提出了一种名为超图视觉Transformer（HgVT）的新框架，通过将分层二部超图结构融入视觉Transformer中，来有效捕获图像中的高阶语义关系。该方法的核心创新在于，它利用种群和多样性正则化策略来动态构建超图结构，从而避免了传统聚类算法带来的高计算开销。此外，模型还通过引入专家边池化机制来选择性地整合边缘特征，并利用虚拟顶点和超边构建分层语义结构，从而增强了模型的语义表征能力。"
            ]
        },
        {
            "id": "f17ba34b",
            "title": "ViT新突破 | NOVO让Transformer学会选择性遗忘，多类别遗忘准确率碾压现有方法7.3倍",
            "tags": [
                "这是一篇关于机器遗忘的论文，它提出了一种名为NOVO的新型视觉Transformer架构，通过为每个类别关联一个可学习的Prompt键，使得模型只有在相应键存在时才能进行预测，从而在移除键后能即时遗忘特定类别，无需任何微调或访问数据。该方法的核心在于其遗忘感知训练策略，即在训练过程中，通过将每批次的类别随机划分为保留集和遗忘集来模拟遗忘行为，并联合优化模型以正确分类保留集，同时强制遗忘集的输出遵循均匀分布。为了增强模型的鲁棒性和遗忘效果，NOVO还将这些Prompt键注入到网络的更深层次，并采用随机丢弃与扩展策略来打破样本与保留集之间的强关联，确保模型真正依赖于键的存在与否来进行预测。"
            ]
        },
        {
            "id": "27c49da6",
            "title": "ViT 弹性部署新时代 | EA-ViT四维动态适配，性能碾压DynaBERT/MatFormer 26%",
            "tags": [
                "这是一篇关于视觉Transformer弹性部署的论文，它提出了一种名为EA-ViT的高效适应框架，旨在通过单次适应过程，使一个预训练好的ViT能够生成适用于不同资源约束环境的多个模型。其核心技术在于构建了一个多维弹性架构，在MLP扩展率、注意力头数、嵌入维度和网络深度四个维度上引入结构灵活性，并采用基于课程的训练策略来逐步增加弹性，以稳定地保留预训练知识。此外，该框架还设计了一个轻量级路由器，它首先通过定制的进化算法识别出的帕累托最优配置进行初始化，然后与主干网络联合优化，从而能根据设备约束和任务需求自动选择最优的子模型。"
            ]
        },
        {
            "id": "a6b13969",
            "title": "ViT告别固定计算！ThinkingViT弹性计算仅用22.1M参数实现DeiT-Base级别性能，计算量降低67%",
            "tags": [
                "这是一篇关于视觉Transformer的论文，它提出了一种名为ThinkingViT的嵌套架构，该架构通过多阶段渐进式推理，根据输入图像的复杂度动态调整计算资源。其核心机制在于，模型首先激活一小部分注意力头进行初始预测，然后通过计算预测结果的熵来判断其确定性，如果确定性足够高，则提前终止推理，否则将激活更多的注意力头进行更深入的计算。为了使渐िन्进式推理更高效，该架构还设计了Token回收机制，将前一阶段的特征嵌入循环利用到后续阶段，使得模型的后续思考能够建立在已有认知的基础上，避免了重复计算。"
            ]
        },
        {
            "id": "0f1e6310",
            "title": "YOLOv8-SMOT自适应追踪框架，实时FPS17.61碾压OC-SORT",
            "tags": [
                "这是一篇关于小型多目标追踪的论文，它提出了一个名为YOLOv8-SMOT的检测追踪框架，专门用于解决无人机视角下鸟类等小型敏捷目标的追踪难题。在检测端，该方法通过一个创新的SliceTrain训练框架，采用确定性全覆盖切片结合切片级随机增强的策略，有效解决了高分辨率图像中微小目标学习不足的问题，并在推理时直接使用全图以保证效率。在追踪端，它设计了一个完全不依赖外观特征的鲁棒追踪器，通过在OC-SORT基础上引入运动方向维持机制来应对复杂运动，并采用结合了边界框扩展与距离惩罚的自适应相似度度量，以解决小目标在密集遮挡下的身份匹配难题。"
            ]
        },
        {
            "id": "8ce6dc82",
            "title": "YoloV：视频中目标实时检测依然很棒（附源代码下载）",
            "tags": [
                "这是一篇关于视频目标检测的论文，它提出了一种名为YOLOV的高效框架，通过将时间特征聚合步骤置于单阶段检测器（如YOLOX）之后，来解决传统两阶段检测器计算耗时的问题。该方法首先利用单阶段检测器快速生成高质量的目标候选框，从而避免了对大量低质量区域进行处理，然后仅针对这些高质量候选框进行跨帧的特征聚合与细化。为了有效聚合信息，该框架设计了一个新模块来评估目标框与参考框之间的关系，并创新性地对所有相似度高于特定阈值的参考特征进行平均池化，以融合更多样化的时间信息来增强最终的分类预测。"
            ]
        },
        {
            "id": "b32116b6",
            "title": "YOLOv7插上时序的翅膀 | 轻量级时序融合策略实现MOT20Det数据集85.5% mAP",
            "tags": [
                "这是一篇关于目标检测的论文，它提出了一种轻量级时序融合策略，通过将多个连续视频帧沿通道维度堆叠成单一输入，使YOLOv7等单帧检测器能够利用时间上下文信息。该方法主要修改了网络的第一层卷积，并探索了两种融合方式：一种是直接使用标准卷积进行早期融合，以联合学习时空特征；另一种是采用分组卷积，先独立提取每帧的低级特征再进行后期融合。该框架的一个核心特点是其弱监督训练机制，即尽管输入了多帧图像，但仅对最新的目标帧进行监督，其余帧则作为无标签的上下文来帮助模型隐式学习运动和时序依赖关系。"
            ]
        },
        {
            "id": "236730fd",
            "title": "YOLO-MS：重新思考实时目标检测中的多尺度表征学习（提供源代码）",
            "tags": [
                "这是一篇关于实时目标检测的论文，它提出了一种名为YOLO-MS的新检测器，通过一个名为MS-Block的新型基础构建模块来增强多尺度特征表示。该MS-Block采用分层多分支结构来丰富不同感受野的特征，并引入全局查询学习策略，通过一个跨阶段传递的轻量级查询来动态调整各分支的权重，从而减少无关信息的干扰。此外，该方法还提出了一种异构内核大小选择协议，即在网络的浅层使用小尺寸卷积核处理高分辨率特征，在深层逐渐增大卷积核尺寸以更好地捕捉大目标的语义信息。"
            ]
        },
        {
            "id": "e3956d8b",
            "title": "Transformer效率革命 | AnchorFormer通过Anchor机制实现分类/检测/分割全面SOTA",
            "tags": [
                "这是一篇关于视觉Transformer的论文，它提出了一种名为AnchorFormer的高效框架，旨在通过引入可学习的Anchor点来表示图像中的关键信息，从而降低传统自注意力机制的二次计算复杂度。其核心技术在于，它不再计算所有token之间的全局注意力，而是先计算所有token与一小部分可学习的Anchor点之间的二分注意力，从而将计算复杂度从平方级降低到线性级。关键在于，这些Anchor点被实现为可学习的神经元，使模型能够通过梯度下降自动学习和定位图像中的关键信息区域，并随后利用这些Anchor点的分布通过一个高效的数学过程近似恢复出全局自注意力。"
            ]
        },
        {
            "id": "20e0f8f5",
            "title": "YOLOv13震撼发布 | 超图高阶建模+轻量化模块，保证实时性的情况下，检测精度再创新高！",
            "tags": [
                "这是一篇关于目标检测的论文，它提出了一种名为YOLOv13的实时目标检测器，旨在通过自适应超图机制来增强模型对高阶视觉相关性的建模能力，从而提升检测精度。该方法的核心创新在于，引入了HyperACE机制，该机制能够通过自适应超图计算来捕获复杂场景下的多对多高阶相关性，并利用该相关性引导特征增强。此外，YOLOv13还采用了FullPAD范式，实现了全流程的多尺度特征聚合与分配，以及轻量级的深度可分离卷积模块，从而在保持模型轻量化的同时，提升了检测性能和推理速度。"
            ]
        },
        {
            "id": "245c1a43",
            "title": "YOPOv2-Tracker开源 | 端到端方法革新，跟踪提速10倍，扰动观测器破解传统框架延迟难题",
            "tags": [
                "这是一篇关于无人机目标跟踪与导航的论文，提出了一种名为YOPOv2-Tracker的端到端框架，它将传感器观测直接映射为底层控制指令，从而显著降低传统分离式流程的延迟。该方法借鉴单阶段目标检测器的思想，利用一组运动基元作为先验锚点来探索可行空间，并通过一个统一的全卷积网络并行地回归轨迹的偏移量、成本以及目标分数，将感知、检测和路径规划集成在一次前向传播中。为了简化部署并处理动力学不确定性，方案采用扰动观测器来补偿外部干扰，并通过将可微分的轨迹成本梯度直接反向传播至网络进行无专家演示的训练，实现了传统运动规划与深度学习的无缝结合。"
            ]
        },
        {
            "id": "e5c18c84",
            "title": "揭示卷积神经网络（CNN）与专家混合模型（MoE）的内在等价性：一个数学视角",
            "tags": [
                "这是一篇关于神经网络架构理论的论文，它从数学上论证了标准的卷积层本质上可以被视为一种隐式的、带有特定约束的专家混合模型（MoE）。论文将卷积核或权重矩阵类比为固定的“专家”，而将固定的非线性激活函数视为一种由数据驱动的、非归一化且不可学习的“门控”机制，这与MoE中可学习、归一化且稀疏的动态路由形成对比。这一理论视角揭示了提升传统CNN性能的明确路径，即通过引入独立可学习和归一化的门控网络（如动态卷积），将这种隐式结构显式地转化为真正的MoE，从而解锁模型处理具有内在聚类结构等复杂任务的能力。"
            ]
        },
        {
            "id": "4e100157",
            "title": "即插即用黑科技！DyCAF-Net无缝替换PANet Neck，Furniture数据集性能提升5.79%",
            "tags": [
                "这是一篇关于目标检测的论文，提出了一种名为DyCAF-Net的新型检测颈部网络，其核心是采用基于隐式平衡定点建模的动态融合机制来替代传统静态的多尺度特征融合。该网络通过一个双重动态注意力机制，利用输入和类别相关的线索自适应地调整通道与空间响应，并引入了类别感知特征自适应模块，通过调节特征来优先处理稀有或被遮挡类别的判别性区域。通过将动态融合、双重注意力与类别感知调节相结合，该框架实现了对不同尺度、遮挡和类别不平衡场景下特征的自适应优化，解决了传统方法中静态融合与类别无关注意力机制的局限性。"
            ]
        },
        {
            "id": "471d5ec0",
            "title": "告别知识漂移！实例级Top-k选择机制让模型自动适配最优教师路径，准确率最高提升12.3%",
            "tags": [
                "这是一篇关于跨模态知识蒸馏的论文，提出了一个名为MST-Distill的框架，通过构建一个由多模态和跨模态模型组成的混合专业教师池，来解决蒸馏路径选择和知识漂移的核心挑战。该框架引入一个实例级的路由网络，使学生模型能为每个样本动态地选择最优的教师组合进行学习，从而实现自适应的知识迁移。为了缓解不同模-态-归纳偏差导致的知识漂移，方案还设计了一个即插即用的MaskNet模块，它通过响应一致性引导来重建教师的中间层表示，使其行为与学生模型对齐，整个过程通过协同初始化、教师专业化适应和动态知识蒸馏三阶段策略进行优化。"
            ]
        },
        {
            "id": "51a5abca",
            "title": "底层架构革命！Meta提出大模型友好型全新注意力架构！",
            "tags": [
                "这是一篇关于大模型底层架构的论文，提出了一种名为2-单纯形注意力的全新架构，它将传统的双线性成对关系注意力机制推广到了能够捕捉三元组关系的三线性注意力。该方法为每个输入生成多组查询、键和值向量，其核心计算不再是衡量单个查询与单个键的相似度，而是通过三线性积来评估一个查询与一对键之间的关联强度，并融合这对键对应的值向量来加权求和，从而使模型能发现更高阶的组合依赖关系。为了解决三线性运算带来的巨大计算量，该架构采用滑动窗口机制将注意力计算限制在局部范围内，并利用定制的Triton核进行深度硬件优化，从而在实践中实现了高效运行。"
            ]
        },
        {
            "id": "33d89647",
            "title": "告别O(n²)！上海AI Lab开源Linear-MoE：线性注意力+MoE的终极缝合术",
            "tags": [
                "这是一篇关于大语言模型高效架构的论文，提出并开源了一个名为Linear-MoE的完整技术框架，旨在系统性地将线性序列建模（如线性注意力、状态空间模型等）与混合专家（MoE）这两大技术趋势进行高效结合。该框架的核心是一种模块化设计，它将各类线性序列建模方法封装为可插拔的线性序列建模层，并与多种主流的混合专家层实现进行灵活组合，甚至支持与传统的Softmax注意力层混合构建模型。为实现高效训练，该系统基于Megatron-Core构建，并集成了包括专家并行、线性注意力序列并行以及MegaBlocks在内的多种并行与优化技术，确保了在超大规模参数下的训练效率和稳定性。"
            ]
        },
        {
            "id": "fe32110f",
            "title": "告别FPN局限！PLUSNet三模块协同：HFP净化特征+MCLA优化标签+FDHead解耦任务，小目标精度飞跃",
            "tags": [
                "这是一篇关于小目标检测的论文，提出了一种名为PLUSNet的高质量检测框架，它通过引入三个即插即用模块——层次特征净化器（HFP）、多标准标签分配器（MCLA）和频率解耦头（FDHead）——对传统检测流程的特征融合、标签分配和检测头进行了全面优化。其中，HFP利用傅里叶变换净化低层特征以突出小目标细节并去除冗余语义信息；MCLA结合位置偏移和形状约束等多种准则，解决单一IoU标签分配对小目标的偏向性，以增加高质量正样本的数量。最后，FDHead根据任务特性，分别为分类和回归任务解耦利用低频语义特征和高频轮廓特征，进一步提升了小目标检测的整体性能。"
            ]
        },
        {
            "id": "c6362a8e",
            "title": "从 83 小时到 57 小时！OpenVision 2 拆解多模态视觉编码器的 “轻量化密码”",
            "tags": [
                "这是一篇关于多模态视觉编码器的论文，提出了一种名为OpenVision 2的极简生成式预训练范式，其核心是通过彻底移除传统架构中的文本编码器和图像-文本对比损失，将模型简化为“视觉编码器+文本解码器”的双模块线性结构。该方法仅依赖于单一的字幕生成损失作为训练目标，即模型根据视觉编码器输出的视觉令牌，通过文本解码器自回归地生成高质量字幕。为了进一步提升效率，方案还引入了视觉令牌随机掩码策略，在送入解码器前舍弃约三分之二的令牌，从而显著降低计算量和内存占用。"
            ]
        },
        {
            "id": "b9a76be1",
            "title": "YotoR：融合 Swin Transformer 和YoloR 的混合架构，提升目标检测性能",
            "tags": [
                "这是一篇关于目标检测的论文，提出了一种名为YotoR的混合深度学习架构，旨在将Swin Transformer的强大特征提取能力与YoloR的实时推理速度相结合。该模型的核心是将一个预训练的Swin Transformer作为主干网络，并将其与YoloR的颈部和头部进行融合，以生成一个统一的表示来进行多任务处理。为了实现两种不同架构的有效连接，方案通过对Swin Transformer输出的特征金字塔进行整形和归一化，并使用1x1卷积来调整通道数量，从而使其与YoloR头部所需的输入尺寸相匹配，缓解了信息瓶颈。"
            ]
        },
        {
            "id": "be190b97",
            "title": "目标检测告别传统解码桎梏 | DIAS随机自回归解码器问世，COCO识别精度提升18%同时训练成本减半",
            "tags": [
                "这是一篇目标中心学习领域的论文，提出了一种名为DIAS的槽位注意力新方法，旨在解决传统模型中因冗余槽位竞争导致的目标表示质量不佳以及监督信号不足的问题。该方法通过在聚合过程中减少冗余槽位并重新初始化一个额外的聚合来更新剩余槽位，同时利用最后一次迭代的注意力图来指导第一次迭代，实现了一种无需额外教师模型的自蒸馏机制。此外，它还采用了一种随机顺序的自回归解码器，通过打乱超像素的重建顺序来强制模型学习二维空间相关性，从而改进了解码过程。"
            ]
        },
        {
            "id": "2c7a6850",
            "title": "前景检测大突破 | Class-Aided助力OCCAM，HQES分割碾压传统槽位OCL，分类准确率飞跃",
            "tags": [
                "这是一篇前景检测领域的论文，提出了一种名为OCCAM的新流程，它利用高质量的实体分割模型生成目标掩码，以取代传统的基于槽位的目标中心学习方法来获取孤立的目标表示。该方法首先通过将生成的掩码应用于原始图像来分离出各个目标，然后引入一个类别辅助的前景检测器，从众多候选者中选择出最关键的前景目标。最终，仅将选定的前景目标表示送入分类器进行预测，从而有效消除虚假背景线索的干扰，实现鲁棒的下游分类。"
            ]
        },
        {
            "id": "4b6ced7f",
            "title": "面部关键点检测可以不用 Soft-argmax 了？普渡大学新方法实现SOTA，训练速度还快2.2倍！",
            "tags": [
                "这是一篇面部关键点检测领域的论文，它提出了一种摒弃Soft-argmax的新训练框架，该框架回归到经典的深度结构化学习，直接优化关键点坐标的分数。其核心是通过一个结构化预测损失函数，来惩罚那些分数过高的错误预测，使得真实位置的分数显著高于其他任何位置，从而避免了对argmax进行可微近似带来的优化难题。同时，该方法还设计了一种图像感知的标签平滑技术，利用图像的边缘信息来生成更符合图像结构的平滑标签，以应对标注中的不确定性。"
            ]
        },
        {
            "id": "c6775226",
            "title": "卷积是什么，和矩阵乘法的区别与联系是什么？",
            "tags": [
                "这是一篇关于线性代数与信号处理核心概念的文章，它将卷积定义为一种通过滑动窗口进行加权求和的局部运算，用于匹配和提取模式，而矩阵乘法则是一种组合线性映射的全局变换。二者的核心区别在于运算方式和几何意义，卷积是局部的、滑动的相似度匹配，而矩阵乘法是整体的、一次性的坐标系变换。然而，两者在本质上紧密相连，因为任何卷积运算在数学上都可以被表示为一种具有特殊稀疏结构的大型矩阵乘法，这揭示了深度学习中卷积层的运算本质。"
            ]
        },
        {
            "id": "9c61b8a3",
            "title": "仅1.24ms！FPN终结者 | 金字塔Sparse Transformer粗粒度引导细粒度+参数共享，实现检测与分类双赢",
            "tags": [
                "这是一篇关于目标检测与图像分类中特征融合的论文，提出了一种名为金字塔稀疏变换器 (PST) 的轻量级即插即用模块，它通过一种从粗到细的分层注意力策略来高效地整合多尺度特征。该方法的核心是一个两阶段过程：首先，一个粗粒度的交叉注意力利用高层特征图来引导并识别出低层特征图中最具信息量的区域；然后，一个细粒度的注意力机制仅对这些被选出的关键令牌进行处理，从而大幅降低了计算复杂度。此架构的一个关键创新在于粗粒度和细粒度注意力分支之间共享参数，这使得模型仅需在训练时激活高效的粗粒度分支，而在推理时可以无缝地启用细粒度分支以提升精度，且整个过程无需重新训练。"
            ]
        },
        {
            "id": "83270204",
            "title": "解决Transformer训练困境 | 全新初始化方法让ViT在小数据集上也能赶上CNN的收敛速度",
            "tags": [
                "这是一篇关于视觉Transformer训练领域的论文，它提出了一种新颖的初始化策略，旨在解决ViT在小数据集上训练困难的问题，通过在不改变模型架构的前提下引入卷积的归纳偏置。该方法的核心思想是，不再随机初始化自注意力模块中的查询和键权重，而是先将随机脉冲卷积滤波器转换为其等效的卷积矩阵作为理想的目标注意力图。然后，通过一个简短的预训练过程，专门训练查询和键的权重来拟合这个目标注意力图，从而将这种带有局部性偏置的结构作为ViT的初始状态，使其在训练初期就能像CNN一样高效学习。"
            ]
        },
        {
            "id": "ac61b30f",
            "title": "破解ViT过度自信难题 | Meta提出CalAttn模块，用CLS Token范数动态调节温度，ECE降至1.25%",
            "tags": [
                "这是一篇关于视觉Transformer模型校准领域的论文，为解决模型普遍存在的过度自信问题，它提出了一种名为CalAttn的即插即用模块，用于动态学习每个样本的自适应温度。该方法的核心是利用了一个新发现，即最终全局分类令牌的幅度可以作为衡量样本难度的内在指标，一个轻量级的神经网络模块正是利用这个令牌来为每个输入图像预测一个特定的温度值。该模块通过与主干网络进行端到端的联合训练，将校准过程直接整合到模型学习目标中，从而使模型能够根据每个样本的内在难度动态地调整其预测置信度。"
            ]
        },
        {
            "id": "07319a67",
            "title": "破茧！Hyb-KAN ViT革新视觉架构 | 小波×样条双剑合璧，性能碾压Swin Transformer！",
            "tags": [
                "这是一篇关于视觉Transformer架构领域的论文，它提出了一种名为Hyb-KAN ViT的新型框架，旨在通过将基于小波变换的频谱分解与基于样条优化的激活函数相结合，来克服传统ViT中多层感知器的局限性。该方法的核心是引入了两个关键模块：一个是利用正交小波进行多尺度特征提取以增强边缘检测等空间频率建模能力的Wav-KAN模块，另一个是使用样条函数替代传统激活函数以实现更高效自适应特征表示的Eff-KAN模块。通过将这两个模块系统性地集成到ViT的编码器和分类头中，该框架形成了一种混合架构，协同利用了小波分解在早期层提取的多尺度频谱信息和样条优化在后期层进行的高效特征提炼，从而在不牺牲参数效率的前提下提升了模型的整体性能。"
            ]
        },
        {
            "id": "36158b17",
            "title": "苹果发布MobileCLIP2：最强移动端CLIP，开源数据生成代码！",
            "tags": [
                "这是一篇关于轻量级多模态模型领域的论文，它通过一套名为DFNDR的增强训练方案，全方位优化了模型的训练流程。该方案的核心在于整合了更高质量的基础数据集、采用独立蒸馏温度策略的更强教师模型集成、以及经过微调的合成标题生成器，从而构建了一个极为高效的增强训练数据集。此外，该研究还为较大的模型变体设计了一种新的五阶段图像编码器架构，通过更均匀地分布参数和减少高分辨率下的处理令牌数量，来提升模型的推理效率。"
            ]
        },
        {
            "id": "fe708142",
            "title": "抛弃冗余解码器 | HMPE革新Transformer检测，小目标mAP飙升1.9%，解码器砍掉5层，推理速度翻倍",
            "tags": [
                "这是一篇关于Transformer目标检测领域的论文，它提出了一种名为热力图位置嵌入（HMPE）的新技术，通过利用梯度加权类激活映射生成与检测语义动态对齐的高质量位置编码，以解决传统方法中位置信息与语义特征解耦的问题。该方法将这种热力图嵌入分别应用于编码器和解码器，在编码器端通过多尺度目标框-热力图融合模块增强了特征表示并抑制背景噪声，在解码器端则通过热力图诱导模块直接生成高质量查询，从而允许大幅减少冗余的解码器层数。此外，为了进一步增强对复杂小目标的特征提取能力，该框架还引入了一种线性蛇形卷积模块，它通过双路径互补架构同时捕捉几何上不规则的稀疏特征和连续的线性结构。"
            ]
        },
        {
            "id": "4e1222fc",
            "title": "武汉大学提出 SimROD | 突破检测瓶颈！GGE模块+通道优化，效率超越SOTA方法",
            "tags": [
                "这是一篇目标检测的论文，它提出了一种名为SimROD的轻量级RAW数据目标检测方法，该方法首先通过一个仅有四个可学习参数的全局伽马增强模块来调整RAW图像的整体像素分布。其次，受启发于人眼对绿光更敏感以及相机拜耳阵列的设计，该方法设计了一个绿色引导的局部增强模块，利用信息更丰富的绿色通道来强化局部细节。最终，通过这种全局到局部的两阶段增强策略，提升了后续检测模型的性能。"
            ]
        },
        {
            "id": "7601b453",
            "title": "小模型逆袭大Teacher | 组间再平衡+组内均衡损失实现长尾类别12%性能反超",
            "tags": [
                "这是一篇知识蒸馏的论文，它为解决长尾数据下教师模型存在偏见的问题，首先将传统的知识蒸馏损失创新性地分解为组间和组内两个部分，即分别衡量头部、中部和尾部这些类别组之间的知识传递以及各组内部的知识传递。然后，该方法通过一种组间再平衡策略来修正教师模型对头部组别的过度预测，为学生模型提供一个在类别组之间更均衡的监督信号。与此同时，该方法还设计了一个均匀加权的组内损失来消除教师原始权重对尾部组别学习的抑制，确保所有类别的知识都能被学生模型平等地学习，从而实现从有偏教师向均衡学生的有效知识迁移。"
            ]
        },
        {
            "id": "4a91bbaa",
            "title": "西安交大提出DeepKD | 双层解耦+自适应去噪破解知识蒸馏困境，刷新ImageNet等多项SOTA",
            "tags": [
                "这是一篇知识蒸馏的论文，它为解决不同知识梯度间的冲突，提出了一种双层解耦策略，该策略基于对梯度信噪比的理论分析，将梯度分解为任务导向、目标类和非目标类三个部分，并为它们分别设计独立的动量更新器以实现深度优化。同时，为了应对非目标类知识中低置信度信息带来的噪声，该方法还引入了一种动态Top-K掩码机制，它遵循课程学习的原则，在训练过程中逐步放开对非目标类的限制，从而自适应地过滤噪声并净化暗知识。最终，该方法通过结合深度解耦优化与自适应去噪，构建了一个能更有效协调知识迁移过程的训练框架。"
            ]
        },
        {
            "id": "bc315ca5",
            "title": "让图像会说话！腾讯 ARC × 中科院重磅联手，视觉Token注入CLIP语义，TokLIP重塑多模态理解与生成",
            "tags": [
                "这是一篇多模态的论文，它旨在通过将CLIP的强大语义理解能力注入到VQGAN产生的离散视觉令牌中，从而统一视觉的理解与生成任务。具体来说，该方法先使用一个预训练的VQGAN将图像转换为离散令牌，再通过一个由CLIP权重初始化的令牌编码器将这些令牌映射到高层语义空间。其核心创新在于，训练时仅通过蒸馏和对比学习等语义损失来优化这个令牌编码器，同时冻结VQGAN以避免语义学习与图像重构之间的冲突，最终让每个视觉令牌本身就兼具像素还原能力和高层语义信息。"
            ]
        },
        {
            "id": "a30eb5b9",
            "title": "用好视觉Attention局部性，清华、字节提出Token Reorder，无损实现5倍稀疏、4比特量化",
            "tags": [
                "这是一篇视觉生成模型优化的论文，它基于视觉注意力的局部性先验，提出了一种名为Token Reorder的离线重排方案，该方案通过为每个注意力头选择最优的维度置换，将原本多样且分散的注意力图统一为更规整、更集中的块状模式。接着，在这种统一的块状模式基础上，该方法设计了与之适配的静态稀疏掩码来跳过不重要的计算块，并应用了支持更低位宽的块级量化策略来压缩计算量。最后，通过算子融合和稀疏掩码预取等系统级优化，该方案在硬件层面高效地实现了稀疏化和量化，最小化了额外开销。"
            ]
        },
        {
            "id": "ad2ade9f",
            "title": "小目标检测破局者 | MAFE R-CNN以多线索样本选择+类别感知特征增强显著超越Faster R-CNN",
            "tags": [
                "这是一篇目标检测领域的论文，它为解决小目标检测中的样本不平衡和特征模糊问题，提出了一种名为MAFE R-CNN的多线索分配与特征增强方法。该方法首先设计了一种多线索样本选择策略，它会综合考虑交并比距离、类别置信度和目标尺寸等多个线索，来动态地为小目标选择更多高质量的正样本，以解决训练中样本不足的问题。接着，论文还提出了一种类别感知特征增强机制，通过构建一个能跨图像学习和记忆同类目标特征的模块，并利用交叉注意力让候选框特征与这些记忆特征进行交互，从而增强模糊的小目标特征表示。"
            ]
        },
        {
            "id": "d10b4990",
            "title": "视觉Transformer突破性进展 | Always-Skip-Attention破解SA难题，DCTTG技术引领高效训练",
            "tags": [
                "这是一篇视觉Transformer领域的论文，它从理论上揭示了自注意力模块在没有残差连接时难以训练的根本原因，在于其输出嵌入的条件数很差，而残差连接起到了关键的正则化作用。为进一步改善该问题，论文提出了一种名为“Token Graying”的技术，通过直接优化输入自注意力模块之前的Token，使其具有更好的条件数，从而辅助模型训练。该技术具体通过两种方式实现，一种是基于奇异值分解的直接但高成本的方法，另一种是利用离散余弦变换作为其高效的近似替代方案。"
            ]
        },
        {
            "id": "e8465408",
            "title": "微小目标检测新标杆 | DPNet首创动态神经网络范式，微小目标检测效率跃升35%！",
            "tags": [
                "这是一篇微小目标检测领域的论文，它为解决放大图像带来的高昂计算成本问题，首次将动态神经网络思想引入该任务，提出了一种名为DPNet的动态池化网络。该网络的核心在于设计了一个轻量级的下采样因子预测器，它能根据输入图像的特点自适应地选择一个最优的下采样比例来处理主干网络中的特征图，并通过一个专门设计的引导损失函数来为这个预测器提供监督信号进行训练。此外，为了让单一检测器能兼容不同下采样因子带来的特征分布差异，论文还引入了一个自适应归一化模块，该模块为每种下采样因子配备了独立的归一化层，从而解决了混合尺度训练中的不一致性问题。"
            ]
        },
        {
            "id": "ec0b4673",
            "title": "武汉大学联合上海交大提出细粒度MoE | 减少激活专家数量，让吞吐量再提升50%！",
            "tags": [
                "这是一篇混合专家模型领域的论文，它旨在通过专家削减的策略来优化细粒度混合专家大语言模型的推理效率。该论文研究了两种削减路径：一是在推理时减少每个计算单元所激活的专家数量，并探索了在模型不同层级间如何分配这些激活专家的不同策略。二是在推理前就剪枝掉一部分总专家，并对比了随机移除、结构化移除和基于专家使用频率等不同剪枝方法的有效性。"
            ]
        },
        {
            "id": "7f4f0e83",
            "title": "为什么混合专家模型（MoE）如此高效：从架构原理到技术实现全解析",
            "tags": [
                "这篇是关于大语言模型混合专家架构的论文。该技术将标准Transformer中的部分前馈网络替换为多个并行的专家网络，并引入一个路由机制为每个输入token动态选择性地激活其中少数几个专家进行计算。为了解决路由可能持续选择少数专家导致的负载不均衡问题，模型引入了辅助损失函数来强制均匀分配，并通过设置专家容量来适配硬件的批处理能力。此外，该架构还发展出共享专家与路由专家相结合的模式来存储通用知识，或者借鉴其稀疏思想设计出多头潜在注意力等机制以提升效率。"
            ]
        },
        {
            "id": "4e93a9ce",
            "title": "语义分割新高度 | 英伟达提出SeNaTra空间分组层革新Backbone，性能效率双超Swin Transformer",
            "tags": [
                "这篇是关于语义分割的论文。该技术提出了一种名为SeNaTra的视觉Backbone，其核心是一种空间分组层，通过可微的迭代聚类过程将特征相似的视觉Token动态分组，以替代传统的均匀下采样操作。为保证计算效率，该架构在早期阶段采用局部分组策略，将计算限制在局部窗口内以实现线性复杂度，并仅在最后阶段启用全局密集分组来生成覆盖全图的分割区域。多个分组层堆叠后，其输出的分配矩阵被建模为马尔可夫链的状态转移矩阵，这使得整个Backbone具备了无需专用分割头即可生成分层分割掩码的原生分割能力，并能直接用于特征上采样。"
            ]
        },
        {
            "id": "a7820793",
            "title": "真不容易啊！终于知道神经网络上插入注意力机制为什么不增反降了",
            "tags": [
                "这篇是关于注意力机制的分析文章，它指出注意力模块本身带有参数，在模型本身已过拟合时再添加会加剧该问题导致性能下降。此外，该机制会影响模型的感受野，当原模型感受野已足够大时再加入注意力是冗余的，只有当原模型感受野不足以覆盖目标时，增加注意力才能有效扩大感受野并带来提升。"
            ]
        },
        {
            "id": "0b498142",
            "title": "重新思考FPN范式，无Neck也SOTA | Soft最近邻插值SNI对齐特征+ESD增强空间保留，效率精度双突破",
            "tags": [
                "这篇是关于目标检测的论文，该技术指出传统特征金字塔在融合多尺度特征时存在错位问题。为解决该问题，它在特征上采样阶段引入带权重缩放因子的软最近邻插值来缓解错位，并在下采样阶段设计了一种结合非线性与线性分支的扩展空间窗口方法以保留更多空间信息。此外，该技术还通过一种完全舍弃特征融合、采用独立层级金字塔的无颈部架构来从根本上规避该问题，并优化了轻量化卷积以提升效率。"
            ]
        },
        {
            "id": "a0ce1183",
            "title": "自注意力中簇的涌现",
            "tags": [
                "这篇是关于Transformer注意力机制的论文。该技术将自注意力动态过程建模为一个交互粒子系统，其中每个输入token被视为一个粒子，其演化过程对应于网络层数的加深。该系统证明了随着层数加深，代表token的粒子会自发地向特定的极限对象收敛，从而在表示空间中涌现出簇结构。这些簇的最终几何形态，例如是收敛到多胞形的顶点还是特定的超平面，主要由价值矩阵的谱特性决定，并从数学上为注意力机制中出现少数主导性“领导者”token的现象提供了理论解释。"
            ]
        },
        {
            "id": "e081371e",
            "title": "专治自动驾驶\"水土不服\" | DG-DETR如何让AI眼力跨越天气鸿沟？",
            "tags": [
                "这篇是关于目标检测领域泛化的论文。该技术利用小波变换将特征分解为领域不变与领域特定两部分，通过仅扰动代表风格的领域特定特征来合成多样化的训练数据，从而在保留目标语义的同时增强模型鲁棒性。同时，它提出了一种领域无关的查询选择策略，通过构建风格表征并利用正交投影从中移除领域诱导的偏差，从而为解码器提供包含更丰富领域不变信息的初始查询。"
            ]
        },
        {
            "id": "7270a7c0",
            "title": "ICML 2025 | 突破SAM 2适配瓶颈！FSSAM 框架凭伪提示生成 + 迭代记忆优化，刷新Few-Shot分割",
            "tags": [
                "这是一篇关于少样本分割的论文，它首次将SAM 2应用于该任务，并通过伪提示生成器将少样本分割里不同身份对象匹配问题转化为SAM 2预训练时所适应的相同身份对象匹配问题。为了优化伪提示的质量，该框架利用迭代记忆精炼模块，通过迭代地从支持集中补充前景特征来完善不完整的前景。最后，一个支持校准记忆注意力模块在特征融合阶段进一步过滤残余的背景特征，以减少分割错误。"
            ]
        },
        {
            "id": "4a9315b9",
            "title": "CNN、ViT、SSM 谁更强？VCMamba 混合架构告诉你 “1+1>2”",
            "tags": [
                "这是一篇关于视觉主干网络的论文，它提出了一种混合分层架构，在早期阶段利用卷积模块提取多尺度局部特征以保留细粒度信息，在后期阶段则利用状态空间模型来高效建模全局依赖。网络的前三个阶段主要采用以深度可分离卷积为核心的卷积前馈网络模块，通过下采样层逐步构建特征金字塔，用以积累丰富的局部空间信息。最后一个阶段的核心是一个多方向Mamba模块，它将二维特征图沿四个不同的空间连续方向展平为一维序列，并独立应用选择性扫描机制进行方向感知的状态更新，最后聚合多方向的输出来捕获全局上下文。"
            ]
        },
        {
            "id": "a46f904a",
            "title": "ICCV 2025 | Meta LeCun 团队发布DINO-World：基于隐空间仅 1/12 参数量实现SOTA视频预测。",
            "tags": [
                "这是一篇关于视频世界模型的论文，它提出了一个在冻结的DINOv2隐空间中进行操作的框架，通过一个基于交叉注意力的Transformer预测器，来预测未来帧的隐空间特征而非原始像素。该预测器利用旋转位置编码来注入时空坐标信息，并通过动态时间采样和块三角注意力掩码的设计，使其能够适应任意时长预测并进行高效的并行训练。在需要动作条件的微调阶段，该框架会引入一个轻量级的动作适配器模块，该模块仅更新预测器中交叉注意力模块的查询向量，从而在不破坏预训练学到的通用动态知识的基础上融入动作信号。"
            ]
        },
        {
            "id": "71d596b8",
            "title": "即插即用卷积--AKConv",
            "tags": [
                "这篇是深度学习卷积的论文，它提出一种名为AKConv的新型卷积算子，旨在解决标准卷积因采样形状和大小固定而无法适应不同目标形态的局限。该方法的核心是先通过一种新的坐标生成算法来定义任意数量参数卷积核的初始采样位置，再利用一个可学习的偏移量动态调整每个位置的采样形状以响应目标变化。这种机制使得卷积核能具备任意采样形状和大小，并实现了参数数量随卷积核大小线性增长，而不是传统卷积的平方增长。"
            ]
        },
        {
            "id": "d6b45d9b",
            "title": "ICML 2024 | 大小不变性很重要：重新思考不平衡多目标显著目标检测的指标和损失函数",
            "tags": [
                "这篇是显著目标检测的论文，它指出当前评估指标和损失函数存在尺寸敏感性偏差，会因赋予大目标更高权重而忽略小目标。为此，论文提出一种大小不变的评估范式，该范式通过连通域或最小外接矩形将不同目标划分为独立部分，并对各部分指标进行等权重求和来消除尺寸差异带来的影响。进一步地，论文将该范式推广为一种优化框架，通过在训练中自适应地重新加权像素损失，强制模型平等对待所有尺寸的目标，从而缓解尺寸敏感问题。"
            ]
        },
        {
            "id": "f891ed14",
            "title": "TGRS 即插即用 | 小目标也能被看见——SCAM让检测更清晰",
            "tags": [
                "这篇是小目标检测的论文，它在YOLOv5的颈部依次串联了用于扩大感受野的FEM模块、改进多尺度融合的FFM模块以及进行全局上下文建模的SCAM模块。其中的核心SCAM模块利用全局平均池化和最大池化捕获通道上下文，并结合一个简化的自注意力计算来生成空间上下文，再将两者融合以建模全局关系来抑制背景噪声。此外，论文还利用部分卷积对网络进行轻量化，并结合使用归一化高斯瓦萨斯坦距离损失函数来缓解小目标定位的敏感性问题。"
            ]
        },
        {
            "id": "af85b87d",
            "title": "CVPR 2024｜YOLO-World：首个高效实时通用词汇目标检测 YOLO 框架，速度精度双突破！",
            "tags": [
                "这是一篇开放词汇目标检测的论文，它通过提出一种可重参数化的视觉语言融合模块RepVL-PAN，并结合区域-文本对比损失的训练策略，首次将YOLO框架扩展到开放词汇检测任务。该方法在推理时采用“先提示后检测”的机制，将预先编码好的文本词汇重参数化为网络权重，从而移除了对文本编码器的在线依赖。最终，模型能够根据用户输入的任意文本提示进行实时的目标检测，解决了传统YOLO检测器只能识别固定训练类别的问题。"
            ]
        },
        {
            "id": "014660b1",
            "title": "ICIP 2025 | CLIP+LLM 双加持，VocAda 重构开放词汇检测范式！",
            "tags": [
                "这是一篇开放词汇目标检测的论文，它提出了一个无需额外训练的测试时词汇自适应模块VocAda，用于解决用户自定义词汇集存在噪声和误指定的问题。该方法在推理阶段利用大型视觉语言模型为输入图像生成描述，并从中提取名词短语。最后，它通过CLIP相似度或大型语言模型推理，从用户原始词汇表中筛选出与图像内容相关的类别子集，再送入检测器进行检测。"
            ]
        },
        {
            "id": "c3d5935a",
            "title": "论文分享|SAM-COD：SAM引导的弱监督伪装目标检测统一框架",
            "tags": [
                "这是一篇弱监督伪装目标检测的论文，它提出了一个统一框架SAM-COD，利用分割大模型SAM从点、框和涂鸦等多种弱监督标签中生成高质量的伪标签。该框架首先通过提示适配器来兼容不同类型的弱监督输入，然后结合响应过滤器和语义匹配器来筛选和修正SAM的输出，以解决其直接应用时产生的极端响应和语义错误问题。最后，该方法将优化后的分割结果作为教师知识，通过一种提示自适应知识蒸馏策略来训练一个最终的学生模型，从而实现稳定的特征学习与知识迁移。"
            ]
        },
        {
            "id": "614d5497",
            "title": "CLIP为何搞不定分割与检测？哈工大团队开源通用视觉任务新框架：突破开放词汇稠密感知瓶颈！",
            "tags": [
                "这是一篇开放词汇稠密感知的论文，它针对CLIP模型因注意力机制后期偏向背景导致稠密特征缺乏局部判别力的问题，提出一种无监督微调框架。该框架的核心是解耦自注意力模块，从而分别获取用于提升局部判别力的内容特征和用于保持空间相关性的上下文特征。框架通过让内容特征与图像裁剪表征对齐来学习局部细节，并利用视觉基础模型DINO指导上下文特征学习空间关系，以此解决两者之间的优化冲突。"
            ]
        },
        {
            "id": "42fa8acc",
            "title": "YOLOv11的小目标进化之路 | RS-TinyNet通过渐进式融合检测头实现多尺度目标精准定位",
            "tags": [
                "这是一篇遥感图像微小目标检测的论文，它提出了一个多阶段特征融合与增强框架RS-TinyNet。该框架通过一个融合了通道、空间、局部和全局信息的多维协同注意力模块来增强微小目标的显著性，并利用一个辅助可逆分支来缓解主干网络在特征提取过程中的信息衰减。最后，在检测头部分，它采用一种渐进式融合策略，通过逐层对齐相邻层级的特征来减少多尺度特征融合时的语义差距，从而重建特征的完整性。"
            ]
        },
        {
            "id": "8347ae90",
            "title": "PicoSAM2突破侧端分割极限 | 1.22MB模型在IMX500上实现14.3ms实时推理",
            "tags": [
                "这是一篇轻量化图像分割的论文，它提出了一种完全基于卷积神经网络的深度可分离U-Net架构，以规避Transformer模块从而适配资源受限的边缘硬件。该方法通过一种隐式提示编码机制，在训练时裁剪图像使提示点位于中心，让模型学习空间先验，从而在仅有图像输入的情况下响应提示。在训练阶段，模型结合了来自教师模型SAM2的知识蒸馏和基于真实标签的硬监督，并引入动态权重进行平衡，以提升泛化能力。"
            ]
        },
        {
            "id": "be6e7bed",
            "title": "极力推荐-LAYN：用于小目标检测的轻量级多尺度注意力 YOLOv8 网络",
            "tags": [
                "这是一篇轻量级小目标检测的论文，它通过用GhostNet替换YOLOv8的主干网络来减少模型参数和计算量。为了提升小目标检测性能，该方法设计了一种多尺度注意力模块，它利用级联的非对称卷积从空间和通道维度捕捉判别性特征，并抑制无关信息。此外，该方法还引入了Soft-NMS算法来处理密集或重叠小目标的漏检问题，从而进一步提高检测精度。"
            ]
        },
        {
            "id": "a9beac14",
            "title": "TGRS 2025 | 哈工大新突破！LTDNet：轻量骨干 + 可变形卷积头，遥感小目标检测精度与效率双优",
            "tags": [
                "这是一篇遥感图像微小目标检测的论文，它提出了一个轻量级检测网络LTDNet。该网络的核心是一个重新分配了计算资源的骨干网络，它将更多的计算力集中在处理高分辨率特征的早期阶段，以强化对微小目标的细节捕捉。在检测头部分，该方法通过引入可变形卷积来灵活适应微小目标的不规则形状，并结合优化的网络通道数，共同构建了一个在精度和效率上取得平衡的轻量化结构。"
            ]
        },
        {
            "id": "dd9a8ee1",
            "title": "(CVPR 2025) 从5%到100%：Mona如何颠覆视觉模型微调逻辑",
            "tags": [
                "这是一篇关于视觉模型微调的论文，提出了一种名为Mona的适配器调优方法，它在适配器中用多尺度卷积滤波器替代了传统的线性投影，以更适应视觉特征。该方法还在适配器前引入一个带有可学习权重的缩放归一化层，用以动态调整冻结主干网络输出的特征分布。通过结合多尺度卷积与输入归一化，Mona在冻结预训练模型主体参数的同时，旨在提升模型向各类视觉任务的迁移性能。"
            ]
        },
        {
            "id": "06190c40",
            "title": "分割新突破 | GroundingDINO-US-SAM实现文本驱动分割，零样本泛化DSC达72.83%",
            "tags": [
                "这篇多模态图像分割的论文提出一种文本驱动的超声图像分割方案，该方案串联了Grounding DINO和SAM2模型。方案首先利用视觉语言模型Grounding DINO来理解文本提示，并自动为目标器官生成边界框作为空间先验。随后将生成的边界框输入给冻结的SAM2模型以完成最终的精细化分割，其中Grounding DINO通过低秩适配技术进行参数高效微调以适应超声领域。"
            ]
        },
        {
            "id": "f6321dda",
            "title": "（ICCV2025）东南、浙大、百度等提出PropVG：通用视觉定位新标杆",
            "tags": [
                "这篇视觉定位的论文提出了一个端到端的候选框驱动框架，该框架通过可学习查询向量和可变形解码器自主生成前景候选框，从而摆脱了对预训练检测器的依赖。为了实现精准匹配，方案设计了对比式参考评分模块，该模块通过动态融合句子和单词两个粒度的对比分数来计算候选框与文本的相似度。此外，为了解决目标存在性判别问题，方案还引入了多粒度目标判别模块，该模块利用分数先验交叉注意力机制来融合对象级与语义级信息，从而判断目标是否存在。"
            ]
        },
        {
            "id": "c0fff008",
            "title": "DINOv3确实很“类脑”！Meta 深度研究揭示模型、训练与数据的三重影响",
            "tags": [
                "这篇神经AI交叉研究的论文通过系统性地训练一系列改变了模型尺寸、训练量和数据类型的DINOv3自监督模型，并将其内部表征与人脑功能性磁共振成像和脑磁图活动数据进行对比分析。研究发现，模型的类脑程度会随着模型尺寸增大、训练量增加以及使用更具生态有效性的人类中心自然图像而提升。此外，这种类脑特性的涌现过程遵循特定的时空规律，即模型会先与初级视觉皮层对齐，然后才逐渐与高级皮层对齐，这与大脑自身的处理流和发育过程相似。"
            ]
        },
        {
            "id": "86508fc9",
            "title": "DMAT联合框架实现湍流抑制与目标检测双提升，小目标检测精度暴涨15%",
            "tags": [
                "这篇图像复原与目标检测的论文提出了一个名为DMAT的端到端联合框架，该框架将大气湍流抑制和目标检测任务集成在统一架构中。方案中的湍流抑制模块采用基于3D Mamba和可变形卷积的结构来处理时空位移和模糊，而检测器则基于Transformer架构。两个模块通过交换低层恢复特征和高层语义特征实现相互增强，并采用交替训练策略分别进行优化以提升整体性能。"
            ]
        },
        {
            "id": "83fe9af8",
            "title": "【ESWA 2025】震撼！轻量级神器 GS-HalfConv 横空出世：速度飙升，精度爆表，刷新移动端视觉新极限！",
            "tags": [
                "这篇轻量化计算机视觉的论文提出一种通道分组半卷积模块，该模块的核心机制是仅对输入特征图的一半通道执行标准卷积操作，而另一半通道保持不变以保留原始信息并降低计算量。在此基础上，论文进一步设计了门控打散半卷积模块，通过引入通道打散操作来促进跨分组的信息交互，并结合轻量空间混合与全局门控机制增强模型的特征表达能力。这些模块旨在作为视觉骨干网络中标准卷积的高效替代方案，从而在移动端等资源受限场景下实现计算效率与模型精度的平衡。"
            ]
        },
        {
            "id": "1758f2ac",
            "title": "论文分享|NeurIPS2024|PointMamba",
            "tags": [
                "这篇点云分析的论文提出了一个基于状态空间模型的PointMamba架构，该方案首先通过最远点采样筛选关键点，再利用希尔伯特空间填充曲线及其转置变体将无序点云转化为有序序列。接着，方案使用K近邻和轻量网络生成点标记，并设计了一个简单的顺序指示器来区分由不同曲线生成的序列，最后将拼接后的序列送入堆叠的非分层Mamba模块进行全局信息编码。此外，该工作还定制了一种基于序列化掩码的预训练任务，通过重建被遮蔽的点云坐标来增强模型的表示能力。"
            ]
        },
        {
            "id": "4f2a1d50",
            "title": "(AAAI 2025) 轻量级、即插即用的注意力融合模块CMA，涨点启动！",
            "tags": [
                "这篇多模态注意力机制的论文提出了一个名为CMA的跨模态注意力融合模块，该模块将图像特征视为查询，同时将CLIP提取的语义特征视为键和值，通过计算通道维度的注意力图来对语义信息进行加权。加权后的语义信息通过一个可学习的缩放参数与原始图像特征进行残差融合，从而实现了轻量化和即插即用的特性。该模块被嵌入到一个模拟人类视觉系统的双分支架构中，用于结合自底向上的视觉感知与自顶向下的任务语义引导，以实现更精准的注意力预测。"
            ]
        },
        {
            "id": "783e9000",
            "title": "(arXiv 2025) SBSAtt：让Transformer学会分频思考的注意力机制",
            "tags": [
                "这篇注意力机制的论文提出一种光谱分段自注意力模块，该模块首先通过快速傅里叶变换将特征图转换到频域。随后，方案在频域内对特征进行分段，旨在为代表背景纹理的高频分量和代表雨痕等退化信息的低频分量分配不同的注意力权重。这种差分处理使得模型能够抑制低频的退化成分并保留高频的图像细节，最终通过逆傅里叶变换将增强后的特征转换回空间域。"
            ]
        },
        {
            "id": "38808ead",
            "title": "(IEEE 2025) 线性注意力的新突破：推理提速 ×5，精度几乎不掉！",
            "tags": [
                "这篇线性注意力的论文提出了一个即插即用的PnP-Nystra模块，它通过Nyström方法对指数核注意力矩阵进行低秩近似，从而在无需微调的情况下加速预训练恢复模型。具体来说，方案通过窗口均值池化选取一小组地标来构建近似矩阵，并结合稳健的伪逆迭代计算最终输出，从而将二次复杂度降低为线性。"
            ]
        },
        {
            "id": "6b52ecc0",
            "title": "TPAMI | MSA 模块：前景与背景分开看的注意力新范式",
            "tags": [
                "CamoFormer 提出 Masked Separable Attention (MSA) 模块，将注意力头分为前景（F-TA）、背景（B-TA）和全局（TA）三组，分别建模以增强对伪装目标与背景的区分能力。",
                "通过在解码器中引入逐级掩码引导的 MSA 和多级监督机制，模型在多个 COD 基准上显著提升边界分割精度，超越现有 SOTA 方法。"
            ]
        },
        {
            "id": "9c5de015",
            "title": "CNN+ViT完美融合 | DuoFormer 创新多尺度Token化，性能碾压Swin Transformer",
            "tags": [
                "这是一篇计算机视觉领域的论文，它提出DuoFormer模型，通过一种多尺度块Token化方法，将CNN主干网络提取的多阶段特征组装成多尺度Token，以融合CNN的归纳偏置和ViT的全局建模能力。",
                "然后，它引入了一种双注意力机制，包括用于建模单个图像块内部及跨尺度信息交互的局部注意力和关注图像块之间长距离依赖关系的全局注意力。",
                "为此，模型还设计了一个专门的尺度Token，它聚合了CNN不同阶段的多尺度信息，以引导局部注意力并作为全局注意力的输入，从而连接两个注意力模块。"
            ]
        },
        {
            "id": "c611f182",
            "title": "Shape-IOU | 即插即用IOU Loss，YOLO系列亲测涨点",
            "tags": [
                "该目标检测论文提出了一种名为Shape-IoU的损失函数，它在计算传统IoU的基础上，额外引入了对预测框与真实框之间形状和尺度差异的惩罚。",
                "具体而言，该方法设计了一个加权的中心点距离项来度量位置偏差，并设计了一个形状代价项来度量宽高差异。",
                "此外，作者还将这种思想应用于Dot Distance和NWD，提出了专门针对小目标的Shape-Dot Distance和Shape-NWD。"
            ]
        },
        {
            "id": "9bc46808",
            "title": "ICML 2024 | 基于蒸馏的源偏差消除方法用于域自适应目标检测",
            "tags": [
                "这篇域自适应目标检测论文提出了一个基于蒸馏的源偏差消除框架，通过训练一个域无关的分类教师和一个目标相关的定位教师来解决源域偏差问题。",
                "在检测器训练阶段，该方法利用分类教师蒸馏出的域无关知识来指导学生模型，以抑制源偏差。",
                "在测试阶段，该方法利用定位教师网络生成的结合了目标亲和度的定位分数，来调整最终的分类置信度，从而缓解分类与定位之间的不一致性。"
            ]
        },
        {
            "id": "a9269b86",
            "title": "通往超级智能之路！清华&上海AI Lab最新推理模型强化学习超全综述",
            "tags": [
                "这篇是关于强化学习提升大模型推理能力的综述论文，阐述了强化学习从对齐工具转向推理能力塑造核心的范式转变。",
                "其核心技术方案包含三大组件：通过可验证信号进行奖励设计，采用GRPO等无评论者算法进行策略优化，以及运用动态和结构化采样来提升数据质量。",
                "该方案的落地依赖于高质量的训练资源，特别是包含可验证轨迹的静态语料和支持长程交互的动态环境。"
            ]
        },
        {
            "id": "3f9c05dc",
            "title": "YOLOv8优化：注意力魔改 | 一种结合坐标注意力和内卷积的双坐标注意力特征提取（DCAFE），2025年最新发表",
            "tags": [
                "这篇是关于目标检测注意力机制的论文，旨在解决类别间相似度高和类内差异大的问题。",
                "其技术方案为双坐标注意力特征提取模块，该模块并行运用平均池化和最大池化实现坐标注意力，以捕捉长距离依赖关系和位置信息。",
                "该方案还引入了基于内卷积的特征精炼模块，通过串行内卷积层来提炼上下文特征。"
            ]
        },
        {
            "id": "eb25c73b",
            "title": "ACM MM2025 | Dome-DETR: 中科大团队提出遥感微小目标检测新方法, 代码开源！",
            "tags": [
                "这篇是关于遥感目标检测的论文，提出了一种基于密度引导的DETR变体模型用于微小目标检测。",
                "其技术方案首先利用浅层特征预测目标密度图，并以此引导稀疏窗口注意力机制，将计算集中于高密度前景区域。",
                "该方案还根据密度图动态生成数量自适应的目标查询，以适应不同密度场景下的检测需求。"
            ]
        },
        {
            "id": "b0eddf01",
            "title": "（CVPR 2025）轻量化也能很聪明：跨注意力的新玩法",
            "tags": [
                "这篇是低光图像增强的论文，提出了HVI新颜色空间，通过对色调饱和度平面进行极化和使用可学习的强度函数，解决了HSV空间固有的红色不连续与黑平面噪声问题。",
                "论文设计了双分支网络CIDNet，分别在HV色彩分支和I亮度分支上进行处理，并利用光照交叉注意力模块LCA实现颜色和亮度信息的跨分支交互。",
                "整体技术流程首先将图像映射到HVI空间以分离颜色与亮度，接着在HVI空间内使用CIDNet进行增强，最后通过感知反变换将结果映射回原始图像空间。"
            ]
        },
        {
            "id": "935fd9a6",
            "title": "【RL第五篇】信赖域策略优化-Trust Region Policy Optimization（TRPO）",
            "tags": [
                "这篇是强化学习的论文，它通过在策略更新时引入信赖域约束，解决了传统策略梯度方法因步长选择不当而导致性能崩溃的问题。",
                "该方法将策略性能的提升近似为在旧策略状态分布下优势函数的期望，并使用平均KL散度来约束新旧策略的差异，从而在保证单调性能提升的信赖域内进行优化。",
                "最终，该优化问题转化为一个带约束的优化问题，即在KL散度约束下，通过重要性采样利用旧策略的样本来最大化新策略的目标函数。"
            ]
        },
        {
            "id": "a2454604",
            "title": "腾讯、复旦、上海创智学院提出SwiftVideo：首个Continuous-time视频蒸馏加速框架，实现业界最快最高清视频生成",
            "tags": [
                "这篇是视频生成的论文，提出了一个名为SwiftVideo的统一蒸馏框架，旨在通过结合轨迹保持和分布匹配策略，实现少步数下的高质量视频生成。",
                "该框架包含三个核心组件：连续一致性蒸馏，它通过精确的ODE轨迹保持避免了离散化误差；分布对齐，通过在时空维度上进行对抗训练来直接近似真实数据分布，以提升视频细节；轨迹对齐，利用直接偏好优化算法隐式地将低步数推理轨迹与高步数轨迹对齐。",
                "最终，SwiftVideo框架将连续一致性蒸馏和分布对齐作为主要训练阶段，然后通过轨迹对齐进行后训练微调，从而在极少的采样步数下生成高清视频。"
            ]
        },
        {
            "id": "e1233b28",
            "title": "UniConvNet破局 | 三层RFA小核组合重塑AGD，84.2% ImageNet精度碾压SLaK等超大核ConvNet",
            "tags": [
                "这是卷积神经网络架构设计的论文。",
                "提出三层感受野聚合器，通过组合7×7、9×9、1×1等小卷积核扩展有效感受野，同时保持其渐近高斯分布。",
                "基于该模块构建的UniConvNet可作为通用主干网络，适用于从轻量级到大规模的各种模型尺度。"
            ]
        },
        {
            "id": "5d37e8be",
            "title": "(CVPR 2024) SFS-Conv：空间–频率选择卷积助力SAR目标检测",
            "tags": [
                "这是面向合成孔径雷达（SAR）目标检测的轻量化卷积模块论文。",
                "提出SFS-Conv，通过分流–感知–选择策略，在单层内并行提取空间上下文（SPU）与频率纹理（FPU）特征，并以无参数通道选择单元（CSU）自适应融合二者。",
                "基于该模块构建的SFS-CNet在多个SAR检测数据集上实现SOTA性能，同时显著降低参数量与计算开销。"
            ]
        },
        {
            "id": "0485716d",
            "title": "(ICASSP 2025) 小目标检测的秘密武器——ACFM 全局与局部融合新思路",
            "tags": [
                "这是面向医学图像中小目标检测的多尺度融合检测框架论文。",
                "提出ACFM模块，通过并行的全局注意力分支与局部分支（卷积+通道混洗）联合建模长程依赖与局部细节，并引入MSNN实现多尺度特征融合。",
                "基于YOLOv8构建的CAF-YOLO在肺结节和血小板等微小病灶检测任务上显著优于现有方法，尤其提升了细小目标的检测鲁棒性。"
            ]
        },
        {
            "id": "0d2f55c9",
            "title": "哈工大等提出弱监督目标检测新方法：DTH-CP 框架",
            "tags": [
                "这篇弱监督目标检测的论文提出了一个热图引导提案选择器，它利用高低双阈值处理过的热图对提案进行聚类，以生成能够区分相邻实例且覆盖完整的伪真值框。",
                "该方法设计了一个新的弱监督基础检测网络，通过将类别表示重构为包含背景的维度并引入热图预监督，解决了传统网络背景缺失和语义鸿沟的问题。",
                "为了加速网络收敛，该框架还提出一种分类忽略损失，利用被忽略提案中包含的负确定性信息进行监督。"
            ]
        },
        {
            "id": "799b4da7",
            "title": "性能暴涨94%！Gensyn提出SAPO：共享经验重构小模型顿悟RL训练",
            "tags": [
                "这篇强化学习的论文提出了一个去中心化且异步的后训练算法，该算法让每个异构计算节点管理自己的策略模型，同时在网络中相互共享训练轨迹。",
                "通过对网络中共享的轨迹进行采样，该算法能够传播有效的经验以引导和加速小模型的学习过程，从而避免传统强化学习后训练的扩展瓶颈。"
            ]
        },
        {
            "id": "e935e72d",
            "title": "【即插即用模块】注意力篇 | ICCV 2025 | 大核卷积的完美替代！多层中核卷积模块RFA，有效扩大感受野，实现涨点！",
            "tags": [
                "这篇即插即用模块的论文提出了一个感受野聚合器，通过分层叠加中等大小的深度可分离卷积来替代大核卷积，从而在保持高斯分布的同时扩大感受野。",
                "该模块将输入特征沿通道维度拆分，并在一个三层结构中逐步处理，每一层都使用比前一层更大的卷积核来聚合特征。",
                "在每一层内部，模块通过一个注意力分支与价值分支相乘，再将结果与另一路经过局部特征提取的特征进行融合与拼接，最终实现分阶段的感受野扩展。"
            ]
        },
        {
            "id": "d58000a5",
            "title": "【RL第一篇】强化学习入门：核心概念全面详解",
            "tags": [
                "这篇强化学习的入门文章介绍了智能体在环境中根据状态采取动作并获得奖励的核心交互过程。",
                "智能体的目标是学习一个从状态到动作的策略映射，以最大化由一连串奖励构成的长期回报。",
                "文章还讲解了状态价值函数和动作价值函数，它们分别用来评估某个状态或在特定状态下执行某个动作的预期价值。"
            ]
        },
        {
            "id": "92dcd626",
            "title": "【RL第二篇】从策略梯度（Policy Gradient Algorithms）到REINFORCE算法原理详解",
            "tags": [
                "这篇强化学习的论文讲解了策略梯度算法，它通过对策略参数求导来直接优化策略，并使用蒙特卡洛方法采样完整轨迹来估计回报的期望。",
                "基础的REINFORCE算法因为在计算梯度时，让每一步的动作都乘以整个轨迹的总回报，所以会引入很大的方差。",
                "为了降低方差，该算法引入了两个改进，一个是只使用从当前时间步开始的未来回报，另一个是减去一个回报基线来衡量动作的相对好坏。"
            ]
        },
        {
            "id": "9448eb4f",
            "title": "(Elsevier 2025) DCAFE 模块：解决复杂背景下的精细识别新利器",
            "tags": [
                "这篇细粒度识别的论文提出了一个双坐标注意力特征提取模块，该模块通过平均池化和最大池化两个并行分支，独立地在水平和垂直方向上编码位置敏感的长程依赖。",
                "该模块将两个并行分支生成的注意力结果相加，从而使网络能够同时关注特征的全局上下文和局部显著细节。",
                "其整体网络还将此注意力模块与基于动态卷积核的特征精炼模块串联，以自适应地强化对目标的细粒度特征表达。"
            ]
        },
        {
            "id": "d29938da",
            "title": "(arXiv 2025) DiffAttention：轻量级注意力增强的新范式",
            "tags": [
                "这篇是多模态的论文，提出一种差分注意力机制并将其应用于CLIP，通过在每个注意力层学习两组互补的注意力分布并进行相减，来抑制无关特征并聚焦于关键信息。",
                "具体实现上，该方法将查询和键投影各自分为两半以计算出两组注意力图，然后用第一组注意力图减去一个可学习标量加权的第二组注意力图，从而得到最终的差分注意力权重。",
                "作为一个可插拔模块，该机制可以只应用于视觉编码器，同时其加权标量也可以通过动态方式初始化。"
            ]
        },
        {
            "id": "53acdce1",
            "title": "IROS 2024 | SDTrack:用于视觉跟踪的空间解耦跟踪器",
            "tags": [
                "这篇是视觉目标跟踪的论文，提出一种空间解耦跟踪器，通过将解码器中的交叉注意力模块拆分为独立的分类和定位两个分支，来解决不同任务间的特征冲突问题。",
                "为支持该解耦结构，该方法设计了一个查询选择模块以生成任务特定的查询，并引入框到像素的相对位置偏移项引导分类分支关注物体显著区域而定位分支关注边界。",
                "此外，该方法还提出一种任务对齐损失，用于缓解高分类置信度与精确定位之间的不一致性，从而提升跟踪性能。"
            ]
        },
        {
            "id": "647a8b84",
            "title": "无GPU也能打 | CPU-only改进ConvNeXt-Tiny融合GAGM/SEVector夺89%MRI精度",
            "tags": [
                "这篇是医学图像分类的论文，提出一种基于改进ConvNeXt-Tiny架构的轻量级方法，通过融合双全局池化策略和轻量级通道注意力机制来增强特征提取能力。",
                "具体实现上，该方法将全局平均池化与全局最大池化的特征进行拼接，再通过一个简化的Squeeze-and-Excitation模块自适应地调整通道权重。",
                "此外，该方法还引入一种特征平滑损失函数，在训练中动态计算类中心并约束类内样本与其中心的距离，以提升特征空间的判别性。"
            ]
        },
        {
            "id": "8131ec79",
            "title": "端到端网络架构CLIP-VG开源：简单高效实现CLIP到视觉定位任务的无监督和全监督迁移",
            "tags": [
                "这篇是视觉定位的论文，提出一种自步课程自适应方法，通过利用伪语言标签将预训练的CLIP模型迁移到下游定位任务。",
                "具体实现上，该方法先训练一个初始模型作为可靠度评估器来为伪标签打分，再通过贪心样本选择策略，以由易到难的方式逐步采样可靠的伪标签来训练定位模型。",
                "该方法进一步扩展到多源场景，通过评估特定源可靠度和跨源可靠度，并结合源难度排序，渐进式地从多个伪标签源中选择样本，以平衡可靠性与多样性。"
            ]
        },
        {
            "id": "6d69e6b4",
            "title": "DINOv3杀疯了！实时检测迎来新王DEIMv2，重磅革新实现ViT主干极致轻量化，YOLO迎来最强挑战者！",
            "tags": [
                "这篇是实时目标检测的论文，提出一种空间调谐适配器，以解决视觉基础模型单尺度输出与检测任务所需多尺度特征之间的矛盾，从而将其语义表征能力引入实时检测框架。",
                "该适配器通过无参数的双线性插值将视觉转换器不同块的单尺度特征上采样，并并行地通过一个轻量级卷积网络提取图像的细粒度多尺度细节，最后将两者融合以生成用于检测的多尺度特征。",
                "此外，该方法还通过采用高效激活函数和归一化层来简化解码器结构，并引入对象级的复制混合数据增强策略来强化训练过程中的监督信号。"
            ]
        },
        {
            "id": "1cd2a5a6",
            "title": "DeCLIP：让AI像人类一样\"看懂\"世界的革命性技术",
            "tags": [
                "这篇是开放词汇密集感知的论文，为解决CLIP模型深层注意力涣散的问题，提出一种将视觉特征学习解耦为内容和上下文两个独立路径的方法。",
                "内容路径通过自蒸馏技术，对比图像块与整体特征来强化模型对局部细节的判别能力。",
                "上下文路径则在一个视觉基础模型的监督下，重构注意力计算以专注于学习物体间的空间相关性，从而更好地理解全局布局。"
            ]
        },
        {
            "id": "9b20a62e",
            "title": "(DSP 2025) HPA：结合平均池化与最大池化的注意力新思路",
            "tags": [
                "这篇是高光谱图像分类的论文，提出一种并行双分支卷积模块来分别提取光谱与空间特征，并设计了一种混合池化注意力模块来增强特征表达。",
                "其核心的混合池化注意力在水平和垂直方向上同时利用平均池化与最大池化来捕获长程依赖，从而实现跨空间和跨通道的信息交互与加权。",
                "此外，该方法还在后续的变换器编码器之间引入跨层特征融合模块，通过级联与自适应融合来整合多层特征，以缓解深层信息丢失问题。"
            ]
        },
        {
            "id": "26e31209",
            "title": "YOLOv11-KW-TA-FP | KernelWarehouse×三重注意力×FP-IoU，让小目标mAP50飙至86.4%",
            "tags": [
                "这是一篇目标检测与分割领域的论文，提出了一种基于YOLOv11n的混凝土裂缝检测模型。",
                "该模型在主干网络中使用动态卷积核仓库增强特征表示，并在特征金字塔中融入三重注意力机制来聚焦关键裂缝信息。",
                "此外，它还设计了一种新的损失函数，通过自适应惩罚与非单调注意力层来优化边界框的回归定位。"
            ]
        },
        {
            "id": "bd205531",
            "title": "E-ConvNeXt | CSPNet重构ConvNeXt，0.9G FLOPs斩获78.3% ImageNet Top-1",
            "tags": [
                "这是一篇关于轻量级卷积神经网络的论文，它通过重构ConvNeXt网络来解决其在轻量化场景中计算复杂度高的问题。",
                "该方法将跨阶段局部网络（CSPNet）思想与ConvNeXt相结合，并通过引入过渡超参数和调整阶段比例，降低了网络复杂度和参数量。",
                "为进一步提升性能和效率，论文优化了网络初始的Stem结构以减少信息丢失，并使用批量归一化（BN）全面替代层归一化（LN）来加速推理。",
                "同时，论文使用带归一化层的通道注意力机制替换了原有的Layer Scale，以增强模型的特征表达能力并稳定训练过程。"
            ]
        },
        {
            "id": "24329bf6",
            "title": "告别均匀Query！CrowdQuery如何让Deformable DETR在拥挤人群里多检出2.3%？",
            "tags": [
                "这是一篇目标检测领域的论文，它提出了一种名为CrowdQuery的通用查询引导模块，旨在解决拥挤场景下传统均匀分布查询的检测难题。",
                "该方法的核心是扩展了密度图的定义，不仅使用物体位置，还创新性地融入了每个边界框的尺寸信息，以更准确地表征物体的空间占用和形状。",
                "接着，模块会预测这种信息更丰富的密度图，并通过交叉注意力机制将其与解码器中的对象查询进行交互，从而生成能够感知拥挤区域的密度引导查询。",
                "这种将密度信息作为先验知识来指导查询生成的思路，统一了二维和三维的拥挤人群检测任务，并且可以作为一个通用模块集成到多种基于Transformer的检测器中。"
            ]
        },
        {
            "id": "85d669bf",
            "title": "NeurIPS2025 | 视频定位还在靠标注？用MLLMs把零样本Video Grounding做到新高度",
            "tags": [
                "这是一篇多模态视频定位领域的论文，它挖掘多模态大模型进行零样本时空视频定位的潜力，其核心思路是将复杂的文本查询分解为空间属性和时间动作两个子任务。",
                "针对空间和时间子查询，该方法分别设计了一种logit引导的重注意力机制，通过优化可学习的视觉提示，迫使模型将注意力聚焦到与文本线索对应的关键视觉证据上。",
                "为了解决动态视频中定位不稳定的问题，该框架还提出了一种时间增强组装策略，利用帧反转等数据增强方式来提升空间定位在时间维度上的一致性和鲁棒性。"
            ]
        },
        {
            "id": "95fa2ae0",
            "title": "NeurIPS2025 | UniPixel：打通像素级视觉推理，统一目标指代与分割的多模态新范式",
            "tags": [
                "本文介绍多模态大模型中像素级视觉理解任务的统一方法。",
                "UniPixel通过三个核心模块实现指代与分割的统一，分别是Prompt Encoder将点框掩码等视觉提示编码为LLM可处理的令牌，Object Memory Bank存储目标ID与时空掩码的映射关系并解耦区域理解与掩码预测，Mask Decoder基于SAM2.1从LLM的SEG令牌特征生成时空掩码。",
                "训练采用三阶段策略，先预训练稀疏提示编码器，再对齐LLM与掩码解码器，最后联合优化全模型，损失函数包含语言建模损失和掩码预测的焦点损失骰子损失以及IoU预测损失。"
            ]
        },
        {
            "id": "2b0d46c0",
            "title": "超越YOLOv7-X！TACR-YOLO用坐标+任务双注意力，PABD数据集飙至91.92%mAP",
            "tags": [
                "目标检测领域提出TACR-YOLO用于特殊场景异常行为识别。",
                "在YOLOv7-X骨干上植入坐标注意力以解耦通道与空间响应强化小目标感知，并通过基于DY-ReLU-A的任务感知注意力自适应区分分类和回归特征。",
                "系统采用多分支增强Neck实现精细多尺度融合，结合K-means更新先验框、DIoU-Loss优化回归，并构建覆盖手机吸烟饮酒面部等类别的PABD数据集支撑针对性训练。"
            ]
        },
        {
            "id": "12b2cac6",
            "title": "(ICCV 2025) ConvAttn：用卷积“假扮”自注意力的高效替代方案",
            "tags": [
                "这篇是图像超分辨率领域的论文。",
                "论文提出ConvAttn模块，通过共享的13×13大卷积核模拟自注意力的长距离依赖建模，同时使用每层独立的动态卷积核捕获输入自适应加权特征。",
                "基于不同层间自注意力特征高度重复的发现，仅在每个ESC Block首层保留自注意力，后续层全部替换为ConvAttn，并引入Flash Attention降低显存占用。",
                "ConvAttn避免构造注意力矩阵的二次复杂度，使用动态卷积核通过自适应平均池化和两层卷积网络生成输入相关的权重，与静态大核卷积结果相加实现全局和局部特征融合。"
            ]
        },
        {
            "id": "48bac209",
            "title": "告别冗余视觉Token | CoViPAL在LLaVA-OneVision上剪枝75%仅掉1.6%，完胜FastV",
            "tags": [
                "这是一篇关于大型视觉语言模型的论文，提出了一种名为CoViPAL的分层上下文化视觉Token修剪方法，通过一个即插即用的分类器模块在视觉Token进入大语言模型前进行剪枝。",
                "该方法的核心是一个放置在大语言模型前的轻量级分类器，它会结合文本上下文为每个视觉Token计算重要性分数，并根据预设比例移除分数较低的冗余Token。",
                "其训练过程分为两个阶段，第一阶段利用大语言模型深层中的累积注意力权重作为监督信号，来训练分类器对Token重要性进行初步判断。",
                "第二阶段则引入了剪枝操作的可微分近似，并采用对比风格的正则化目标进行端到端训练，以拉大重要与不重要Token的预测分数差距。"
            ]
        },
        {
            "id": "725ee1b4",
            "title": "告别昂贵SFT！ReVPT用GRPO让3B/7B模型自如调用目标检测等工具，CV-Bench飙升9%",
            "tags": [
                "这是一篇关于多模态大语言模型工具使用的论文，提出了一种名为ReVPT的强化学习框架，旨在训练模型调用目标检测等视觉工具进行推理。",
                "该方法首先进行冷启动阶段的监督微调，使用高质量的合成工具使用轨迹数据，为模型提供初始的工具调用能力。",
                "随后进入强化学习阶段，通过GRPO算法和基于答案正确性与格式规范性的二元奖励信号，来优化模型的工具选择和推理策略。"
            ]
        },
        {
            "id": "a33934d9",
            "title": "(AAAI 即插即用) 轻量全局建模神器——sMLP Block的原理与优势",
            "tags": [
                "这是一篇关于图像识别的论文，提出了一种名为sMLP的轻量化全局建模模块，作为自注意力机制的替代方案。",
                "该模块通过沿特征图的水平和垂直方向分别应用独立的线性投射层来捕获长距离依赖。",
                "然后将这两个方向处理后的特征与原始输入特征进行拼接，并使用一个融合层将通道维度恢复至原始大小。"
            ]
        },
        {
            "id": "cf5099ea",
            "title": "(ACM MM 2025) Dome-DETR：用密度引导的小目标检测新范式",
            "tags": [
                "这是一篇关于小目标检测的论文，提出了一种名为Dome-DETR的密度引导检测框架。",
                "该方法首先通过一个密度焦点提取器从浅层特征中预测密度热图，然后利用该热图对窗口注意力进行稀疏化，仅在高密度前景区域内计算注意力。",
                "同时，一个渐进式自适应查询初始化模块根据密度图来动态调整查询的数量和位置，并实现了密度感知的非极大值抑制。"
            ]
        },
        {
            "id": "5ee70fcb",
            "title": "IDEA提出Rex-Omni：将目标检测变为“下一个点预测”，零样本性能超越DINO",
            "tags": [
                "这是一篇关于目标检测的论文，提出了一个名为Rex-Omni的多模态大语言模型，它将目标检测任务重新定义为下一个点预测任务。",
                "该模型将图像坐标空间量化为离散值，并为每个值分配一个特殊token，从而将边界框表示为一个由四个坐标token组成的序列。",
                "训练过程分为两个阶段，先通过监督微调掌握坐标预测能力，再利用GRPO强化学习方法提升框体精度并抑制重复预测等问题。"
            ]
        },
        {
            "id": "f077deff",
            "title": "Mamba-3惊现ICLR 2026！引爆AI圈",
            "tags": [
                "这是一篇关于序列建模的论文，提出了状态空间模型Mamba架构的第三代版本。",
                "该模型采用梯形积分法则进行更精确的状态离散化更新，并引入复数隐藏状态以捕捉序列中的周期性模式。",
                "此外，模型还采用了多输入多输出的结构，允许在每个时间步并行处理多个信号，以提升硬件计算效率。"
            ]
        },
        {
            "id": "bc20cb06",
            "title": "MiniCPM-V 4.0 开源：高效多模态小钢炮，手机上跑出GPT-4V性能新标杆！",
            "tags": [
                "这是一篇关于多模态大语言模型的论文，介绍了一系列名为MiniCPM-V的高效轻量级模型，旨在实现GPT-4V级别的性能并部署于手机等边缘设备。",
                "模型采用自适应视觉编码策略，将高分辨率图像切片处理后，通过一个交叉注意力压缩模块显著减少视觉令牌数量以降低计算成本。",
                "其训练采用渐进式多模态学习策略，包含预训练、有监督微调，以及利用基于AI反馈的强化学习进行对齐以抑制模型幻觉。",
                "为实现高效的端侧部署，模型整合了四比特量化、顺序加载视觉与语言模块的内存优化以及针对目标设备的编译优化等技术。"
            ]
        },
        {
            "id": "d5311ca8",
            "title": "梯度爆炸终结者：ViT-22B训练稳定性秘诀+ViTUnet图像生成首秀，全面力压ViT",
            "tags": [
                "这是一篇关于大规模视觉模型的论文，探讨了ViT-22B的训练稳定性及其在图像生成领域的应用。",
                "该方法向模型的并行线性网络中引入归一化层，以解决训练过程中的梯度爆炸问题。",
                "论文提出了名为ViTUnet的图像生成架构，该架构采用编码器-解码器结构，并在解码阶段结合Transformer模块与CNN残差连接来重建图像。",
                "此外，作者在相同的优化器、训练周期和数据增强条件下从头训练了ViT和ViT-22B模型，以进行客观的性能比较。"
            ]
        },
        {
            "id": "6d349408",
            "title": "CVPR | InceptionNeXt：重新定义大核卷积的速度与性能平衡",
            "tags": [
                "这是一篇关于大核卷积的论文，提出了一个名为InceptionNeXt的模块，用于高效替代大核深度可分卷积。",
                "该模块将输入特征沿通道维度分解为四个并行分支，分别应用小尺寸方形卷积、两个正交的一维条形卷积以及一个恒等映射。",
                "所有并行分支的输出特征最终在通道维度上被拼接在一起。"
            ]
        },
        {
            "id": "7bb464d5",
            "title": "小目标远距离全搞定 | SBP-YOLO融合NWD蒸馏，用139 FPS碾压YOLOv11",
            "tags": [
                "这篇是目标检测领域的论文。",
                "论文提出SBP-YOLO模型，引入轻量级高效检测头LEDH降低P2检测层的计算开销，同时在骨干网络和颈部网络应用GhostConv模块实现高效特征提取，并集成VoVGSCSPC模块增强多尺度特征表示。",
                "训练策略整合NWD损失函数用于小目标精确定位，采用BCKD进行知识蒸馏从教师模型迁移知识到学生模型，使用Albumentations数据增强模拟运动模糊、光照变化和恶劣天气条件。",
                "GhostConv通过标准卷积生成内在特征图再经深度卷积扩展为完整特征集，VoVGSCSPC采用跨阶段设计将输入分为卷积层后接GSBottleneck和深度卷积残差两个分支，LEDH使用解耦架构包含分类和"
            ]
        },
        {
            "id": "d414f87c",
            "title": "CVPR | Single-Head Attention：去掉多头，速度翻倍的新一代轻量注意力机制",
            "tags": [
                "这篇是视觉Transformer领域的论文。",
                "论文提出SHViT模型，采用16×16大步长patchify stem和3-stage结构减少早期token冗余，使用Single-Head Self-Attention仅对部分通道进行单头注意力计算而剩余通道保持不变。",
                "架构前期利用深度卷积提取局部特征，后期在部分通道上执行单头自注意力获取全局信息，通过Inverted Residual Block进行stride-2分层降采样，SHSA中使用LayerNorm其余层使用BatchNorm和ReLU。",
                "SHSA模块将输入张量按通道分割为两部分，对第一部分通过GroupNorm预归一化后生成query、key、value并计算注意力权重，将注意力输出与第二部分保留的卷积特征拼接后通过投影层输出。"
            ]
        },
        {
            "id": "7108195f",
            "title": "3B参数的视觉全能王！IDEA最新开源：一个模型支持十多种视觉任务！零样本检测、OCR、关键点全拿下",
            "tags": [
                "这篇是多模态大语言模型领域的论文。",
                "Rex-Omni将所有视觉任务统一为自回归生成坐标点序列，通过输出左上角和右下角两个点实现目标检测，通过先输出中心点再输出边界框实现对象指代。",
                "采用两阶段训练流程，第一阶段在2200万数据上进行监督微调教会模型基本坐标预测能力，第二阶段进行基于GRPO的强化学习改进几何感知和行为一致性。"
            ]
        },
        {
            "id": "692d3a60",
            "title": "APC框架：跨域行人/目标重识别mAP提升15%+，刷爆6大数据集！",
            "tags": [
                "这篇是目标重识别领域的论文。",
                "论文提出APC框架，构建包含S个共享属性提示的语义属性字典SAD，每个提示由L个可学习令牌构成并通过正交损失强制不同属性在特征空间保持差异，提示组合模块PCM根据视觉特征计算余弦相似度筛选Top-K个相关属性提示，通过两层交叉注意力实现视觉特征与属性提示的动态融合。",
                "采用快慢训练策略FSTS，快速更新流FUS采用常规学习率快速捕捉ReID任务特异性特征，慢速更新流SUS采用指数移动平均策略更新参数保留VLM泛化能力，通过身份原型引导机制让FUS从SUS泛化能力中受益。",
                "总损失函数包含身份损失基于交叉熵实现身份分类，三元组损失拉近同一身份特征距离拉远不同身份特征距离，正交损失平衡属性多样性与其他任务损失。"
            ]
        },
        {
            "id": "5a07ef9a",
            "title": "NeurIPS2025 | ProDA刷新动作识别mAP，解锁多动作场景分析新高度",
            "tags": [
                "这篇是视频动作识别领域的论文。",
                "论文提出ProDA框架，将视频转换为时空场景图SSG后通过动态Prompt模块DPM生成与视频内容关联的动作Prompt，DPM根据节点特征和动作规格向量动态计算候选Prompt权重并注入节点特征，同时在指定动作Prompt中注入干扰动作避免模型依赖标签捷径。",
                "视频图解析神经网络VGPNN通过Link-Message-Update三步从完整SSG中解析出指定动作子图，Link阶段用MLP和自注意力编码器建模跨帧节点交互，Message阶段根据交互特征生成动态权重过滤无关交互，Update阶段将消息注入原始节点特征并用MLP融合得到更新后的节点特征。",
                "视频图归一化VGNorm通过实时计算帧级均值并动量更新全局均值实现时序一致性，同时引入可学习的均值缩放因子保留不同视频间的差异性。",
                "动作解耦损失AD Loss包含解耦损失通过最小化指定动作特征和剩余动作特征的Pearson相关系数确保特征独立性，重构损失通过融合解耦特征并用重构网络恢复原始特征确保信息完整性，总损失结合解耦损失、重构损失和对指定动作、剩余动作、融合动作分别计算的二分类交叉熵损失。"
            ]
        },
        {
            "id": "2a2cfda1",
            "title": "YOLO26学界首评：四大革新点究竟有多强？",
            "tags": [
                "这篇是目标检测领域的论文。",
                "YOLO26移除分布式焦点损失DFL模块将边界框预测回归到直接回归任务简化模型结构，通过重新设计预测头实现端到端无NMS推理直接输出无冗余检测框。",
                "引入ProgLoss在训练过程中动态调整不同损失成分权重防止模型过拟合，STAL标签分配策略在训练时优先考虑像素占比小的目标增强小目标识别能力。",
                "采用MuSGD混合优化器结合传统SGD鲁棒性和Muon优化器自适应特性实现更快更稳定收敛，支持导出为ONNX、TensorRT、CoreML、TFLite和OpenVINO格式并支持INT8量化或半精度FP16部署。"
            ]
        },
        {
            "id": "a2525889",
            "title": "TopKD革新蒸馏：Top-K缩放+解耦余弦损失，ResNet/ViT通杀，性能全面超越DKD/CRD",
            "tags": [
                "这篇是知识蒸馏领域的论文。",
                "论文提出TopKD框架，采用对比损失替代KL散度作为主要损失函数，通过拉近相同样本的logits推远不同样本的logits实现教师学生表示之间的关系模式对齐。",
                "Top-K缩放模块TSM通过增加Top-K预测的值强调其影响，当教师Top-1预测错误时对真实标签的logits应用更大的缩放因子纠正教师输出偏差，缩放因子与排名相关并包含与Top-K和Non-Top-K logit平均差异成比例的偏差项。",
                "Top-K解耦损失TDL基于教师logits的符号和幅度将全局余弦相似度解耦为Positive Top-K、Negative Top-K和Non-Top-K三个分量，通过实例级对比损失强制学生和教师预测在批次维度保持一致，同时通过余弦相似度损失保持实例内语义一致性并优化嵌入空间中的优化方向。"
            ]
        },
        {
            "id": "d66b23a9",
            "title": "标注成本清零？SimCLR驱动YOLO主干，让YOLOv5/8在低标注场景狂飙mAP与召回率",
            "tags": [
                "这篇是自监督学习与目标检测领域的论文。",
                "论文提出Self-Supervised-YOLO框架，采用SimCLR对比学习方法在COCO无标签数据集上预训练YOLOv5和YOLOv8的主干网络，将主干网络截断至最后卷积特征图后通过全局平均池化获得单个特征向量，再输入两层MLP投影头产生用于对比损失的潜在嵌入。",
                "预训练阶段对每张图像进行随机强增强生成两个视图，通过NT-Xent对比损失鼓励同一图像的嵌入相似并将不同图像的嵌入分离，采用批大小256和余弦学习率调度训练200个epoch。",
                "微调阶段将预训练的主干网络权重加载到完整YOLO架构中，对主干网络层应用较低学习率为基础学习率的0.1倍避免预训练特征不稳定，允许整个模型端到端训练并在短暂预热后统一学习率继续训练。"
            ]
        },
        {
            "id": "049dfd07",
            "title": "中科院SNELLA：视觉模型微调新范式，性能超越SOTA，内存占用降低近40%",
            "tags": [
                "这篇是参数高效微调领域的论文。",
                "论文提出SNELLA框架，采用核化低秩适应通过两个低秩矩阵经非线性核函数合成稀疏增量矩阵实现权重更新，核函数将低秩矩阵映射到高维空间增强表达能力。",
                "自适应双层稀疏分配机制包含层间竞争和层内竞争，层间竞争根据各层对任务损失的敏感性和不确定性综合评估重要性分数分配参数预算，层内竞争评估所有权重更新的重要性保留得分最高的权重并将其余置零。"
            ]
        },
        {
            "id": "b80cf94d",
            "title": "ICCV 2025 | 天大等提出DMPO：解耦多预测器优化，30%算力超越对手70%性能",
            "tags": [
                "这篇是模型推理效率优化领域的论文。",
                "论文提出DMPO框架，采用轻量级旁路模块在每个阶段保留原始特征用于传递给下一阶段保证基础特征完整性，同时旁路模块处理原始特征生成专门用于当前阶段预测的判别性特征实现特征分离。",
                "高阶统计预测器在早期阶段捕捉特征的二阶统计信息如协方差从浅层特征中挖掘判别信息提升早期预测准确率。",
                "两阶段解耦优化策略通过动态调整损失权重实现，第一阶段训练初期给浅层预测器分配较小权重保证模型代表性能力，第二阶段逐步增大浅层权重激励模型加强判别性能力让更多样本提前退出。"
            ]
        },
        {
            "id": "786af667",
            "title": "MoR-ViT打破ViT参数冗余魔咒 | token级动态递归对决DynamicViT，70%裁参2.5倍提速",
            "tags": [
                "这篇是视觉Transformer模型压缩领域的论文。",
                "论文提出MoR-ViT框架，采用轻量级路由器在每个递归步骤为每个token计算门控分数，通过在自适应百分位数处对门控分数进行阈值处理构建二进制掩码实现动态token选择，路由分数高的token继续递归处理而低分token提前退出。",
                "实现专家选择和Token选择两种路由方案，专家选择在每次递归中采用分层top-k token选择，Token选择在开始时为每个token分配固定递归步骤。",
                "引入参数共享机制仅缓存被选择token的键值对用于后续自注意力计算，训练目标由标准任务损失和路由正则化项组成通过权衡系数平衡两者。"
            ]
        },
        {
            "id": "7af36435",
            "title": "突破360°跟踪极限！OmniTrack++：全景MOT新范式，HOTA指标狂飙43%",
            "tags": [
                "这是一篇多目标跟踪领域针对360度全景图像的论文，提出OmniTrack++框架解决全景相机中的图像畸变和目标身份丢失问题。",
                "通过DynamicSSM模块基于状态空间模型隐式调整特征分布来处理全景图像的几何畸变和光照变化，使模型学习到稳定的特征表示。",
                "设计FlexiTrack Instances融合目标外观信息和历史轨迹动态信息实现短时关联，同时引入ExpertTrack Memory模块采用专家混合设计维护长期稳定的身份记忆和动态交互记忆来解决长期遮挡后的身份重识别。",
                "采用双分支适配器在TBD和E2E两种跟踪范式之间动态切换并通过集成模块融合结果，结合轨迹反馈机制缩小搜索范围提高关联准确性。"
            ]
        },
        {
            "id": "eda95e8e",
            "title": "“左右互搏”，提升空间理解！Spatial-SSRL：自监督强化学习让LVLM读懂空间，性能平均提升4.63%",
            "tags": [
                "这是一篇大型视觉语言模型领域的论文，提出Spatial-SSRL自监督强化学习范式来提升模型的空间理解能力。",
                "设计五个预设任务从图像自身挖掘监督信号，包括打乱图块重排训练2D结构理解、翻转图块识别增强局部方向感知、裁剪图块修复实现完形填空能力。",
                "针对RGB-D图像设计区域深度排序任务让模型判断区域远近关系训练3D深度感知，以及相对3D位置预测任务让模型描述区域间方位关系。",
                "采用组相对策略优化算法进行强化学习训练，模型对自监督任务给出答案后根据正确与否获得奖励或惩罚，通过不断试错优化学习空间问题的正确回答方式。"
            ]
        },
        {
            "id": "9939b9da",
            "title": "MobileViCLIP横空出世：55倍速度碾压InternVideo2-L14，移动设备视频文本理解首次超越云端",
            "tags": [
                "这是一篇视频文本多模态理解领域的论文，提出MobileViCLIP模型通过将高效图像文本模型MobileCLIP适配到视频理解任务实现移动设备上的视频文本检索和动作识别。",
                "设计时空结构重参化模块在2D深度卷积层之前构建一维深度卷积层处理时序建模，并在推理时重参化为单个卷积层无需非线性激活和批量归一化来降低延迟。",
                "引入时空注意力模块在条件位置编码之前添加可学习的时序位置编码提供时序位置信息，结合深度卷积生成的条件位置编码实现全局时空表示建模。",
                "采用视频文本对比学习损失函数通过最大化正样本对之间的一致性同时最小化负样本对之间的一致性来学习视频和文本的独立表示，训练时冻结文本分支仅微调视频分支。"
            ]
        },
        {
            "id": "fd236c0f",
            "title": "AAAI 2026 Oral | 中国联通等提出HiMo-CLIP：大幅提升CLIP读懂长难句能力，重新定义多粒度图文对齐",
            "tags": [
                "这是一篇多模态领域的论文，针对CLIP模型在处理长文本时语义层次和单调性缺失的问题，提出了名为HiMo-CLIP的图文对齐框架。",
                "该方法引入层次化分解模块，利用批内主成分分析技术捕捉文本特征的主方向，将长文本动态分解为全局表征和包含核心信息的成分表征。",
                "其提出的单调性感知对比损失函数在标准对齐基础上增加了成分级对齐目标，通过约束完整文本的匹配分数高于核心成分的匹配分数来建立语义递进关系。"
            ]
        },
        {
            "id": "2f4f71a0",
            "title": "让Qwen-VL的检测能力像YOLO一样强？Om AI Lab开源新框架：语言理解与感知定位能力全都要！",
            "tags": [
                "这是一篇多模态目标检测领域的论文，针对视觉语言模型在细粒度定位任务中表现不佳的问题，提出了名为VLM-FO1的框架，将检测范式从坐标生成转变为区域内容感知。",
                "该方法采用两阶段解耦架构，首先利用全能提案网络生成高质量区域候选框，随后通过混合细粒度区域编码器提取特征并将候选框转换为区域Token输入到大语言模型中。",
                "模型引入双视觉编码器结构，结合原始编码器与专为细粒度感知优化的编码器提取特征，通过将边界框预测转化为区域检索任务来避免直接回归数值坐标带来的误差。"
            ]
        },
        {
            "id": "21f304f1",
            "title": "AAAI 2026 | 港科大等利用强大视觉基础模型VFM提升无源目标检测，性能SOTA！",
            "tags": [
                "这是一篇无源目标检测领域的论文，旨在通过引入视觉基础模型来辅助师生自训练框架，解决无源域数据下的特征迁移和判别难题。",
                "该方法提出了双源增强伪标签融合模块，基于熵不确定性动态整合自适应教师模型与检测基础模型的预测输出，生成更可靠的伪标签用于监督学生模型。",
                "框架中包含基于图块权重的全局特征对齐模块以自适应聚焦关键语义区域，同时利用基于原型的实例特征对齐模块通过动量更新和对比损失将实例特征与基础模型空间中的类别原型对齐。"
            ]
        },
        {
            "id": "1ba56160",
            "title": "突破跨模态识别瓶颈！火箭军工程大学提出MFENet：让AI在白天黑夜都能准确识人",
            "tags": [
                "这是一篇可见光红外行人重识别领域的论文，提出了一种多频嵌入网络MFENet，旨在通过频域分析来挖掘身份的本质特征以克服模态差异。",
                "该网络包含高低频调制模块，在频域对低频信息进行滤波去除模态噪声，同时在空间域精细提取高频边缘轮廓特征，并通过频率感知多样性增强模块将频谱划分为多个频段以自适应学习权重。",
                "模型训练采用了跨模态软检索损失函数以优先保证跨模态一致性，配合跨模态排序正则化损失函数引导多分支网络学习多样化的特征组合。"
            ]
        },
        {
            "id": "e7bd2ac6",
            "title": "CVPR | 从RetNet到RMT：MaSA如何为视觉Transformer注入显式空间先验",
            "tags": [
                "这是一篇关于视觉Transformer通用骨干网络的论文。",
                "该方法提出曼哈顿自注意力机制将一维时间衰减扩展至二维空间域，利用曼哈顿距离构建空间衰减矩阵引入显式空间先验，并通过沿水平与垂直轴的分解计算实现全局建模的线性复杂度。",
                "整体架构采用四阶段层次化设计，在前三阶段应用分解注意力而在末级使用完整注意力，同时配合卷积词嵌入起始层、条件位置编码以及基于深度可分卷积的局部上下文增强模块来优化特征表达。"
            ]
        },
        {
            "id": "3d2ac299",
            "title": "无需训练与注意力图，Representation Shift携手FlashAttention实现5.5倍加速",
            "tags": [
                "这是一篇关于视觉Transformer模型加速与高效推理的论文。",
                "该方法提出一种名为表示偏移的非参数化度量指标，通过计算Token在经过神经网络层变换前后的特征向量欧氏距离来量化其信息重要性。",
                "方案主要选取多层感知机模块作为观测对象，依据输入与输出特征的差异幅度筛选关键Token，在无需重新训练的情况下直接移除变化微小的冗余单元。",
                "这种不依赖注意力图的特性使其能与FlashAttention算子深度融合，同时支持将其扩展应用到卷积神经网络的结构化剪枝以及状态空间模型架构中。"
            ]
        },
        {
            "id": "ae0aec62",
            "title": "DINOv3和DINO-X是什么关系？",
            "tags": [
                "这是一篇关于计算机视觉领域中DINOv3与DINO-X模型架构对比及部署实践的文章。",
                "DINOv3本质是基于自监督学习算法的通用视觉特征提取器，而DINO-X则是基于DETR架构构建的端到端目标检测框架。",
                "实践方案通过调用Transformers库加载Grounding DINO模型，利用图像与文本提示词进行零样本推理，并配合置信度阈值过滤完成目标边界框的后处理绘制。"
            ]
        },
        {
            "id": "0446c6a2",
            "title": "ICCV 2025 | 告别海量标注！ConformalSAM 解锁基础模型潜力，半监督分割效率翻倍",
            "tags": [
                "这是一篇关于半监督语义分割领域的论文，旨在通过共形预测解决基础模型生成的伪标签在目标域存在噪声和分布差异的问题。",
                "该方案提出ConformalSAM框架，首先利用目标域少量有标签数据构建校准集，通过计算像素级不一致分数并基于分位数统计确定动态置信度阈值。",
                "在伪标签生成阶段引入类别条件过滤策略，针对不同类别设定特定的筛选标准，优先保留目标类别的预测以克服背景像素的主导影响并生成高质量掩码。",
                "模型训练采用两阶段策略，设计了动态加权损失函数，随着训练进程逐步降低对基础模型校准伪标签的权重，平滑过渡到利用下游模型自身预测进行自主优化的阶段。"
            ]
        },
        {
            "id": "4d97dd77",
            "title": "AAAI 2026 | 港科大&IDEA&华南理工提出T-Rex-Omni：为开放集目标检测器引入“负面提示”，性能提升显著",
            "tags": [
                "这是一篇开放集目标检测领域的论文。",
                "该方案在T-Rex2架构基础上引入负面视觉提示机制，通过对真实标注框进行轻微几何抖动生成正面提示，利用剧烈变换生成负面提示，以此构建统一的视觉提示编码器。",
                "设计了免训练的负向否定计算模块，该模块依据物体与负面提示的相似度对检测结果进行加权惩罚，从而在推理阶段动态校准置信度概率。",
                "训练阶段采用负向否定铰链损失函数，目的是在特征空间中强制拉大正面提示与负面提示嵌入向量之间的距离，并支持用户策划、自动建议及仅正面提示三种推理模式。"
            ]
        },
        {
            "id": "4114464c",
            "title": "MIT何恺明团队新作：让扩散模型回归“去噪”本质，简单Transformer即可实现SOTA性能",
            "tags": [
                "这是一篇扩散生成模型领域的论文，麻省理工学院何恺明团队提出了名为JiT的去噪生成框架。",
                "该方案摒弃主流的噪声或流速预测范式，基于流形假设直接让模型预测低维流形上的干净图像，从而避免在高维空间拟合无结构噪声。",
                "模型架构采用标准的Vision Transformer，不使用分词器、预训练权重及U-Net结构，通过处理像素块直接输出原始图像的预测结果。"
            ]
        },
        {
            "id": "94019f3e",
            "title": "ICCV 2025 Oral | 三星提出DTWSR：Transformer巧解小波频率难题，图像超分告别伪影",
            "tags": [
                "这是一篇单图像超分辨率领域的论文。",
                "该方案提出基于扩散Transformer的小波谱超分框架，通过多级离散小波变换将图像分解，在频率域内利用扩散过程恢复多尺度频率子带信息。",
                "模型采用金字塔令牌化方法，依据低频密集和高频稀疏的特性分别指定不同大小的切片尺寸，在减少令牌数量的同时保持跨层级感受野一致。",
                "设计了包含低频基础解码器和高频细节解码器的双分支结构，利用特定的注意力掩码机制强制模型学习低频与高频子带间的协同表示。"
            ]
        },
        {
            "id": "5000516e",
            "title": "(CVPR 即插即用) 单头自注意力（SHSA）：让Transformer更聪明也更省电",
            "tags": [
                "这是一篇关于轻量级视觉Transformer架构设计的论文。",
                "该方案宏观上构建了三阶段分级网络结构，利用大步长重叠卷积Stem层减少早期Token冗余，并在浅层使用深度可分卷积提取局部特征，深层引入单头自注意力模块处理全局信息。",
                "微观上设计了单头自注意力机制，通过仅对部分通道进行单头计算来消除多头冗余并降低显存访问开销，同时结合倒残差下采样块与混合归一化策略优化推理效率。"
            ]
        },
        {
            "id": "d747b0c2",
            "title": "(ECCV 即插即用) 频率域 × 空间域 = 全局感知！揭秘 Fused Fourier Convolution Mixer",
            "tags": [
                "这是一篇图像去雨领域的论文，提出了一种结合频域建模与先验引导机制的高效Transformer网络结构FADformer。",
                "该模型利用融合傅里叶卷积混合器替代传统自注意力机制，通过在空间域使用多尺度深度卷积提取局部特征，并在频率域执行卷积操作以实现全局特征捕获。",
                "前馈网络部分引入了残差信道先验门控机制，通过计算输入图像的先验特征来引导网络在特征传递过程中增强对结构细节与局部纹理的恢复。",
                "训练阶段采用了频域对比正则化策略，利用雨条纹在频率域的特征差异将负样本信息融入训练，从而提升模型对退化信号的辨识能力。"
            ]
        },
        {
            "id": "f9dc7ebc",
            "title": "MoIIE打破三阶段魔咒 | 模态内外专家混合+两阶段训练，激活5.5B参数反超密集LVLM",
            "tags": [
                "这是一篇多模态大语言模型领域的论文，提出了一种名为MoIIE的混合模态内与模态间专家架构，该结构包含分别专精于语言和视觉的两个模态内专家组，以及一个由两种模态共享的跨模态专家组。",
                "模型通过为图像和文本Token分别设定专用路由器来实现动态路由，允许Token根据特征需求灵活激活对应的模态内专家或共享的跨模态专家，从而兼顾模态特定特征学习与跨模态关联建模。",
                "该方案采用两阶段训练策略替代传统三阶段流程，第一阶段仅预训练连接模块以对齐视觉表征与语义空间，第二阶段结合交叉熵损失与负载均衡辅助损失，对全量参数进行多模态微调与稀疏化联合优化。"
            ]
        },
        {
            "id": "fc6752d3",
            "title": "让Qwen-VL的检测能力像YOLO一样强，VLM-FO1如何打通大模型的视觉任督二脉",
            "tags": [
                "这是一篇多模态大模型领域的论文，提出了即插即用的VLM-FO1框架，旨在通过增强区域感知能力，解决现有VLM模型在精确坐标生成和细粒度定位任务上的瓶颈。",
                "该模型设计了混合细粒度区域编码器，包含并行的双视觉通道，主编码器提取语义信息，辅助编码器采用高分辨率DaViT模型捕捉细节特征，两者融合后形成兼具语义与位置信息的区域表示。",
                "训练过程分为两个阶段，首先仅训练新增模块将区域特征映射至语言空间，随后开放更多参数进行指令微调，在不破坏原有语言理解能力的前提下赋予模型细粒度感知能力。",
                "系统摒弃了直接生成浮点坐标的传统范式，转而采用理解区域内容的策略，通过特征融合与映射机制让大语言模型能够直接处理和推理图像中的具体区域信息。"
            ]
        },
        {
            "id": "99f425bc",
            "title": "Pose-RFT：首个混合动作强化微调MLLM，用HyGRPO超越SMPL回归实现3D人体姿态精准生成",
            "tags": [
                "这是一篇多模态大语言模型领域的论文，提出了一种专为3D人体姿态生成设计的强化微调框架Pose-RFT。",
                "该方法提出HyGRPO混合动作强化学习算法，将连续姿态生成建模为多元高斯分布策略，联合优化离散语言预测与连续姿态参数。",
                "网络结构引入了在人体姿态估计任务上预训练的视觉Transformer作为姿态感知编码器，提取高分辨率姿态敏感特征以增强多模态状态表示。",
                "训练过程引入了空间位置、语义对齐、格式正确性以及文本嵌入相似度等任务特定奖励函数，利用组内奖励归一化指导策略更新以实现精准生成。"
            ]
        },
        {
            "id": "6ca524a0",
            "title": "记忆卡尔曼+运动IoU双剑合璧 | MeMoSORT在DanceTrack刷新SOTA，比TrackTrack再涨1.4%",
            "tags": [
                "这是一篇多目标跟踪领域的论文，提出了一种名为MeMoSORT的实时跟踪框架，旨在解决非线性运动和严重遮挡场景下的状态估计与关联难题。",
                "该模型引入了记忆辅助卡尔曼滤波器，利用神经网络构建记忆更新、状态预测和状态更新三个门控模块，通过拟合非线性函数来补偿传统线性物理运动模型的预测误差。",
                "在关联阶段设计了运动自适应交并比机制，由扩展交并比和高度交并比组成，分别通过扩大匹配空间来抵抗检测器位置偏差以及利用高度特征相似性来区分遮挡目标。",
                "系统还包含一种运动自适应技术，能够根据目标的中心移动速度和高度变化速度动态调整边界框扩展因子和高度权重参数，从而在不同运动模式下自适应优化关联策略。"
            ]
        },
        {
            "id": "39ecd97c",
            "title": "ACCV | 轻量视觉网络的新标配：Local Attention 的高性价比解析",
            "tags": [
                "这是一篇图像超分辨率领域的论文，提出了一种名为PlainUSR的高效轻量级卷积网络，旨在通过结合重参数化卷积、局部注意力机制与通道级U形结构来实现快速图像重建。",
                "该模型利用RepMBConv模块将MobileNetV3的倒残差块在推理阶段重参数化为单一卷积层，从而在保持特征表达能力的同时大幅减少显存访问与激活操作。",
                "网络引入了基于局部重要性的注意力机制LIA，通过构建局部Softmax重要性图与通道门控来实现高效的二阶特征交互，以极低的计算成本增强局部纹理与细节的建模能力。",
                "主干网络采用通道维度的轻量级PlainU-Net架构，在编码阶段逐级分裂通道并在解码阶段利用缓存拼接，推理时通过通道索引替代物理分割以显著降低计算量并加速前向传播。"
            ]
        },
        {
            "id": "e1359f93",
            "title": "打破多语言诅咒 | MetaCLIP 2零样本ImageNet首破81%",
            "tags": [
                "这是一篇关于CLIP模型训练扩展的研究论文，提出了名为MetaCLIP 2的方案，旨在打破“多语言诅咒”，即通过从头开始使用精心策展的全局（英语+非英语）互联网数据训练CLIP模型，同时提升其在英语和非英语任务上的表现。",
                "MetaCLIP 2通过构建覆盖300多种语言的全局元数据、设计基于语言特定阈值的全局数据策展算法以平衡头尾部概念，以及采用包含多语言分词器和按比例扩展训练对的全局训练框架来实现这一目标。",
                "实验结果表明，在最小可行模型容量（ViT-H/14）下，MetaCLIP 2成功打破了多语言诅咒，不仅在零样本ImageNet分类上优于纯英语版本，还在多语言检索和问答等基准测试中创造了新的SOTA，实现了英语与非英语数据的相互促进。"
            ]
        },
        {
            "id": "58922c8c",
            "title": "基础架构的新探索：清华提出Step by Step Network",
            "tags": [
                "这是一篇深度学习网络架构领域的论文，提出了一种名为Step by Step Network的通用骨干网络，通过渐进式学习策略解决深度模型性能停滞的问题。",
                "该方法旨在解决深层残差网络中累积的残差信号稀释输入信息导致的捷径退化问题，以及在固定计算预算下增加深度被迫压缩宽度从而限制特征表达能力的矛盾。",
                "核心机制是将输入特征沿通道维度进行拆分，一部分进入当前子网络处理，其输出结果与剩余的原始特征拼接后送入下一级子网络，形成递归式的窄宽堆叠结构。",
                "这种设计为原始特征通向深层网络开辟了直接通道以保持信号纯净，同时通过多级级联实现了在保持计算量不变的前提下有效增加模型的深度与宽度。"
            ]
        },
        {
            "id": "7fa4c608",
            "title": "Adam的稳+Muon的快？华为诺亚开源ROOT破解大模型训练「既要又要」的两难困境",
            "tags": [
                "这是一个大模型训练优化领域的论文，旨在解决现有正交化优化器Muon在混合精度训练中存在的不同矩阵维度精度不一致以及对梯度噪声过敏的稳定性问题。",
                "该方案提出了自适应Newton-Schulz迭代算法，摒弃了全局固定系数的做法，转而根据网络中每个矩阵的特定长宽维度定制细粒度系数，并通过与模型参数联合优化来确保正交化更新的几何一致性。",
                "针对大规模训练中梯度易受异常值污染的现象，引入了基于L1范数近端算子的软阈值机制，将梯度分解为基础分量与异常分量，通过过滤大幅度噪声并仅对基础分量进行正交化来提升鲁棒性。"
            ]
        },
        {
            "id": "75384bed",
            "title": "万字解析 | 终于等到了Qwen3-VL报告！！！",
            "tags": [
                "这是一篇关于视觉-语言多模态大模型领域的论文，介绍了涵盖密集型与混合专家架构的原生支持超长上下文的Qwen3-VL模型系列。",
                "架构上改进了旋转位置编码为交错式分布以均衡频带，引入DeepStack机制将多层级视觉特征注入语言模型中间层以增强对齐，并采用显式文本时间戳替代绝对位置编码来优化长视频的时序定位与理解。",
                "训练过程采用平方根归一化每token损失来平衡模态贡献，预训练分为对齐、全参数多模态、长上下文及超长上下文适应四个阶段，后训练则通过监督微调、强到弱知识蒸馏以及包含推理与通用任务的强化学习来提升模型性能。",
                "数据工程方面构建了包含合成数据与清洗数据的庞大语料库，针对推理任务设计了非思考型与思考型两种模型变体，利用长思维链数据和工具集成强化学习来增强模型在复杂多模态场景下的决策与执行水平。"
            ]
        },
        {
            "id": "c10e2399",
            "title": "告别专业检测器！LMM-Det开创多模态模型自主检测新时代",
            "tags": [
                "这是一篇关于利用大型多模态模型进行通用目标检测的论文。该方案提出一种不依赖额外检测模块的端到端检测方法，通过半监督学习策略利用专业检测器生成高质量伪标签并与真实标签合并，经非极大值抑制处理后调整训练数据分布以显式提升模型召回率。",
                "模型架构选用高分辨率视觉编码器配合线性投影层及大语言模型，在训练过程中要求模型同时输出边界框坐标以及基于词元概率推导出的置信度分数，从而实现对目标位置和类别的细粒度对齐。",
                "推理阶段摒弃了一次性输出所有类别的传统方式，转而采用类别特定的预测策略，通过多次查询让模型独立输出每个类别的所有目标候选框，以增加推理计算量为代价换取更高的检测覆盖率。"
            ]
        },
        {
            "id": "b3f745d1",
            "title": "CVPR | 从 MobileNet 到 ShuffleNet，TVConv 如何做到 3 倍加速还更准？",
            "tags": [
                "这是一篇计算机视觉领域关于轻量级高效卷积算子设计的论文，提出了一种专为面部识别和医学分割等固定布局任务设计的平移时变卷积TVConv。",
                "该方案引入可学习的亲和图来描述图像的全局空间布局，无需计算昂贵的自注意力矩阵即可捕获像素间的关系从而赋予卷积空间自适应性。",
                "通过权重生成模块根据亲和特征生成位置自适应的深度卷积核，这种权重在推理阶段仅需一次性生成并缓存，从而在保持动态卷积适应性的同时实现静态卷积的高推理效率。",
                "算法本质上执行的是平移时变的深度卷积操作，通过将输入图像块与对应位置生成的权重块进行逐点相乘并求和，解决了传统像素级动态卷积计算量大及图像级动态卷积无法利用跨图像相似度的问题。"
            ]
        },
        {
            "id": "4a3cb465",
            "title": "HQ-CLIP横空出世！10亿参数模型让图像检索性能飙升11.7%",
            "tags": [
                "这是一篇关于利用大型多模态模型进行通用目标检测的论文。该方案提出一种不依赖额外检测模块的端到端检测方法，通过半监督学习策略利用专业检测器生成高质量伪标签并与真实标签合并，经非极大值抑制处理后调整训练数据分布以显式提升模型召回率。",
                "模型架构选用高分辨率视觉编码器配合线性投影层及大语言模型，在训练过程中要求模型同时输出边界框坐标以及基于词元概率推导出的置信度分数，从而实现对目标位置和类别的细粒度对齐。",
                "推理阶段摒弃了一次性输出所有类别的传统方式，转而采用类别特定的预测策略，通过多次查询让模型独立输出每个类别的所有目标候选框，以增加推理计算量为代价换取更高的检测覆盖率。"
            ]
        },
        {
            "id": "1c04617e",
            "title": "多模态效率新突破！北大团队AdaTok框架：以对象级令牌合并，让MLLM只需10%Tokens保持96%性能",
            "tags": [
                "这是一篇多模态大语言模型效率优化的论文，提出了一种基于对象感知表示的自适应令牌压缩框架AdaTok，旨在通过将压缩粒度从补丁级提升到对象级来降低计算负担并减少幻觉。",
                "该方案首先利用分割模型提取图像中的对象掩码，将视觉编码器输出的特征图重塑并上采样至原图分辨率，随后计算每个掩码区域内特征的平均值以合并为单个对象令牌。",
                "压缩后的特征通过多层感知机投影映射到语言空间，模型在训练阶段采用低秩适应技术对投影器和语言模型进行指令微调，以弥补对象级特征与预训练模型之间的语义鸿沟。"
            ]
        },
        {
            "id": "55d453eb",
            "title": "一步也能SOTA！何恺明团队新作iMF：无需蒸馏，直达ImageNet FID 1.72",
            "tags": [
                "这是一篇关于图像生成领域的论文，提出了一种无需教师模型蒸馏即可从零训练一步生成模型的方法Improved Mean Flow。",
                "该方案通过重构训练目标，利用平均速度与瞬时速度的微分关系建立参数化复合函数，并在计算雅可比向量积时使用网络自身的预测值替代真实值，从而将训练过程修正为标准的回归问题。",
                "在网络架构上移除了自适应层归一化模块，转而采用上下文条件机制将条件映射为令牌拼接到图像序列前，并将无分类器引导的比例作为动态输入条件以训练灵活的平均速度场。"
            ]
        },
        {
            "id": "c9762570",
            "title": "WACV | 参数量砍掉 70%，效果反超 3D！这就是 Cross-Slice Attention 的魔力",
            "tags": [
                "这是一篇医学图像分割领域的论文，提出了最轻量的2.5D交叉切片注意力模块CSAM，旨在解决各向异性体积医学图像分割中的参数量与性能平衡问题。",
                "该方案形式化定义了2.5D医学图像分割模型，并引入语义注意、位置注意和切片注意三级机制，逐级捕获体积内部的跨切片全局信息。",
                "切片注意模块结合了低秩高斯分布建模切片级不确定性，以提升模型鲁棒性并减少假阳性。CSAM作为可插拔模块，能适配任意2D CNN架构，在保持低参数量的同时显著提升分割性能。"
            ]
        },
        {
            "id": "0cbe3b22",
            "title": "Elsevier | 比 SENet 更灵！比 CBAM 更准！CPAM 到底强在哪？",
            "tags": [
                "这是一篇针对密集小目标场景的细胞实例分割算法论文，提出了基于YOLOv5改进的ASF-YOLO模型架构。该网络引入了尺度序列特征融合模块SSFF，通过高斯多尺度平滑与3D卷积对主干P3至P5层特征进行尺度对齐与序列化建模，同时配合三元特征编码器TFE分别从大中小三种尺度提取局部细粒度特征。",
                "核心的通道与位置注意力机制CPAM利用一维卷积捕获局部跨通道交互，并结合水平与垂直方向的自适应平均池化生成空间注意力图，以此将全局尺度语义与局部细节特征进行加权融合。",
                "算法在预测端采用EIoU Loss优化边界框回归精度，并集成Soft-NMS策略处理密集重叠区域，配合分割原型分支输出最终的实例掩码结果。"
            ]
        },
        {
            "id": "a289d2bf",
            "title": "TETCI | 卷积不够用了？Transformer Self-Attention 给你全局视野",
            "tags": [
                "这是一篇医学图像分割领域的论文，提出了融合Transformer注意力机制与U-Net架构的TransAttUnet网络。该模型在编码器与解码器连接处引入自感知注意力模块，通过并行计算Transformer自注意力分支与全局空间注意力分支，分别捕获特征图的长程依赖关系及全局空间像素关联。",
                "网络采用了多尺度跳跃连接策略，利用残差或密集连接路径将编码阶段的多层级特征逐步聚合至解码阶段，在逐级上采样过程中动态融合深层语义与浅层细节。",
                "算法通过可学习权重自适应调节双路注意力特征的贡献度，将全局上下文信息与局部空间特征进行加权重组，最终经由常规卷积层输出像素级分割结果。"
            ]
        },
        {
            "id": "aff4a82a",
            "title": "巨节能的ViT | EcoTransformer横空出世！L1距离替代点积，能耗直降61%",
            "tags": [
                "这是一篇关于Transformer模型架构轻量化与节能优化的论文，旨在解决传统缩放点积注意力机制计算量大且能耗高的问题。",
                "该方案提出了EcoTransformer架构，建立注意力机制与空间距离的联系，使用查询向量与键向量之间的距离度量替代传统的点积运算，并通过拉普拉斯核对值向量进行卷积来构建输出上下文。",
                "算法核心在于利用加法和绝对差分运算完全替代了注意力分数计算阶段的矩阵乘法，将相关性评估转化为距离测量，同时支持应用在其它低复杂度架构中以实现线性级别的计算效率。"
            ]
        },
        {
            "id": "870bbaa4",
            "title": "0.1%参数解决大问题：CalAttn模块实现ViT端到端自校准，无需后处理",
            "tags": [
                "这是视觉Transformer概率校准领域的论文，提出CalAttn模块用于实现端到端自校准。",
                "模块利用CLS Token的L2范数作为样本难度指标，范数大对应过度自信样本，范数小对应欠自信样本。",
                "CalAttn由两层MLP构成，将CLS Token映射为实例级温度标量，通过交叉熵加Brier惩罚与主干网络联合训练，在训练和推理阶段都对logits进行温度缩放。",
                "实例级温度替代全局温度缩放，对过度自信样本使用大于1的温度冷却，对欠自信样本使用小于1的温度锐化。"
            ]
        },
        {
            "id": "d2fa731a",
            "title": "【CVPR 2025】最具爆发力模块！GCConv重构卷积范式，让速度与精度双封神，引爆实时视觉新时代！",
            "tags": [
                "这是实时语义分割领域的论文，提出了GCConv金箍棒卷积模块。",
                "模块在训练阶段采用纵向多卷积横向多路径结构增强特征表达，在推理阶段通过卷积重参数化将多路径融合为单一3×3卷积。",
                "训练时的扩张网络作为教师模型，推理时的收缩网络作为学生模型，实现无需外部教师模型的自蒸馏学习。"
            ]
        },
        {
            "id": "4a89b90d",
            "title": "永别了，Tokenizer！何恺明师徒新作，颠覆AI生图技术",
            "tags": [
                "图像生成领域论文提出了一种无需Tokenizer并直接在像素空间建模的纯Transformer去噪生成框架。该方案将原始图像切分为大尺寸像素块并直接通过线性投影将其映射为序列向量输入Transformer架构。",
                "技术核心将去噪任务的预测目标由传统的噪声或流速度转变为原始像素图像。",
                "该机制利用自然图像在像素空间的低维流形分布特性，规避了高维空间处理离散噪声时产生的维度灾难。"
            ]
        },
        {
            "id": "3266bb81",
            "title": "AAAI | 告别昂贵自注意力！Striped Conv让CNN也能看“全局”",
            "tags": [
                "这篇论文属于实时语义分割领域。训练阶段采用辅助分支架构，通过语义信息对齐模块将长程依赖特征迁移至卷积主干，推理阶段则移除辅助分支以实现单路径预测。",
                "核心模块利用水平与纵向条带卷积模拟自注意力操作，通过正交方向的一维卷积核捕获全局上下文，并结合分头机制进行通道重构。",
                "对齐方案涵盖骨干特征投影与共享解码头同步，并应用轻量化金字塔池化模块融合层级特征，利用通道级蒸馏损失约束语义分布的一致性。"
            ]
        },
        {
            "id": "70682228",
            "title": "(ACCV 即插即用) Local Attention：在局部区域做“精准注意力”的高性价比方案",
            "tags": [
                "这篇论文属于图像超分辨率领域。该方案通过重参数化技术将训练时的移动端反转残差结构在推理阶段折叠为单层标准卷积，从而解决深度卷积与逐点卷积产生的内存访问开销问题。",
                "局部重要性注意力机制利用指数加权池化与多层卷积提取特征权重，并配合单通道门控单元对局部纹理进行二阶建模以强化空间细节。",
                "主干网络在训练时通过通道维度的切分与拼接构建层级编码解码结构，推理时则转化为纯净的顺序执行路径，并最终采用子像素卷积层实现图像重建。"
            ]
        },
        {
            "id": "5809c8e1",
            "title": "Mobile U-ViT逆袭nnUNet | 1.39M参数、51 FPS轻量级医学分割新王者，零样本SOTA",
            "tags": [
                "这是一篇医学图像分割领域的论文，提出Mobile U-ViT轻量级模型用于移动端医学图像分割。",
                "编码器采用ConvUtr模块作为分层块嵌入，通过大核深度卷积提取全局特征，再经倒置双点卷积实现通道交互，模拟Transformer的建模模式同时保持轻量化。",
                "引入大核局部全局局部LKLGL模块，先用大核深度可分离卷积聚合局部特征，再通过池化操作减少token数量后用注意力机制进行全局上下文交换，最后用转置卷积在局部重新分配信息流。",
                "解码器采用级联上采样结构并在不同分辨率引入下采样shortcut，用于对齐编码器CNN特征和高层Transformer输出的语义差异，同时使用最大池化下采样来减少背景噪声并锐化边界。"
            ]
        },
        {
            "id": "349f84ca",
            "title": "CLIP遇上扩散模型 | 零样本异常检测新突破，性能碾压WinCLIP 8倍速！",
            "tags": [
                "这是一篇零样本和少样本异常检测的论文，提出CLIPFUSION方法融合CLIP判别模型和扩散生成模型。",
                "基于CLIP的PatchCLIP模块利用块嵌入提供空间先验，通过VV-attention机制提取局部特征，并计算块嵌入与异常文本嵌入的对齐度生成语言引导分数图。",
                "基于扩散的MapDiff模块使用修复Pipeline配合空Mask控制时间步长，从去噪器中间层提取交叉注意力图和特征图，交叉注意力图反映图像位置对异常状态Token的响应强度。",
                "零样本设置下融合CLIP的块嵌入文本对齐分数和扩散模型的交叉注意力图分数，少样本设置下额外加入CLIP图像编码器特征与参考图像特征的对比分数以及扩散解码器特征与参考特征的对比分数。",
                "分类任务通过聚合类别Token与异常文本的对齐度以及交叉注意力图的聚焦程度，分割任务通过融合四个分数图并加权平均得到最终异常分数。"
            ]
        },
        {
            "id": "5cae4733",
            "title": "CVPR | 看似更少，实则更快：Partial Convolution的速度魔法",
            "tags": [
                "这是一篇轻量级神经网络加速的论文，提出Partial Convolution和FasterNet网络。",
                "PConv仅在部分输入通道上执行3x3卷积操作，其余通道直接保留，通过减少冗余计算和内存访问提升FLOPS利用率。",
                "FasterNet Block由一个PConv、两个1x1卷积和残差连接组成，仅在中间1x1卷积后添加归一化和激活函数。",
                "PConv实现时将输入沿通道维度分割成两部分，对第一部分执行3x3卷积，第二部分保持不变，最后在通道维度拼接两部分输出。"
            ]
        },
        {
            "id": "f500efb6",
            "title": "(CVPR 2025) 比 Attention 快，比 SSD 轻：HSM-SSD 的工程级优化思路",
            "tags": [
                "这是一篇视觉状态空间模型用于视觉骨干网络设计的论文。",
                "提出 HSM-SSD 将 SSD 的通道混合从 token 空间转移到压缩的 hidden state 空间，在 hidden state 上完成门控与线性投影后再投影回 token，避免在长序列上重复执行通道投影。",
                "HSM-SSD 先对特征做归一化并展平成序列，通过投影产生状态相关参数并用深度可分离卷积注入局部先验，再用状态空间对偶形式完成 token 到 hidden state 的聚合以及 hidden state 到 token 的回写。",
                "Hidden State Mixer 采用单头结构在 hidden state 侧做门控通道交互与输出投影，结合残差缩放减少多头带来的张量重排与内存访问。",
                "EfficientViM 采用三阶段层级主干，stem 用连续三乘三卷积下采样，block 由归一化、HSM-SSD 全局混合、DWConv 局部建模与轻量 FFN 串联，并在分类头使用多阶段 hidden state 融合将各 stage 的分类 logits 加权汇聚。"
            ]
        },
        {
            "id": "7864ff41",
            "title": "NeurIPS 2025 | SuperCLIP：对比学习加上分类任务，使CLIP更强了！",
            "tags": [
                "这是一篇多模态视觉语言对比学习的论文。",
                "在 CLIP 的图像编码器输出上接入线性分类层，将配对文本标题分词后的词元作为类别标签对图像特征做监督。",
                "训练时联合优化图文对比损失与词元分类损失，使视觉编码器在统一特征空间同时学习句级匹配与词级语义对齐。",
                "分类分支仅增加线性映射，分类损失不依赖批量规模，可作为模块迁移到其他 CLIP 系对比学习框架。"
            ]
        },
        {
            "id": "e9a4ec5c",
            "title": "【浙大等团队】轻量 Adapter 解锁 SAM3 全能力",
            "tags": [
                "这是一篇关于视觉基础模型参数高效微调与图像分割领域的论文。",
                "通过冻结SAM3主干网络参数并在Transformer模块中插入包含独立微调层与共享上采样层的轻量级适配器，在不改变原有架构基础上注入任务特定信息。",
                "模型利用可学习权重对分块嵌入和高频纹理等多种先验特征进行加权组合，引导编码器关注特定结构纹理细节并仅对掩膜解码器与适配器模块进行微调训练。"
            ]
        },
        {
            "id": "1188bb38",
            "title": "继何恺明DyT后，LayerNorm再遭暴击！简单erf函数竟成Transformer新宠",
            "tags": [
                "这是一篇关于Transformer架构优化与无归一化神经网络设计的论文。",
                "研究团队总结了零中心性、有界性、中心敏感性和单调性四大原则，并据此提出基于高斯误差函数的Derf算子来完全替代LayerNorm和DyT。",
                "该算子通过引入可学习的缩放与平移参数对输入进行非线性变换，在消除对数据均值方差依赖的同时引入隐式正则化以提升模型泛化性能。"
            ]
        },
        {
            "id": "6d66c16a",
            "title": "TGRS 2025 | 山东大学×提出HDNet：融合多尺度高频信息增强的混合域红外小目标检测网络",
            "tags": [
                "这是一篇关于红外小目标检测领域的论文，提出了一种融合空间域感知与频率域滤波的混合域网络架构。",
                "空间域采用多尺度空洞对比卷积模块，利用并行且具有不同核尺寸和空洞率的分支计算中心目标与周围背景的像素差值，在保持分辨率的同时增强对可变尺寸目标的局部对比度特征提取。",
                "频率域引入动态高通滤波器模块，根据图像内容的频率能量分布动态计算掩膜半径以分层剔除特定比例的低频分量，从而自适应地抑制复杂背景杂波并保留高频目标细节。"
            ]
        },
        {
            "id": "d2576290",
            "title": "CVPR | 为什么你的模型细节有了，结构却塌了？试试 Local-Global Feature Extraction",
            "tags": [
                "这是一个单幅图像去雾领域的论文，提出了一种深度信息辅助的双任务协同互促框架，旨在通过去雾与深度估计的端到端联合训练提升结构保持能力。",
                "模型设计了差异感知双任务交互机制，利用去雾图像与真值的像素残差引导深度网络聚焦难恢复区域，并反向利用深度特征差异强化去雾网络对结构退化的感知。",
                "核心组件局部全局特征提取模块结合了卷积的局部纹理提取能力与窗口注意力的长距离依赖建模能力，通过规范化层和多层感知机交替处理实现特征增强。",
                "网络引入特征调制植入模块以多尺度方式融合深度与去雾特征，配合交替优化策略在训练中动态平衡两个任务的梯度更新，避免陷入单任务局部最优。"
            ]
        },
        {
            "id": "5ea68b1f",
            "title": "参数砍掉 34% 还能涨点？ResNet50 换上 SCConv 直接起飞，轻量化网络又有新玩法！",
            "tags": [
                "这是一篇计算机视觉领域关于轻量化网络设计的论文，提出了一种空间与通道重建卷积模块，旨在通过显式减少特征图中的空间和通道冗余来降低计算量并提升模型性能。",
                "空间重建单元依据组归一化层的缩放因子来评估空间内容信息量，采用分离重建机制将特征划分为不同信息等级并进行加权组合，从而抑制空间维度的冗余特征。",
                "通道重建单元利用分割变换融合策略，将特征图分流后分别执行高效的分组卷积与特征复用操作，并通过全局平均池化和加权机制实现自适应特征融合。",
                "该模型以串联方式组合上述两个单元，能够直接替换标准卷积神经网络瓶颈结构中的卷积层，在端到端训练中实现特征表达能力的增强与参数量的压缩。"
            ]
        },
        {
            "id": "123000e9",
            "title": "上采样一切！无需任何训练即可让一切分割、深度估计精度暴涨！（KAIST, MIT, 微软开源）",
            "tags": [
                "这是一个特征上采样与超分辨率领域的论文，提出了一种名为Upsample Anything的无需训练的测试时优化框架，旨在解决视觉基础模型特征下采样导致的空间细节丢失问题。",
                "该方法以单张高分辨率RGB图像为引导，通过优化从下采样版本重建原图的过程，学习每个像素包含空间方差和旋转角度在内的各向异性高斯核参数。",
                "模型结合了联合双边上采样与高斯泼溅技术，利用学习到的连续空间范围核将低分辨率特征图直接映射并泼溅到原始图像网格上，实现了跨模态和分辨率的高精度重建。"
            ]
        },
        {
            "id": "b917cff9",
            "title": "RK-∞降维打击Mamba？线性注意力真的有“免费午餐”！",
            "tags": [
                "这篇是大语言模型线性注意力机制优化的论文。",
                "这篇是大语言模型线性注意力机制优化的论文。该方案通过解析求解底层线性常微分方程，利用零阶保持假设将离散化的一阶欧拉法替换为无限阶龙格库塔级别的解析解，消除了状态更新中的数值漂移和离散化误差。",
                "利用动力学矩阵的秩一属性使矩阵指数的泰勒展开式简化，在维持线性时间复杂度的前提下实现了状态更新公式的闭式表达。",
                "引入基于键向量范数的光谱门控机制，通过非归一化输入信号产生的方向性衰减实现对历史背景信息的选择性遗忘与记忆动态管理。"
            ]
        },
        {
            "id": "5e7cb427",
            "title": "NeurIPS2025新型即插即用注意力机制-CBSA！",
            "tags": [
                "这篇是计算机视觉中注意力机制优化的论文。",
                "这篇是计算机视觉中注意力机制优化的论文。该方案基于最大编码率削减原理，通过引入少数代表性标记并建立编码率约束，将全体标记的结构压缩任务转化为对子空间代表者的收缩优化。",
                "算法执行过程分为收缩与广播两个阶段，即先计算代表性标记间的自注意力以确定特征演化方向，再将该方向通过注意力权重矩阵映射回所有原始标记。",
                "该架构通过调整代表性标记的生成方式实现了多种主流注意力机制的统一建模，并利用矩阵收缩特性将计算复杂度降低至线性。"
            ]
        },
        {
            "id": "0b158cda",
            "title": "AAAI 2026 Oral | Styletailor：首个集成设计/推荐/试衣/打分的负反馈多智能体框架",
            "tags": [
                "这篇是多模态领域中多智能体协同与个性化时尚造型的论文。",
                "该方案建立了包含单品、套装及试穿三个维度的分层负反馈机制，通过在迭代生成过程中显式参考并规避历史负面选择集来提升意图对齐精度。",
                "设计师智能体利用视觉语言模型将模糊需求解码为结构化属性，配合专家序列调度机制与视觉语义一致性校验实现单品检索与套装搭配的闭环优化。",
                "顾问智能体采用按服装面积从大到小排序的渐进式合成策略，并通过视觉语义闭环机制将试穿图像缺陷转化为负面提示词进行定向纠错。"
            ]
        },
        {
            "id": "0139c2e0",
            "title": "新王登基！VajraV1屠榜YOLO全家桶 | 无痛融合Transformer，实时性与精度刷新SOTA",
            "tags": [
                "这篇是目标检测领域中关于架构设计与特征融合的论文。",
                "该方案通过增加主计算模块卷积通道宽度并采用重参数化技术增强特征表达能力，配合双分支池化结构实现低计算成本的下采样。",
                "在深层网络中应用参数高效计算块，结合深度卷积与轻量级多层感知机模拟注意力机制的空间和通道混合功能。",
                "架构集成改进的自注意力模块，通过共享查询与键矩阵、深度卷积位置编码以及批归一化层实现卷积主干网络与全局建模模块的高效融合。"
            ]
        },
        {
            "id": "60a1a96f",
            "title": "Mamba作者团队提出SonicMoE：一个Token舍入，让MoE训练速度提升近2倍",
            "tags": [
                "这篇是大语言模型混合专家架构系统优化的论文。",
                "该方案重新设计计算图，通过在路由梯度计算阶段不缓存激活值，实现了激活显存占用量与专家粒度解耦，降低了反向传播过程中的内存消耗。",
                "利用异步并行范式设计专用内核，将分组矩阵乘法计算与全局显存的数据采集操作重叠，并通过融合输入采集与激活函数操作减少动态数据的传输延迟。",
                "引入令牌舍入调度策略，将分发至各专家的令牌数量调整为硬件计算块大小的倍数，通过对各专家分配结果进行增减处理来消除计算资源填充浪费。"
            ]
        },
        {
            "id": "f1517fa4",
            "title": "TPAMI 2025 | 轻量高效新方案：T2I-PAL 兼容任意 CLIP 框架，零 少样本多标签识别性能碾压现有方法",
            "tags": [
                "这篇是计算机视觉中多标签图像识别的论文。",
                "该方案利用预训练文本到图像生成模型将文本描述转化为合成图像，通过构建视觉文本联合训练集来弥合语义描述与视觉特征间的模态差距。",
                "模型架构整合了双分支提示学习与共享适配器机制，通过为类别设计不同粒度的文本提示并在图像局部特征与文本嵌入间建立跨模态交互路径。",
                "系统集成类激活热图机制以强化关键区域的特征表示，利用局部相似性度量与多模态目标函数实现对图像中多个语义目标的关联建模。"
            ]
        },
        {
            "id": "0822aae1",
            "title": "小米AI全面开花 | HyperVL扔掉笨重ViT！这个1.8B小模型在手机上跑出SOTA，还省电90%！",
            "tags": [
                "这篇是多模态大模型在移动端部署与性能优化的论文。",
                "该方案采用图像分块策略将高分辨率输入划分为固定尺寸的子块以保持恒定的峰值内存占用，并引入双一致性学习框架建立多尺度视觉编码器与共享大语言模型的语义对齐。",
                "通过语义一致性蒸馏机制使轻量化视觉分支模仿大型编码器的输出预测分布，实现了不同规模编码器在推理过程中的动态无缝切换。",
                "系统集成基于轻量级神经网络的分辨率压缩模块，通过预测最优图像压缩比来调节输入分辨率，从而在维持感知能力的同时减少冗余视觉令牌的计算开销。"
            ]
        },
        {
            "id": "af11dbf8",
            "title": "(ICLR 2025) O(n) Attention 来了：抛弃相似度的 Transformer 新思路",
            "tags": [
                "这篇是关于Transformer架构中线性注意力机制设计的论文。",
                "该方案完全舍弃了计算标记之间的两两相似度矩阵，转而利用标记特征在多个低维子空间内的二阶统计量来构造对角形式的注意力权重。",
                "技术核心源于最大编码率削减理论，通过将压缩目标的变分形式进行算法展开，使每一层注意力算子在数学本质上等价于执行一步旨在减少类内冗余的梯度下降迭代。",
                "该架构通过学习到的投影矩阵将标记映射至子空间，根据特征能量分布对不同方向进行选择性缩放，从而在保持全局感受野的同时实现低秩特征提取与去噪。"
            ]
        },
        {
            "id": "5fa009f7",
            "title": "SAM3零样本分割竟被YOLO11吊打12%？一个关键指标揭开算法评估的惊天秘密！",
            "tags": [
                "这是一篇关于实例分割领域的论文，重点探讨了通用基础模型SAM3与专用微调模型YOLO11在密集场景下的性能差异与评估机制。",
                "研究通过对比零样本推理与监督微调两种范式，发现轻量级专用模型在特定任务中具有更高的推理速度和目标召回率，而通用大模型虽然泛化能力强但在具体领域的语义识别上存在局限性。",
                "深入分析评估指标发现IoU阈值对模型评价具有决定性影响，专用模型因掩码边界拟合较粗糙导致在高阈值下性能显著下降，反之基础模型凭借精准的边缘分割能力在不同阈值下保持了指标稳定性。",
                "误差分析显示通用模型倾向于产生大量假阳性误检，而专用模型通过针对性训练在抑制背景干扰和适应边缘计算设备的低延迟部署方面展现出更优的工程实用性。"
            ]
        },
        {
            "id": "0baede91",
            "title": "(SCI 2025) 即插即用空间注意力新思路：SMSA",
            "tags": [
                "这是一篇计算机视觉领域关于注意力机制改进的论文，旨在探索空间注意力作为语义先验引导通道注意力的协同效应。该方法设计了共享多语义空间注意力模块，通过将输入特征沿通道维度划分为多个子组并应用不同核尺寸的一维深度可分离卷积来显式捕获多尺度空间结构。引入渐进式通道自注意力模块，利用空间渐进压缩策略降低计算复杂度，并在空间先验信息的引导下通过通道维度的单头自注意力机制完成特征重标定。整体架构建立了一种空间语义引导通道交互的非对称协同机制，利用组归一化与门控操作融合局部细节与全局上下文以解决传统串联结构中的语义割裂问题。"
            ]
        },
        {
            "id": "d2705a68",
            "title": "(CVPR 2025) 不用 DCN，也能做尺度自适应？ARConv 给出了新答案",
            "tags": [
                "这是一篇针对遥感图像全色锐化领域的论文，提出了自适应矩形卷积模块以解决多尺度目标建模难题。该方法打破了传统固定正方形卷积核的限制，通过显式学习卷积核的高度和宽度参数，生成能够自适应拉伸或收缩的矩形感受野。模块建立了两参数驱动的采样密度联动机制，根据学习到的长宽尺寸自动动态调整采样点数量，在保证特征覆盖的同时避免了可变形卷积中高维偏移量带来的计算冗余。此外在卷积输出后引入了仿射变换以增强空间自适应能力，并将其嵌入到编解码结构的残差块中，通过多尺度特征提取与细节注入实现高分辨率多光谱图像重建。"
            ]
        },
        {
            "id": "be0869ce",
            "title": "Meta FAIR推出Pixio: 追求视觉预训练中的像素空间监督",
            "tags": [
                "这是一篇视觉预训练与自监督表征学习领域的论文，提出了一种坚持纯像素空间监督的Pixio模型架构。 该方案针对MAE解码器容量不足的问题，显著增加了解码器层数以释放编码器提取特征的能力，并采用更大的掩码块粒度来防止像素真值泄露并增强长距离依赖建模。 模型引入了多个Class Token机制来并行捕获场景类别、图像风格和相机姿态等多种全局语义信息，在下游任务中可通过平均或拼接方式使用。 训练数据策略上利用基于重建损失大小的加权采样来平衡样本难度，并结合颜色直方图熵阈值过滤掉文档等低信息量图像，实现了在网络规模数据上的有效预训练。"
            ]
        },
        {
            "id": "33522ebc",
            "title": "MIT&伯克利提出 DAVE | 视觉编码器总翻车？两阶段训练法，让视觉编码器重新“看清”世界！！",
            "tags": [
                "这是一篇多模态领域的论文，旨在解决通用视觉语言模型在文档理解和网页智能体任务中结构与空间感知能力不足的问题。该方案第一阶段采用改进的掩码自编码器进行自监督预训练，通过将损失函数调整为直接重建原始像素值，解决了文档和网页图像因块间方差过低导致的训练崩溃问题。第二阶段利用多任务监督学习对齐视觉与语言空间，使用不同的语言模型作为解码器训练多个编码器副本，并通过蒸馏损失将这些权重合并以构建与具体解码器解耦的编码器。最终模型采用特征集成策略，将训练得到的领域专家特征与冻结的通用视觉编码器特征进行拼接，从而同时保留底层精细结构感知与高层通用语义理解能力。"
            ]
        },
        {
            "id": "b3a8da20",
            "title": "(CVPR 即插即用) 不改结构直接提性能：Manhattan Self-Attention 即插即用指南",
            "tags": [
                "这是一篇关于通用视觉Transformer骨干网络的论文，提出了一种名为RMT的高效架构方案。 核心提出Manhattan Self-Attention模块，通过引入基于曼哈顿距离的二维显式空间衰减矩阵，赋予自注意力机制近邻权重高而远处递减的类卷积空间偏置。 采用可分解的注意力计算策略，将二维交互沿水平和垂直方向拆分，在保留空间先验的同时将计算复杂度从二次方降低为线性以处理高分辨率特征。 模型整体采用四阶段金字塔结构，前三阶段使用分解式注意力进行线性全局建模，第四阶段使用完整二维注意力，并配合深度卷积模块增强局部上下文信息。"
            ]
        },
        {
            "id": "c50c5ff6",
            "title": "NeurIPS 2025 | 上大澳大联手，“无需训练”无人机全天候定位技术，暴雨浓雾都不怕！",
            "tags": [
                "这是一篇关于全天候无人机视觉地理定位与跨视角检索的论文，旨在解决雨雾雪夜等复杂气象条件下的特征对齐难题。该方案利用大视觉语言模型结合思维链推理技术，在无需针对天气微调的情况下，生成包含天气要素强度与宏观空间结构的规范化文本描述。通过文本驱动的动态门控机制将语义嵌入映射到视觉通道，利用自适应重加权策略显式解耦天气干扰与场景特征以实现稳健定位。"
            ]
        },
        {
            "id": "5efd9bfc",
            "title": "(CVPR 2025) 不做 Token Attention，也能学会融合：Sequence Shuffle Attention",
            "tags": [
                "这是一篇关于图像恢复领域的Vision Mamba论文，提出了一种名为MaIR的混合架构模型，旨在解决现有方法在序列化过程中破坏空间局部性与连续性的问题。 该方案提出Nested S-shaped Scanning扫描策略，通过结合条带级扫描区域与S型扫描路径，在将二维图像转换为一维序列的过程中同时保持像素的空间局部性与路径连续性。 引入Sequence Shuffle Attention模块，利用序列重排与分组卷积在通道维度显式建模不同扫描序列之间的依赖关系，替代简单的加和操作以实现多视角信息的自适应加权融合。 整体架构采用卷积神经网络与Mamba相结合的形式，在深层特征提取阶段堆叠残差Mamba组，并将上述扫描策略与注意力机制嵌入核心单元以在不增加计算负担的前提下增强长程建模能力。"
            ]
        },
        {
            "id": "e97a7647",
            "title": "(CVPR 2025) 结构胜过算子：Multi-Scale Grouped Dilated Convolution 的设计哲学",
            "tags": [
                "这是一篇关于高效视觉Transformer骨干网络的论文，提出了一种名为BHViT的二值化友好型混合架构方案。模型前两个阶段采用多尺度分组膨胀卷积替代注意力机制，通过不同膨胀率的卷积核进行局部特征交互，有效避免了早期注意力在二值化条件下的信息熵退化问题。后两个阶段引入改进的二值多头注意力模块，采用量化分解方案将二值注意力矩阵分解为多个逻辑阈值子注意力的叠加，并在查询键值路径中加入残差连接以改善梯度传播。此外设计了基于移位的二值多层感知机，利用空间移位操作增强信息交互能力，并配合层级残差与后期L1正则化损失的优化策略来解决二值网络训练不稳定的难题。"
            ]
        },
        {
            "id": "2b6ee72a",
            "title": "DFIR-DETR深度揭秘 | 砍掉75%计算量，小目标检测精度反升4.2%！",
            "tags": [
                "这是一篇关于跨场景小目标检测领域的Transformer架构优化论文，旨在解决微弱特征退化及计算资源分配低效的问题。提出动态CSP特征注意力模块，通过门控网络动态筛选相关性最高的前k个键值对并掩码其余连接，将注意力计算从全图密集型转变为结构化稀疏型以降低复杂度。设计动态特征金字塔网络，在特征上采样路径中集成幅度归一化算子，通过除以尺度因子抵消插值导致的数值膨胀，保持深浅层特征强度的可比性与连贯性。构建频域迭代细化模块，利用快速傅里叶变换建立全局感受野，通过可学习的频域卷积核自适应增强对小目标敏感的高频细节并抑制背景低频噪声。"
            ]
        },
        {
            "id": "7f74c60e",
            "title": "Linear Attention基础-理论篇",
            "tags": [
                "这是一篇关于线性注意力机制的基础理论文章，重点梳理了从标准Softmax架构向高效线性化模型演进的技术路径与数学本质。核心方案通过核函数映射利用矩阵结合律将计算复杂度由平方级降为线性，并基于循环神经网络形式实现了无需重复计算历史键值的高效自回归推理。进一步阐述了状态空间模型通过离散化与选择机制解决上下文推理难题，以及DeltaNet利用近似在线梯度下降更新规则处理键值非正交导致的信息冲突。最终探讨了测试时训练视角下的统一回归框架，并分析了引入因果卷积增强局部性、复数状态空间提升表达力以及外挂后缀自动机检索历史等工程优化手段。"
            ]
        },
        {
            "id": "eca8473f",
            "title": "NeurIPS 2025 | 不再迷信注意力：HoloV 带来的视觉 Token 裁剪新范式",
            "tags": [
                "这是一篇多模态大模型领域的论文，提出了一种面向全局语境的视觉Token剪枝范式HoloV，旨在解决传统基于注意力剪枝导致的语义碎片化和位置偏置问题。该方案放弃单一的注意力排序，通过将图像划分为空间块并计算块内Token相似度方差来获取语义多样性得分，再将其与注意力显著性加权融合。算法引入自适应配额分配机制，依据各块的平均得分动态拆分Token保留预算，避免局部高亮区域独占资源以维持跨区域的全局语义依赖。最终通过在各空间块内筛选高分Token完成剪枝，并利用前馈网络将部分被剪除的Token作为键值记忆重新注入中间层以补充丢失的细节信息。"
            ]
        },
        {
            "id": "9c0e457b",
            "title": "密歇根大学新研究：能泛化的扩散模型，源于其学到了均衡的表征空间",
            "tags": [
                "这是一篇生成式人工智能领域的论文，提出通过分析模型内部表征空间的形态来界定扩散模型是处于记忆训练数据还是泛化创作的状态。记忆模式下模型权重倾向于直接复刻样本从而形成仅有极少数神经元激活的尖峰表征，而泛化模式则学习数据的局部统计特性并形成能量分布均匀的均衡表征。方案基于此特性设计了通过计算中间层表征标准差来识别记忆样本的检测器，以及利用均衡表征空间的线性可加性实现无需训练的图像内容编辑方法。"
            ]
        },
        {
            "id": "7ca73282",
            "title": "(Elsevier 2025) 不再盲目多尺度：Kernel Selective Fusion Attention 如何让模型“自己选感受野”",
            "tags": [
                "这是一篇高光谱图像分类领域的论文，提出了双选择Transformer网络DSFormer以解决地物尺度不匹配及全注意力计算冗余的问题。核选择融合模块通过并行提取不同尺度的膨胀深度卷积特征，利用空间与光谱双重注意力机制自适应加权融合出最佳感受野范围。令牌选择融合模块在自注意力机制中引入重要性筛选策略，结合光谱分组与三维卷积生成特征，仅对高相关性的图块进行计算以抑制噪声。模型整体采用主成分分析降维预处理，通过堆叠包含上述两种模块的双选择融合组，在保留图像三维结构的同时实现空间与光谱信息的联合建模。"
            ]
        },
        {
            "id": "5221c3bf",
            "title": "滴滴&清华提出ColaVLA | 从“想”到“动”延迟砍掉80%！让端到端规划快如闪电",
            "tags": [
                "这是一篇自动驾驶领域的端到端轨迹规划论文，提出了基于视觉语言模型的ColaVLA框架以解决传统文本推理的高延迟问题。该方案构建了认知潜在推理器，通过两次前向传播将离散文本推理重构为连续潜在空间内的并行计算，利用自车状态对视觉特征进行自适应路由筛选并生成元动作决策。分层并行规划器采用因果保持的混合注意力机制，强制约束从粗粒度意图到细粒度控制的信息流向，在保证物理合理性的同时并行解码出多尺度轨迹。系统通过阶段感知的轨迹查询向量结合置信度引导的并行解码头，在一次推理中回归出未来不同时间域的路径点，实现了决策与规划的高效耦合。"
            ]
        },
        {
            "id": "36121f3e",
            "title": "ACM MM 2025 | 告别二次复杂度！ELFATT 让 Vision Transformer 兼具低内存与线性计算效率",
            "tags": [
                "这是一篇视觉Transformer注意力机制领域的论文，提出了高效线性快速注意力机制ELFATT以解决传统架构计算复杂度过高的问题。核心方案采用双并行注意力头架构，将输入特征在维度上进行拆分，分别送入全局线性和稀疏分块两个分支进行并行计算后融合。全局线性分支通过核函数近似方法捕捉长距离依赖，利用指数特征映射替代点积运算，从而实现与序列长度相关的线性计算复杂度。稀疏分块分支将序列划分为局部块以保留局部特征，天然兼容内存加速技术，并基于理论推导给出了近似计算的误差上界保证。"
            ]
        },
        {
            "id": "f67e9420",
            "title": "模块级解析｜Spatially-Enhanced Feedforward Network：为 SSM 补上空间意识 WACV | 2025",
            "tags": [
                "这是一篇图像修复领域的论文，提出了基于U-Net架构的SEM-Net，利用选择性状态空间模型Mamba进行像素级长程依赖建模。 模型核心采用Snake Mamba Block，通过蛇形双向扫描策略在水平和垂直方向建立序列，保持像素邻接连续性并隐式注入空间结构。 针对SSM局部感知能力的不足，设计了空间增强前馈网络SEFN，利用卷积和池化提取二维空间先验，并通过门控机制调制SSM后的特征输出。 整体架构包含位置增强层以显式增强长程位置信息，并配合多尺度编码器解码器结构与跳跃连接，在特征提取中平衡全局语义与局部细节。"
            ]
        },
        {
            "id": "65f9ff56",
            "title": "DeepSeek 开年王炸：mHC 架构用流形约束重构 ResNet 残差连接",
            "tags": [
                "这是一篇深度学习基础架构领域的论文，旨在通过流形约束超连接mHC重构传统ResNet的残差连接机制。模型将权重矩阵强制投影到特定的流形空间，在保留超连接高带宽与多通路优势的同时恢复恒等映射属性，解决了此前架构中梯度传播不稳定的跷跷板效应。方案引入谱范数约束限制最大奇异值以防止信号发散，并利用双重随机矩阵的闭包性质使层级输出保持凸组合形式，从数学层面保障了深层网络的收敛性。架构基于动力系统理论通过投影手法控制Lyapunov指数，并配合定制化的CUDA算子优化，在几乎不增加计算开销的情况下实现了对参数流形的几何约束。"
            ]
        },
        {
            "id": "1830d953",
            "title": "检测稳如狗，关联总掉链子？FDTA用三招让多目标跟踪ID永不乱！",
            "tags": [
                "这是一篇端到端多目标跟踪领域的论文，旨在解决共享特征提取导致的目标嵌入区分度不足问题，提出了包含空间、时间及身份三个适配器的FDTA框架。空间适配器利用知识蒸馏技术从基础模型获取深度伪标签，结合线性递增离散化与前景加权损失训练深度感知分支，并通过注意力机制将深度信息注入目标嵌入。时间适配器引入Transformer编码器处理目标历史轨迹序列，设计双重注意力掩码以保证因果性并处理检测缺失，从而生成聚合了长程依赖的轨迹嵌入。身份适配器通过质量感知的对比学习优化特征空间，利用交并比加权与一致性特征提取器在训练阶段拉大不同目标的特征距离，且推理阶段不增加计算开销。"
            ]
        },
        {
            "id": "85b52366",
            "title": "清华新作：用FFT将ViT注意力复杂度降至O(NlogN)！",
            "tags": [
                "这是一篇视觉Transformer领域的论文，旨在解决标准自注意力机制在高分辨率任务中计算复杂度过高的问题。研究团队发现ViT训练生成的注意力图在数学结构上呈现出明显的块循环矩阵特征。基于此特性提出的循环注意力机制利用卷积定理，通过快速傅里叶变换将时域的矩阵运算转化为频域内的点乘运算。这种方法在保持全局感受野的前提下，成功将原本的二次计算复杂度降低至线性对数级别。"
            ]
        },
        {
            "id": "e559957c",
            "title": "IEEE TPAMI 2026 | 窗口注意力“变形”了！DSwinIR重塑Transformer，图像复原新标杆",
            "tags": [
                "这是一篇图像复原领域的论文，提出了基于Transformer架构的DSwinIR模型，旨在解决传统窗口注意力机制存在的边界盲区和形状固定难以适应复杂纹理的问题。模型引入了可变形滑动窗口注意力机制，通过Token中心的滑动范式确保每个位置获取完整的局部上下文，并利用轻量级网络预测采样点的二维偏移量以实现感受野的动态调整。该方案采用双线性插值对偏移位置进行特征采样，并结合多尺度多头注意力策略为不同头组分配差异化的窗口尺寸，从而协同聚合局部细节与广阔的上下文信息。"
            ]
        },
        {
            "id": "4e777133",
            "title": "(AAAI 2025) 一个轻量模块，解决深层网络最容易忽略的“位置问题”",
            "tags": [
                "这是一篇航拍实时目标检测领域的论文，提出了基于YOLO架构改进的FBRT-YOLO模型，重点解决深层特征空间信息衰减与网络结构冗余问题。该模型在主干网络中嵌入特征互补映射模块，利用通道与空间双向映射机制将浅层位置信息显式注入深层语义特征。网络末端设计了多核感知单元替代常规下采样，通过串联多尺度深度可分离卷积来强化对微小目标的跨尺度特征提取。方案还包含面向航拍场景的冗余剪枝策略，通过移除多余的下采样层及对应的检测头来压缩参数量并提升推理效率。"
            ]
        },
        {
            "id": "75a0b34a",
            "title": "CVPR 2025满分论文! OverLoCK: 一种仿生的卷积神经网络视觉基础模型",
            "tags": [
                "这是一篇计算机视觉基础主干网络领域的论文，提出了一种受人类视觉认知启发的动态卷积神经网络OverLoCK。模型放弃传统金字塔结构提出深度阶段分解策略，构建了负责底层感知的Base-Net、提取全局粗糙语义的Overview-Net以及在先验引导下精细分析的Focus-Net三个子网络。全局高级语义作为自上而下的指导信号，在前向传播中持续更新并注入Focus-Net，显式引导门控计算、动态权重生成以及特征图的融合过程。核心组件ContMix动态卷积通过计算特征点与聚类中心的亲和度矩阵生成动态核，将全局上下文信息映射到卷积权重中，在保持局部归纳偏置的同时实现了长距离依赖建模。"
            ]
        },
        {
            "id": "db1b7593",
            "title": "视觉Transformer“偷懒”的秘密被发现了！Circulant-Attention破解“算力诅咒”与“人工枷锁",
            "tags": [
                "这是一篇针对视觉Transformer中自注意力机制进行计算效率优化的论文。研究人员通过分析发现成熟模型的注意力权重矩阵呈现出块循环块循环矩阵的结构特征，表明模型内在倾向于学习具有平移不变性的模式。核心方案是将注意力矩阵投影到块循环空间，利用卷积定理和快速傅里叶变换将高复杂度的矩阵乘法转化为频域内的逐元素相乘。为了解决循环结构导致的行列和固定限制，该方法引入了可学习的特征重加权模块对输出进行补偿以恢复特征表达能力。"
            ]
        },
        {
            "id": "20f9ea68",
            "title": "FPN 居然还在迭代 | KAN-FPN-Stem 根本上提升了融合质量，给卷积架构带来性能第二春",
            "tags": [
                "这是一篇针对基于视觉Transformer的人体姿态估计任务的论文。该方案首先使用由ResNet主干和特征金字塔网络组成的结构替代原始的块嵌入操作，以解决原生架构中细节丢失和尺度单一的问题。核心改进在于利用Kolmogorov-Arnold网络卷积层替换特征金字塔末端的线性平滑卷积，通过在权重上引入可学习的非线性函数来提升多尺度特征的融合质量。"
            ]
        },
        {
            "id": "1eb52d8d",
            "title": "NeurIPS 2025 x JMLR｜港中文提出RankSEG：无需重训模型，仅需三行代码即可显著提升分割模型 Dice/IoU",
            "tags": [
                "这是一篇针对语义分割任务通过无需重训的后处理算法优化Dice与IoU指标的论文。该方案基于排序统计理论证明了传统固定阈值方法的次优性，提出通过对预测概率图进行排序并动态搜索最佳截断点，从而直接最大化全局分割指标的期望值。为克服理论计算的高复杂度，研究引入倒数矩近似技术，利用总体特征忽略单像素差异并以期望的倒数替代倒数的期望，实现了推理过程的线性时间复杂度。在多类别场景下，算法采用独立二值分割配合贪心去重策略，依据像素归属不同类别时产生的指标期望增益值来处理重叠冲突并完成最终分类。"
            ]
        },
        {
            "id": "914dd09a",
            "title": "TPAMI 2026 | 北大彭宇新团队提出免特征重建终身行人重识别方法Bi-C2R：在隐私、性能与效率间寻找最优解",
            "tags": [
                "这是一篇免重索引终身行人重识别领域的论文，提出了双向持续兼容表征框架Bi-C2R，旨在无需访问历史图像数据的情况下通过更新数据库特征实现新旧模型的兼容。该方案构建了双向持续转移网络，通过知识捕获与前向映射模块在目标特征与源特征间进行双向转移，利用对称机制平衡新旧知识并避免灾难性遗忘。算法通过双向兼容蒸馏模块对齐特征分布并保持样本间相似度关系，配合双向抗遗忘蒸馏模块提取旧特征的分布统计量，利用判别一致性约束保留类间鉴别信息。模型最后引入动态特征融合模块，根据新旧模型预测结果的差异衡量知识变化程度，自适应地融合转移特征与旧特征以解决不同数据域的领域漂移问题。"
            ]
        },
        {
            "id": "4af7e32e",
            "title": "ICLR | 通道注意力太重？试试 Channel Reallocation",
            "tags": [
                "这是一篇关于计算机视觉通用骨干网络的论文，提出了名为MogaNet的纯卷积架构方案。核心模块利用多阶门控聚合机制，通过多分支不同尺度的深度可分离卷积并行提取空间信息，并使用门控单元自适应融合局部、区域与全局特征。在通道维度设计了通道重分配前馈网络，通过卷积降维提取全局响应并进行特征分解，利用可学习的缩放因子增强细粒度特征的表达能力。整体结构摒弃了自注意力机制，完全依靠层级化的卷积堆叠和动态门控加权，实现了兼顾计算效率与全局感受野的特征建模。"
            ]
        },
        {
            "id": "d3025838",
            "title": "(CVPR 2025) 高频一定是细节吗？Frequency Dynamic Selection Mechanism 的反直觉设计",
            "tags": [
                "这是一篇近红外图像辅助的图像去噪领域的论文，提出了一种利用跨模态频率相关性的FCENet网络架构。核心方案通过频率动态选择机制，依据RGB模态低频可信度高与近红外模态高频结构清晰的互补特性，在频域内分别筛选并保留各自优势的频率分量。模型设计了频率穷尽融合模块，并行提取跨模态的公共低频特征与近红外特有的高频差异信息，解决了传统融合策略中因仅保留公共特征而导致的高频细节缺失问题。具体实现上采用了基于快速傅里叶变换的动态滤波器，通过辅助网络生成路由权重对一组复数基滤波器进行线性组合，在频域通过逐点乘法实现自适应的特征滤波与重构。"
            ]
        },
        {
            "id": "d236da67",
            "title": "字节跳动提出 Hyper-Connections，训练提速 1.8 倍",
            "tags": [
                "这是一篇深度学习网络架构优化的论文，字节跳动提出Hyper-Connections以解决传统残差连接存在的表征崩溃与梯度消失问题。该方案不再使用单一特征向量，而是将其扩展为超隐状态矩阵，利用宽度连接对矩阵内的多个向量进行加权求和作为当前层输入。层计算后通过深度连接机制更新超隐状态，利用可学习的静态或动态权重控制信息的保留与写入，实现网络拓扑结构在串联与并联间的自适应切换。"
            ]
        },
        {
            "id": "cc146ea6",
            "title": "CVPR25 |小卷积SW-Conv，参数砍半，精度飙升",
            "tags": [
                "这是一篇计算机视觉领域中关于卷积神经网络基础算子改进的论文。该方案提出Shiftwise卷积算子，通过引入可学习的位移操作，使3x3小卷积核能够动态覆盖大感受野并构建长距离稀疏依赖。算法利用重参数化技术将移位操作与卷积运算融合，通过优化特征利用路径而非扩大核尺寸，实现了用小卷积核对大尺寸卷积核的高效替代。"
            ]
        },
        {
            "id": "b64e13b6",
            "title": "AAAI | 不靠注意力，sMLP 也能做到 Swin 级性能？",
            "tags": [
                "这是一篇视觉骨干网络设计的论文，旨在探索不依赖自注意力机制构建高性能金字塔式架构的可行性。 该方案提出Sparse MLP模块，利用行与列方向的轴向稀疏连接配合权重共享机制，替代了传统MLP中的全连接操作。 模型采用多阶段层级结构，在每个模块内部通过深度可分离卷积提取局部特征，并结合轴向稀疏连接实现全局信息交互。 计算流程上将水平投影、垂直投影及输入特征进行通道拼接，最后经由线性层融合输出，在降低计算复杂度的同时保证了全局感受野。"
            ]
        },
        {
            "id": "75821c32",
            "title": "CVPR | LGAG：给 Skip Connection 加一道“低成本注意力门”",
            "tags": [
                "这是一篇医学图像分割领域的论文，主要提出了一种即插即用的高效多尺度卷积注意力解码器，旨在解决现有解码结构参数冗余与计算量大的问题。该方案设计了多尺度卷积注意力模块，利用不同尺寸的深度可分离卷积替代传统卷积层，并在模块内并行融合通道注意力与空间注意力以增强特征提取能力。针对跳跃连接融合阶段提出了大核分组注意力门，通过使用分组卷积替代传统的点卷积注意力门，在扩大局部感受野的同时实现特征的低成本选择性激活。整体网络采用U型架构并结合深度可分离上采样模块逐级恢复空间分辨率，同时应用多尺度监督策略在不同解码层级计算损失以优化训练过程。"
            ]
        },
        {
            "id": "1281e92b",
            "title": "(ICLR 2025) 基于二阶统计量的自注意力：TSSA 的理论基础与实践意义",
            "tags": [
                "这是一篇关于高效Transformer架构设计的论文，提出了一种基于Token二阶统计量的线性时间注意力机制TSSA及相应的TOST模型。该方案首次从最大编码率降低理论推导出注意力结构，通过变分展开的方式构建白盒网络设计，摒弃了传统注意力中计算量巨大的点对点相似度矩阵。TSSA模块利用子空间投影估计Token的归属度，并基于投影后的二阶统计量构造对角注意力矩阵，从而在每个注意力头内实现动态低秩投影与信息筛选。模型整体保持了标准Transformer的宏观架构，仅将注意力层替换为TSSA模块，在实现线性计算复杂度的同时具备自然的语义聚类与结构化表示能力。"
            ]
        },
        {
            "id": "08b2ceaa",
            "title": "(CVPR 2025) 不用 Attention，也能建模多尺度：Multi-Scale Grouped Dilated Convolution",
            "tags": [
                "这是一篇二值量化领域的论文，提出了一种专为二值化设计的混合视觉Transformer架构BHViT，旨在解决标准ViT直接二值化带来的性能退化问题。网络浅层阶段采用多尺度分组空洞卷积替代注意力机制，通过不同膨胀率的卷积核并行提取特征，在降低计算量的同时减少二值噪声干扰。深层阶段引入多尺度多头注意力模块恢复全局建模能力，并利用量化分解策略将注意力矩阵拆解为多个二值子矩阵的叠加以缓解信息塌缩。以前馈网络中的位移操作增强二值全连接层的局部特征表达，并配合正则化损失约束潜在权重分布，防止优化过程中的权重震荡与失活。"
            ]
        },
        {
            "id": "44dc0515",
            "title": "给YOLOv8装上这个“去噪”插件，微小目标检测能力竟暴涨97%！",
            "tags": [
                "这是一份关于遥感图像与微小目标检测的技术解读，涵盖了针对多模态数据的动态感受野网络与基于去噪机制的特征金字塔优化方案。 PG-DRFNet通过利用小目标真值建立跨层位置导向关系生成逻辑掩码以监督特征融合，并在推理阶段采用基于特征裁剪与聚合的动态感知算法剔除背景冗余计算。 DNTR框架引入基于几何语义对比学习的去噪FPN模块，利用辅助编码器在训练时约束特征对齐，实现零推理成本的特征金字塔噪声抑制。 该方案的检测头采用Shuffle Unfolding机制通过特征重排增强局部细节，并配合掩码Transformer编码器通过切断注意力联系来分离分类与回归任务以避免特征干扰。"
            ]
        },
        {
            "id": "0a9ea9a7",
            "title": "YOLO26 正式开源！无NMS推理+CPU 性能提升43%，面向边缘视觉AI的新一代YOLO模型",
            "tags": [
                "这是一篇关于边缘视觉AI领域新一代目标检测模型YOLO26的技术报告。该模型通过移除分布焦点损失模块简化了边界框预测流程，并采用原生端到端架构彻底摒弃了传统的非极大值抑制后处理步骤。训练阶段引入渐进式损失平衡与小目标感知标签分配策略以提升检测精度，配合融合了SGD与Muon机制的MuSGD优化器确立训练稳定性。系统针对CPU与边缘设备进行了底层推理优化，并扩展推出了支持多模态提示驱动的开放词汇分割模型YOLOE-26。"
            ]
        },
        {
            "id": "55ae2720",
            "title": "0.15M参数185 FPS！TriLiteNet碾压YOLOPX/ HybridNets，轻量多任务自动驾驶感知新标杆",
            "tags": [
                "这是一篇自动驾驶感知领域的论文，提出了一种名为TriLiteNet的轻量级多任务模型，旨在嵌入式设备上同时实现车辆检测、可行驶区域分割和车道线分割。该方案采用基于ESPNet架构的共享编码器，通过将扩张卷积替换为深度扩张可分离卷积构建深度ESP模块，在大幅降低计算成本的同时保留多尺度特征提取能力。针对检测任务设计了基于路径聚合网络的轻量化特征聚合模块LitePAN，利用深度可分离卷积简化特征融合路径并结合基于锚点的机制处理多尺度目标。分割任务通过部分类激活注意力模块与简单的转置卷积上采样结构进行解码，整体架构利用独立解码器设计避免了任务间冲突，支持在低算力边缘设备上进行实时高效推理。"
            ]
        },
        {
            "id": "16a29768",
            "title": "ECCV | 为轻量模型而生：Efficient Approximation of Self-Attention 是如何省算力的？",
            "tags": [
                "这是一篇轻量级图像超分辨率领域的论文，提出了自调制特征聚合网络SMFANet，旨在通过低成本的类注意力机制解决传统Transformer计算量大且细节恢复能力弱的问题。该方案设计了高效近似自注意力模块，摒弃了传统的像素级点积计算，转而利用特征的空间下采样获取低频结构，并结合全局方差统计量进行特征调制以实现非局部信息的聚合。为了弥补低频感知的不足，网络在同一模块内并行引入了局部细节估计分支，专门负责捕捉图像的高频纹理与边缘信息，与非局部结构分支形成频域互补。此外，论文设计了基于部分卷积的前馈网络，仅对部分通道特征执行卷积操作以增强空间信息交互，在保持重建性能的同时大幅降低了显存占用与计算冗余。"
            ]
        },
        {
            "id": "7a7f9025",
            "title": "ICME | CLFT 模块：不改主干，也能增强全局感知",
            "tags": [
                "这是一篇红外小目标检测领域的论文，提出了基于UNet架构的ABC网络以解决目标弱小及背景噪声干扰问题。编码器引入卷积线性融合Transformer模块，通过并联普通卷积与空洞卷积分支保持局部感知，并利用双线性相关注意力机制在空间维度上建模位置相关性。网络深层设计了U型卷积空洞卷积模块，采用卷积层与多尺度空洞卷积层交替的结构，在低分辨率特征图上通过动态调整感受野来细化语义特征。整体框架通过跳跃连接融合多尺度特征，利用双线性注意力替代标准自注意力机制，在降低计算维度的同时实现全局特征与局部卷积特征的深度融合。"
            ]
        },
        {
            "id": "47a5663a",
            "title": "(TGRS 2025) 轻量模型如何应对复杂空间变化？Dynamic Spatial Attention",
            "tags": [
                "这是一篇计算机视觉领域的论文，提出了一种名为SCConv的空间和通道重构卷积模块，旨在解决卷积神经网络中的特征冗余问题。空间重构单元利用组归一化层的缩放参数来评估特征图的空间信息含量，将信息丰富与空间冗余的特征进行分离并通过加权门控机制实现交叉重构。通道重构单元采用分割变换融合策略将特征图按比例拆分，对高价值通道使用组卷积与点卷积提取特征，对冗余通道则进行廉价卷积处理与特征复用。该方案将上述两个单元串联形成即插即用的卷积模块，在不改变网络拓扑结构的前提下替代标准卷积层，通过先清理空间冗余再压缩通道冗余的方式降低计算复杂度。"
            ]
        },
        {
            "id": "5435f445",
            "title": "IEEE | CNN 不够，Transformer 太重？试试 CAFM",
            "tags": [
                "这是一篇高光谱图像去噪领域的论文，提出了一种混合卷积与注意力机制的网络HCANet，旨在同时解决局部空间光谱相关性与全局长程依赖的建模问题。网络核心采用了卷积注意力融合模块，通过三维卷积配合通道混洗提取局部特征，并行的低复杂度自注意力分支则负责捕捉长距离光谱依赖，两者在特征层级进行融合。传统的前馈网络被替换为多尺度前馈网络，利用不同扩张率的空洞卷积与门控机制来聚合多尺度上下文信息，增强对不同尺度噪声的抑制能力。整体架构设计为U型残差网络结构，编码器与解码器由包含层归一化、特征融合模块及多尺度前馈网络的混合单元堆叠而成，最终通过残差学习输出去噪结果。"
            ]
        },
        {
            "id": "7b464187",
            "title": "中科院提出 SoLA-Vision | 逐层混合注意力用ResNet18的计算量完成了10个点的腾飞，性能反超SOTA！",
            "tags": [
                "这是一篇计算机视觉领域的论文，提出了SoLA-Vision架构，旨在通过逐层混合策略解决线性注意力长程衰减与传统Transformer计算复杂度高的问题。该方案采用稀疏交错的混合模式，在网络的深层阶段将极少量的全局Softmax层插入线性注意力堆叠中，从而在保持低计算量的同时恢复长距离依赖。整体架构遵循四阶段分层设计，前两个高分辨率阶段完全使用线性注意力层以利用其局部归纳偏置并降低计算成本。此外设计了隐藏状态桥机制，将浅层线性单元的隐藏状态经采样投影后直接注入深层Softmax层，以补充高分辨率阶段缺失的全局上下文信息。"
            ]
        },
        {
            "id": "37f4de95",
            "title": "AAAI 2026 Oral | 告别注意力与热传导！北大清华提出WaveFormer，首创波动方程建模视觉",
            "tags": [
                "这是一篇计算机视觉基础骨干网络领域的论文，提出了基于波动方程建模的视觉主干网络WaveFormer。该方法将特征图视为随网络深度演化的空间波场，利用欠阻尼波动方程的物理特性来显式建模语义信息的传播动力学过程。核心机制是通过推导波动方程在频域的闭式解，实现频率与时间的解耦，在频域内对不同频率分量进行差异化的振荡调制以兼顾全局结构与高频细节。网络利用快速傅里叶变换构建了波传播算子，将全局交互的计算复杂度降低至对数线性级别，并以此为基础单元构建了层级化的金字塔型视觉架构。"
            ]
        },
        {
            "id": "692c3793",
            "title": "2026开年新风向：上下文即Teacher，三文详解Self-Distillation新范式",
            "tags": [
                "大语言模型领域提出基于上下文的自我蒸馏范式，利用推理时的额外上下文构建比基础模型更强的自我作为Teacher指导训练；SDFT通过检索旧任务示例作为Context构建Conditioned Teacher分布，让Student在没有演示的情况下通过KL散度拟合Teacher输出实现持续学习中的灾难性遗忘问题；SDPO利用Rich Feedback（如编译器报错）构建Self-Teacher，将稀疏的标量奖励信号转化为密集的Token级监督，通过蒸馏自我修正能力提升代码生成效果；OPSD定义Teacher Policy利用答案作为导航生成高质量思维链，让Student在自己的采样轨迹上拟合Teacher分布，优化Student与全知Teacher之间的分布距离以提升数学推理能力。"
            ]
        },
        {
            "id": "44ec4fa8",
            "title": "(AAAI 2025) 空间信息去哪了？Feature Complementary Mapping Module 的设计逻辑",
            "tags": [
                "航拍图像目标检测领域提出 FBRT-YOLO，通过在 backbone 内部引入 Feature Complementary Mapping Module 实现浅层空间位置信息与深层语义特征的双向互补映射，缓解小目标在深层语义中位置消失的问题；FCM 通过 channel ↔ spatial 双向引导机制，让语义强的特征指导空间特征关注重要通道，让位置敏感的特征指导语义特征关注重要空间位置；以 Multi-Kernel Perception Unit 替代传统下采样，利用多尺度 depthwise 卷积串联扩大感受野并减少检测头数量；针对高分辨率航拍场景设计冗余驱动结构裁剪，重新设计下采样阶段的 channel expansion 与 spatial sampling 顺序，在保证精度的情况下显著减少参数量和计算量。"
            ]
        },
        {
            "id": "2f25e6e8",
            "title": "英伟达开源C-RADIOv4 | 参数少10倍，性能反超DINOv3！用\"一鱼多吃\"颠覆视觉基础模型",
            "tags": [
                "视觉基础模型领域提出 C-RADIOv4，通过多教师蒸馏框架让一个学生模型同时向 SigLIP2（文本对齐）、DINOv3（自监督）和 SAM3（分割）三位顶尖教师学习，实现一个模型通吃分类、分割、检索等多种任务；采用随机分辨率训练策略，让模型在任何分辨率下同时看到所有教师，避免模式切换问题，实现分辨率不变的特征表示；引入平移等变损失，通过随机移动学生和教师看到的裁剪区域，以 Patch 大小为增量避免插值效应，让学生学习真正的语义对应关系而非记住固定位置输出；提出角度离散度归一化解决摘要特征损失不平衡问题，确保所有教师在损失中话语权平等。"
            ]
        },
        {
            "id": "8ba055c3",
            "title": "(TCSVT 2025) MFACB：多尺度融合空洞卷积块，即插即用，永远开源！",
            "tags": [
                "语义分割领域提出 DSNet 和多尺度融合空洞卷积块 MFACB，通过在单个模块内融合多种空洞率对应的感受野，使网络在浅层阶段同时学习多尺度语义信息；设计同分辨率双分支结构，将细节建模与上下文建模并行进行，避免传统下采样带来的信息不可逆丢失，空间分支用标准稠密卷积保留边界纹理信息，上下文分支以小空洞率空洞卷积为核心逐步扩大感受野；引入多尺度注意力融合模块 MSAF，通过区域级与像素级注意力机制动态调节来自不同分支的信息权重，使跨分支特征融合从固定叠加转变为任务驱动的动态选择。"
            ]
        },
        {
            "id": "fc2ea070",
            "title": "牛掰！轻量级VRF-DETR开源，仅13.5M 参数，实时推理，无人机小目标检测\"精度与效率双巅峰\"",
            "tags": [
                "无人机目标检测领域提出 VRF-DETR，通过多尺度上下文融合模块 MSCF 动态调整感受野，当遇到小目标时集中注意力于目标细节，面对大目标时着重把握整体轮廓；设计门控卷积 GConv 结合门控机制与深度可分离卷积降低参数量，门控多尺度融合模块 GMCF 先用全局注意力把握场景整体再进行局部处理解耦被遮挡目标。"
            ]
        },
        {
            "id": "85c7b509",
            "title": "(CVPR 2025) 长程依赖 ≠ 全局 Attention：Token Aggregation Block 的巧妙设计",
            "tags": [
                "图像超分辨率领域提出 CATANet 和 Token Aggregation Block，通过 Content-Aware Token Aggregation 机制将全图中内容相似的 token 聚合为若干组，而非使用空间邻近的分组方式；共享一组全局 token centers 仅在训练阶段通过 EMA 更新，推理阶段完全固定，显著降低计算开销；TAB 将内容感知分组、组内自注意力、组间交叉注意力进行统一设计，组内通过 Intra-Group Self-Attention 实现细粒度长程依赖建模，组间通过 Inter-Group Cross-Attention 与全局 token centers 交互补充全局上下文约束；通过 Local Region Self-Attention 补充局部精细建模，与 TAB 形成互补。"
            ]
        },
        {
            "id": "3fa7e663",
            "title": "Rethinking Transformer-Based Blind-Spot Network for Self-Supervised Image Denoising",
            "tags": [
                "TBSN是一个基于U-Net的多尺度Blind-Spot网络，首次系统性解决Transformer与Blind-Spot Network的结构冲突问题；提出两种满足Blind-Spot约束的Transformer注意力机制：Grouped Channel-wise Self-Attention（G-CSA）通过通道分组控制每组通道数小于空间分辨率，彻底规避中心像素信息泄露；Masked Window-based Self-Attention（M-WSA）通过固定空间掩码仅允许偶数坐标间交互，等效模拟dilated convolution的感受野扩展"
            ]
        },
        {
            "id": "713c02c2",
            "title": "2",
            "tags": [
                "YOLO11-4K：面向4K全景图像实时小目标检测的高效架构",
                "YOLO11-4K是Ultralytics YOLO11框架的扩展版本，通过引入P2细粒度检测层直接提取骨干网络早期高分辨率特征图，专门用于4K全景图像中的小目标检测；采用轻量级GhostConv骨干网络和C3Ghost模块减少计算冗余，结合C3k2模块改进特征聚合效率；端到端处理全分辨率3840×3840全景图像，无需下采样或裁剪，实现每帧28.3毫秒的实时推理速度"
            ]
        },
        {
            "id": "1a79f7df",
            "title": "POLAFORMER: POLARITY-AWARE LINEAR ATTENTION FOR VISION TRANSFORMERS",
            "tags": [
                "视觉Transformer/注意力机制领域的线性注意力改进模块。Polarity-Aware Linear Attention首次显式建模query-key的正负号关系，将注意力交互拆分为同号项和异号项两条分支；解决现有线性注意力因非负kernel导致负值交互信息完全丢失的问题，提出具有正一阶和二阶导数的通道级可学习幂函数，从理论上保证注意力熵下降；使线性注意力在不牺牲O(N)复杂度的前提下恢复softmax的尖峰特性，通过Q/K极性分解和V通道对称拆分实现双分支融合"
            ]
        },
        {
            "id": "c00440b9",
            "title": "Rethinking Transformer-Based Blind-Spot Network for Self-Supervised Image Denoising",
            "tags": [
                "TBSN是一个基于U-Net的多尺度Blind-Spot网络，首次系统性解决Transformer与Blind-Spot Network的结构冲突问题。提出两种满足Blind-Spot约束的Transformer注意力机制：Grouped Channel-wise Self-Attention（G-CSA）通过通道分组控制每组通道数小于空间分辨率，彻底规避中心像素信息泄露；Masked Window-based Self-Attention（M-WSA）通过固定空间掩码仅允许偶数坐标间交互，等效模拟dilated convolution的感受野扩展。"
            ]
        },
        {
            "id": "bce723ab",
            "title": "YOLO11-4K：面向4K全景图像实时小目标检测的高效架构",
            "tags": [
                "YOLO11-4K是Ultralytics YOLO11框架的扩展版本，通过引入P2细粒度检测层直接提取骨干网络早期高分辨率特征图，专门用于4K全景图像中的小目标检测。采用轻量级GhostConv骨干网络和C3Ghost模块减少计算冗余，结合C3k2模块改进特征聚合效率。端到端处理全分辨率3840×3840全景图像，无需下采样或裁剪，实现每帧28.3毫秒的实时推理速度。"
            ]
        },
        {
            "id": "0d4e02ff",
            "title": "Rewrite the Stars",
            "tags": [
                "轻量级网络/卷积神经网络领域的即插即用模块。StarConv通过逐元素乘（star operation）在不增加宽度和结构复杂度的前提下，等价于隐式的多项式核映射，单层即可产生约O(d²)个线性无关的隐式特征维度。首次系统性证明star operation并非只是门控或注意力技巧，而是深层网络实现高阶非线性表达的高效方式。提出StarNet作为验证模型，采用四阶段层级式CNN结构，通过DW-Conv+FC双分支进行逐元素乘完成特征融合，在保持低计算量的同时实现高精度。"
            ]
        },
        {
            "id": "c4d1cb36",
            "title": "POLAFORMER: POLARITY-AWARE LINEAR ATTENTION FOR VISION TRANSFORMERS",
            "tags": [
                "视觉Transformer/注意力机制领域的线性注意力改进模块。Polarity-Aware Linear Attention首次显式建模query-key的正负号关系，将注意力交互拆分为同号项和异号项两条分支。解决现有线性注意力因非负kernel导致负值交互信息完全丢失的问题，提出具有正一阶和二阶导数的通道级可学习幂函数，从理论上保证注意力熵下降。使线性注意力在不牺牲O(N)复杂度的前提下恢复softmax的尖峰特性，通过Q/K极性分解和V通道对称拆分实现双分支融合。"
            ]
        },
        {
            "id": "76682206",
            "title": "InceptionNeXt: When Inception Meets ConvNeXt",
            "tags": [
                "卷积神经网络/轻量级网络领域的Token Mixer重构。指出ConvNeXt中7×7大核depthwise convolution在GPU上严重受限于memory access而非FLOPs。提出Inception Depthwise Convolution将通道沿维度拆分为4个并行分支：3×3深度卷积、1×k横向条带卷积、k×1纵向条带卷积和恒等映射，将k×k的二次复杂度转化为线性复杂度。在ConvNeXt框架内仅替换DWConv为Inception DWConv，不改训练策略、不引入attention或额外token mixer，实现精度几乎不降而吞吐显著提升。"
            ]
        },
        {
            "title": "CATANet: Efficient Content-Aware Token Aggregation for Lightweight Image Super-Resolution",
            "tags": [
                "Token Aggregation Block 是内容感知的 attention 重构模块，用极低的推理成本，把局部 attention 升级为高效、稳定的长程建模能力",
                "Content-Aware Token Aggregation 机制通过 token center + cosine similarity，将语义相似但空间位置可能很远的 token 聚合到同一组，聚合是内容驱动的，而非固定空间划分",
                "Token Aggregation Block 包含 IASA（组内自注意力）、IRCA（组间交叉注意力）和子分组机制，推理时不做任何聚类或迭代更新",
                "TAB 填补了全局 Self-Attention 太慢、Window/Stripe Attention 又 看不远、看不准 的空缺"
            ],
            "id": "2953fc1a"
        },
        {
            "title": "TSD-YOLO使小尺寸交通标志检测mAP提升5.1%，FPS达50的实时精准检测模型",
            "tags": [
                "TSD-YOLO 是基于 YOLOv8s 的小尺寸交通标志实时检测模型",
                "SPD 模块通过空间到深度切片将特征图下采样并保留细粒度信息，扩大感受野",
                "SK 注意力模块使用多尺度卷积分支和自适应权重融合，智能聚焦交通标志区域",
                "WIoUv3 损失根据样本出现频率和检测难度分配权重，提升难样本检测精度"
            ],
            "id": "f068438d"
        },
        {
            "title": "DFIR-DETR 轻量化模型，削减 75% 计算量，小目标检测精度却提升4.2%！",
            "tags": [
                "DFIR-DETR 是基于 Transformer 的小目标检测模型，通过动态稀疏注意力、幅度归一化金字塔和频域全局建模解决传统模型的痛点",
                "DCFA 动态稀疏注意力通过门控网络动态选择关键 Key，将复杂度从 O(N²) 降低到 O(NK)",
                "DFPN 的幅度归一化上采样在上采样后除以尺度因子平方，解决特征虚胖问题",
                "FIRC3 通过傅里叶变换建立全局感受野，以 O(N log N) 复杂度增强高频信息"
            ],
            "id": "b1f2d1a4"
        },
        {
            "title": "HS-FPN: High Frequency and Spatial Perception FPN for Tiny Object Detection",
            "tags": [
                "HS-FPN 是用于微小目标检测的特征金字塔网络，在 FPN 基础上引入高频感知模块和空间依赖感知模块",
                "HFP 利用高通滤波器生成高频响应，从空间和通道维度加权增强微小目标特征",
                "SDP 构建特征间的空间依赖关系，弥补传统 FPN 空间感知能力不足的问题"
            ],
            "id": "29d08f16"
        }
    ]
}